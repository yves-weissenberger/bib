Automatically generated by Mendeley Desktop 1.17.10
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Pompilio,
abstract = {Humans and other vertebrates occasionally show a preference for items remembered to be costly or experienced when the subject was in a poor condition (this is known as a sunk-costs fallacy or state-dependent valuation). Whether these mechanisms shared across vertebrates are the result of convergence toward an adaptive solution or evolutionary relicts reflecting common ancestral traits is unknown. Here we show that state-dependent valuation also occurs in an invertebrate, the desert locust Schistocerca gregaria (Orthoptera: Acrididae). Given the latter's phylogenetic and neurobiological distance from those groups in which the phenomenon was already known, we suggest that state-dependent valuation mechanisms are probably ecologically rational solutions to widespread problems of choice.},
author = {Pompilio, Lorena},
doi = {10.1126/science.1123924},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pompilio, Kacelnik, Behmer - Unknown - State-Dependent Learned Valuation Drives Choice in an Invertebrate.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
number = {5767},
pages = {1613--1615},
pmid = {16543462},
title = {{State-Dependent Learned Valuation Drives Choice in an Invertebrate}},
url = {http://science.sciencemag.org/content/sci/311/5767/1613.full.pdf http://www.sciencemag.org/cgi/doi/10.1126/science.1123924},
volume = {311},
year = {2006}
}
@article{Ulanovsky,
abstract = {Neurons in primary auditory cortex (A1) of cats show strong stimulus-specific adaptation (SSA). In probabilistic settings, in which one stimulus is common and another is rare, responses to common sounds adapt more strongly than responses to rare sounds. This SSA could be a correlate of auditory sensory memory at the level of single A1 neurons. Here we studied adaptation in A1 neurons, using three different probabilistic designs. We showed that SSA has several time scales concurrently, spanning many orders of magnitude, from hundreds of milliseconds to tens of seconds. Similar time scales are known for the auditory memory span of humans, as measured both psychophysically and using evoked potentials. A simple model, with linear dependence on both short-term and long-term stimulus history, provided a good fit to A1 responses. Auditory thalamus neurons did not show SSA, and their responses were poorly fitted by the same model. In addition, SSA increased the proportion of failures in the responses of A1 neurons to the adapting stimulus. Finally, SSA caused a bias in the neuronal responses to unbiased stimuli, enhancing the responses to eccentric stimuli. Therefore, we propose that a major function of SSA in A1 neurons is to encode auditory sensory memory on multiple time scales. This SSA might play a role in stream segregation and in binding of auditory objects over many time scales, a property that is crucial for processing of natural auditory scenes in cats and of speech and music in humans.},
author = {Ulanovsky, Nachum and Las, Liora and Farkas, Dina and Nelken, Israel},
doi = {10.1523/JNEUROSCI.1905-04.2004},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ulanovsky et al. - Unknown - BehavioralSystemsCognitive Multiple Time Scales of Adaptation in Auditory Cortex Neurons.pdf:pdf},
isbn = {1529-2401 (Electronic)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Adaptation,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Cats,Electrophysiology,Linear Models,Memory,Models,Neurological,Neurons,Neurons: physiology,Physiological,Thalamus,Thalamus: physiology,Time Factors},
number = {46},
pages = {10440--53},
pmid = {15548659},
title = {{Multiple time scales of adaptation in auditory cortex neurons.}},
url = {http://www.jneurosci.org/content/jneuro/24/46/10440.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/15548659},
volume = {24},
year = {2004}
}
@article{Choromanska,
abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
archivePrefix = {arXiv},
arxivId = {1412.0233},
author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'{e}}rard Ben and LeCun, Yann},
eprint = {1412.0233},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Choromanska et al. - 2015 - The Loss Surfaces of Multilayer Networks.pdf:pdf},
isbn = {1412.0233},
issn = {15337928},
journal = {Aistats},
keywords = {Neural Network,Optimization},
pages = {192----204},
title = {{The Loss Surfaces of Multilayer Networks}},
url = {http://arxiv.org/abs/1412.0233{\%}5Cnhttp://www.arxiv.org/pdf/1412.0233.pdf},
volume = {38},
year = {2015}
}
@article{Leong2017,
abstract = {Little is known about the relationship between attention and learning during decision making. Us- ing eye tracking and multivariate pattern analysis of fMRI data, we measured participants' dimen- sional attention as they performed a trial-and-error learning task in which only one of three stimulus dimensions was relevant for reward at any given time. Analysis of participants' choices revealed that attention biased both value computation dur- ing choice and value update during learning. Value signals in the ventromedial prefrontal cortex and prediction errors in the striatum were similarly biased by attention. In turn, participants' focus of attention was dynamically modulated by ongoing learning. Attentional switches across dimensions correlated with activity in a frontoparietal attention network, which showed enhanced connectivity with the ventromedial prefrontal cortex between switches. Our results suggest a bidirectional inter- action between attention and learning: attention constrains learning to relevant dimensions of the environment, while we learn what to attend to via trial},
author = {Leong, Yuan Chang and Radulescu, Angela and Daniel, Reka and DeWoskin, Vivian and Niv, Yael},
doi = {10.1016/j.neuron.2016.12.040},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Leong et al. - 2017 - Dynamic Interaction between Reinforcement Learning and Attention in Multidimensional Environments.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = {jan},
number = {2},
pages = {451--463},
title = {{Dynamic Interaction between Reinforcement Learning and Attention in Multidimensional Environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089662731631039X},
volume = {93},
year = {2017}
}
@article{Moreno-Bote2014,
abstract = {Computational strategies used by the brain strongly depend on the amount of information that can be stored in population activity, which in turn strongly depends on the pattern of noise correlations. In vivo, noise correlations tend to be positive and proportional to the similarity in tuning properties. Such correlations are thought to limit information, which has led to the suggestion that decorrelation increases information. In contrast, we found, analytically and numerically, that decorrelation does not imply an increase in information. Instead, the only information-limiting correlations are what we refer to as differential correlations: correlations proportional to the product of the derivatives of the tuning curves. Unfortunately, differential correlations are likely to be very small and buried under correlations that do not limit information, making them particularly difficult to detect. We found, however, that the effect of differential correlations on information can be detected with relatively simple decoders.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.3159v1},
author = {Moreno-Bote, Rub{\'{e}}n and Beck, Jeffrey and Kanitscheider, Ingmar and Pitkow, Xaq and Latham, Peter and Pouget, Alexandre},
doi = {10.1038/nn.3807},
eprint = {arXiv:1411.3159v1},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Moreno-Bote et al. - 2014 - Information-limiting correlations(2).pdf:pdf},
isbn = {2010276795},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {1410--1417},
pmid = {25195105},
title = {{Information-limiting correlations}},
url = {https://www.nature.com/neuro/journal/v17/n10/pdf/nn.3807.pdf http://www.nature.com/doifinder/10.1038/nn.3807},
volume = {17},
year = {2014}
}
@book{Sutton1998,
abstract = {Norton, B., {\&} Toohey, K. (Eds). (2004). Critical pedagogies and language learning. New York: Cambridge University Press. (362pp).},
author = {Sutton, Richard S. and Barto, Andrew G.},
booktitle = {MIT Press},
isbn = {0262193981},
issn = {0959-4388},
pages = {331},
pmid = {7888773},
title = {{Reinforcement Learning: An Introduction}},
year = {1998}
}
@article{Law2008,
abstract = {... Neural correlates of perceptual learning in a sensory - motor but not a sensory cortical area . Chi-Tat Law and Joshua I. Gold. Department of Neuroscience, 116 Johnson Pavillion, 3610 Hamilton Walk, University of Pennsylvania ...},
author = {Law, Chi-Tat and Gold, Joshua I},
doi = {10.1038/nn2070},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Neural correlates of perceptual learning in a sensory- motor, but not a sensory, cortical area.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {4},
pages = {505--513},
pmid = {18327253},
title = {{Neural correlates of perceptual learning in a sensory-motor, but not a sensory, cortical area}},
url = {https://www.nature.com/neuro/journal/v11/n4/pdf/nn2070.pdf http://www.nature.com/doifinder/10.1038/nn2070},
volume = {11},
year = {2008}
}
@article{Macke2011,
abstract = {Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within a local network? We argue that in the cortex, where firing exhibits extensive corre- lations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model cap- tures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by compar- ing a latent dynamical model with realistic spiking observations to coupled gen- eralised linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms theGLMin terms of goodness-of- fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly better goodness-of-fit and more realistic population spike counts.},
author = {Macke, Jakob H and Buesing, Lars and Cunningham, John P and Yu, Byron M and Shenoy, Krishna V and Sahani, Maneesh},
doi = {10.1.1.230.7630},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Macke et al. - Unknown - Empirical models of spiking in neural populations.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems},
pages = {1350--1358},
title = {{Empirical models of spiking in neural populations}},
url = {http://videolectures.net/site/normal{\_}dl/tag=655498/nips2011{\_}buesing{\_}neural{\_}01.pdf{\%}5Cnhttp://books.nips.cc/papers/files/nips24/NIPS2011{\_}0781.pdf},
volume = {24},
year = {2011}
}
@article{Brown2016,
annote = {NULL},
author = {Brown, Jennifer and Martin, Kathleen A. and Dudman, Joshua},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/DCJ97RUG/090209.full.pdf:pdf},
journal = {bioRxiv},
pages = {090209},
title = {{Behavioral evidence for feedback gain control by the inhibitory microcircuit of the substantia nigra}},
url = {http://biorxiv.org/content/early/2016/11/28/090209.abstract http://www.biorxiv.org/content/biorxiv/early/2016/11/28/090209.full.pdf},
year = {2016}
}
@article{Hoyer,
abstract = {The responses of cortical sensory neurons are notoriously variable, with the number of spikes evoked by identical stimuli varying significantly from trial to trial. This variability is most often interpreted as ‘noise', purely detrimental to the sensory system. In this paper, we propose},
author = {Hoyer, Patrik O and Hyv{\"{a}}rinen, Aapo},
doi = {10.1.1.71.1731},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Hoyer, Hyv{\"{a}}rinen - Unknown - Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior.pdf:pdf},
journal = {Advances in neural information processing systems},
number = {1},
pages = {293--300},
title = {{Interpreting neural response variability as monte carlo sampling of the posterior}},
url = {http://www.cis.hut.fi/phoyer/},
year = {2003}
}
@article{Bannerman2012,
abstract = {The ability to associate locations with particular events is essential for the survival of all animals. It is widely believed that NMDAR-dependent synaptic plasticity contributes to the formation of associa-tive memories 1 , and hippocampal NMDARs, particularly those in the dorsal CA1, are thought to be important for associative, long-term spatial memory 2 , although their precise role remains unclear. Indeed, as recently noted, " even though the synaptic plasticity and memory hypothesis is enshrined in most neuroscience text books, this issue is still far from resolved " 3 . Pharmacological studies with NMDAR antagonists are equivocal 4–6 , and previous evidence from transgenic mice lacking NMDARs in dorsal CA1 (refs. 7,8) is confounded by the spread of NMDAR deletion to principal neurons in cortex, as shown in recent studies of this transgenic line 9–13 . Mice lacking NMDARs selectively in dentate gyrus granule cells, and hence long-term potentiation (LTP) in lateral and medial perforant path synapses, exhibit normal long-term spatial memory 14,15 . We have now generated mice (Grin1 ∆DGCA1) in which NMDARs are also lacking in dorsal and, to a lesser extent, ventral hippocampal CA1 pyramidal cells, specifically in adulthood, thus providing a new mouse model for assess-ing the hippocampal NMDAR and memory hypothesis. Here we investi-gated Grin1 ∆DGCA1 mice on tests of associative long-term spatial memory. Mice were assessed on reference memory versions of the water maze and radial maze tasks, which both depend on dorsal hippocampus 16–21 . RESULTS Dentate gyrus– and CA1-specific NMDAR deletion We used a mouse line (Grin1 ∆DGCA1 ; Fig. 1a) gene-targeted for loxP-tagged Grin1 alleles and carrying two transgenes, Tg LC1 and Tg CN12 , which enabled doxycycline (dox)-sensitive, Cre-mediated GluN1 ablation in excitatory hippocampal, but not cortical, neurons of adults 22,23 by use of a Camk2a promoter fused to a Grin2c silencer element 24 . Selective hippocampal NMDAR removal required switch-ing off Cre expression by dox during embryogenesis and nursing the pups with mothers taken off dox postnatally. Delayed Cre expression, detected 4 weeks after birth (Fig. 1b,c), eventually reached a peak in all dentate gyrus granule cells, whereas in CA1 a Cre expression gradi-ent formed along the dorso-ventral axis (Fig. 1d and Supplementary Fig. 1h). We assessed specificity of cumulative Cre expression by 5-bromo-4-chloro-3-indolyl-$\beta$-d-galactoside (X-gal) staining in double transgenic Cre indicator mice (Tg CN12 ; Tg LC1 ; Gt(ROSA)26Sor), which demonstrated strong Cre-induced $\beta$-galactosidase activity throughout the entire dentate gyrus and mossy fibers, as well as dorsal and, to a lesser extent, ventral CA1 (Fig. 1b,c and Supplementary Fig. 1d–g). All other parts of the hippocampal formation (CA3, lateral entorhinal cortex, medial entorhinal cortex, subiculum) exhibited neg-ligible recombination ({\textless}1{\%} co-labeling; Supplementary Fig. 1d–g), although $\beta$-galactosidase was observed in olfactory bulb granule cells and approximately 30{\%} of layer II piriform cortex neurons (Fig. 1b,c and Supplementary Fig. 1d). We confirmed efficient loss of Grin1 expression in dorsal CA1 and dentate gyrus by in situ hybridization, which also revealed reduced expression of the GluA1 AMPA receptor subunit gene Gria1 in the dentate gyrus granule cell layer (Fig. 1e and Supplementary Fig. 2). Further analysis indicated that in older mice the volume of the den-tate gyrus was reduced ({\~{}}50{\%} at age {\textgreater}1 year). NeuN, calbindin, glial fibrillary acidic protein (GFAP) and parvalbumin expression patterns showed that the upper blade of the dentate gyrus granule cell layer was more compromised than the lower blade, exhibiting},
author = {Bannerman, David M and Bus, Thorsten and Taylor, Amy and Sanderson, David J and Schwarz, Inna and Jensen, Vidar and Hvalby, {\O}ivind and Rawlins, J Nicholas P and Seeburg, Peter H and Sprengel, Rolf},
doi = {10.1038/nn.3166},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bannerman et al. - 2012 - Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jul},
number = {8},
pages = {1153--1159},
title = {{Dissecting spatial knowledge from spatial choice by hippocampal NMDA receptor deletion}},
url = {http://www.nature.com/doifinder/10.1038/nn.3166},
volume = {15},
year = {2012}
}
@article{Otazu,
abstract = {Although systems that are involved in attentional selection have been studied extensively, much less is known about nonselective systems. To study these preparatory mechanisms, we compared activity in auditory cortex that was elicited by sounds while rats performed an auditory task ('engaged') with activity that was elicited by identical stimuli while subjects were awake but not performing a task ('passive'). We found that engagement suppressed responses, an effect that was opposite in sign to that elicited by selective attention. In the auditory thalamus, however, engagement enhanced spontaneous firing rates but did not affect evoked responses. These results indicate that neural activity in auditory cortex cannot be viewed simply as a limited resource that is allocated in greater measure as the state of the animal passes from somnolent to passively listening to engaged and attentive. Instead, the engaged condition possesses a characteristic and distinct neural signature in which sound-evoked responses are paradoxically suppressed.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Otazu, Gonzalo H and Tai, Lung-Hao and Yang, Yang and Zador, Anthony M},
doi = {10.1038/nn.2306},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Otazu et al. - Unknown - Engaging in an auditory task suppresses responses in auditory cortex.pdf:pdf},
isbn = {1546-1726 (Electronic)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {5},
pages = {646--654},
pmid = {19363491},
title = {{Engaging in an auditory task suppresses responses in auditory cortex}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4084972/{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/19363491{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4084972{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nn.2306},
volume = {12},
year = {2009}
}
@article{Saxe2013,
abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
archivePrefix = {arXiv},
arxivId = {1312.6120},
author = {Saxe, Andrew M and McClelland, James L. and Ganguli, Surya},
eprint = {1312.6120},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2013 - Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.pdf:pdf},
isbn = {1312.6120},
journal = {CoRR},
pages = {1--22},
title = {{Exact solutions to the nonlinear dynamics of learning in deep linear neural networks}},
url = {https://arxiv.org/pdf/1312.6120.pdf http://arxiv.org/abs/1312.6120},
volume = {abs/1312.6},
year = {2013}
}
@article{Zhang2016,
abstract = {Synthesizing photo-realistic images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose stacked Generative Adversarial Networks (StackGAN) to generate photo-realistic images conditioned on text descriptions. The Stage-I GAN sketches the primitive shape and basic colors of the object based on the given text description, yielding Stage-I low resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high resolution images with photo-realistic details. The Stage-II GAN is able to rectify defects and add compelling details with the refinement process. Samples generated by StackGAN are more plausible than those generated by existing approaches. Importantly, our StackGAN for the first time generates realistic 256 x 256 images conditioned on only text descriptions, while state-of-the-art methods can generate at most 128 x 128 images. To demonstrate the effectiveness of the proposed StackGAN, extensive experiments are conducted on CUB and Oxford-102 datasets, which contain enough object appearance variations and are widely-used for text-to-image generation analysis.},
archivePrefix = {arXiv},
arxivId = {1612.03242},
author = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris},
eprint = {1612.03242},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2016 - StackGAN Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.pdf:pdf},
month = {dec},
title = {{StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1612.03242},
year = {2016}
}
@article{Churchland2010,
abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input.},
author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J. Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
doi = {10.1038/nn.2501},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Churchland et al. - 2010 - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {3},
pages = {369--378},
pmid = {20173745},
title = {{Stimulus onset quenches neural variability: a widespread cortical phenomenon}},
url = {http://dx.doi.org/10.1038/nn.2501},
volume = {13},
year = {2010}
}
@article{Ito,
abstract = {Reinforcement learning theory plays a key role in understanding the behavioral and neural mechanisms of choice behavior in animals and humans. Especially, intermediate variables of learning models estimated from behavioral data, such as the expectation of reward for each candidate choice (action value), have been used in searches for the neural correlates of computational elements in learning and decision making. The aims of the present study are as follows: (1) to test which computational model best captures the choice learning process in animals and (2) to elucidate how action values are represented in different parts of the corticobasal ganglia circuit. We compared different behavioral learning algorithms to predict the choice sequences generated by rats during a free-choice task and analyzed associated neural activity in the nucleus accumbens (NAc) and ventral pallidum (VP). The major findings of this study were as follows: (1) modified versions of an action–value learning model captured a variety of choice strategies of rats, including win-stay–lose-switch and persevering behavior, and predicted rats' choice sequences better than the best multistep Markov model; and (2) information about action values and future actions was coded in both the NAc and VP, but was less dominant than information about trial types, selected actions, and reward outcome. The results of our model-based analysis suggest that the primary role of the NAc and VP is to monitor information important for updating choice behaviors. Information represented in the NAc and VP might contribute to a choice mechanism that is situated elsewhere.},
author = {Ito, Makoto and Doya, Kenji},
doi = {10.1523/JNEUROSCI.6157-08.2009},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ito, Doya - Unknown - BehavioralSystemsCognitive Validation of Decision-Making Models and Analysis of Decision Variables in the Rat Basa.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {31},
pages = {9861--9874},
title = {{Validation of Decision-Making Models and Analysis of Decision Variables in the Rat Basal Ganglia}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.6157-08.2009},
volume = {29},
year = {2009}
}
@article{Sanchez-Vives2000,
abstract = {The neocortex generates periods of recurrent activity, such as the slow (0.1-0.5 Hz) oscillation during slow-wave sleep. Here we demonstrate that slices of ferret neocortex maintained in vitro generate this slow ({\textless} 1 Hz) rhythm when placed in a bathing medium that mimics the extracellular ionic composition in situ. This slow oscillation seems to be initiated in layer 5 as an excitatory interaction between pyramidal neurons and propagates through the neocortex. Our results demonstrate that the cerebral cortex generates an 'up' or depolarized state through recurrent excitation that is regulated by inhibitory networks, thereby allowing local cortical circuits to enter into temporarily activated and self-maintained excitatory states. The spontaneous generation and failure of this self-excited state may account for the generation of a subset of cortical rhythms during sleep.},
author = {Sanchez-Vives, Maria V and McCormick, David A},
doi = {10.1038/79848},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sanchez-Vives, McCormick - 2000 - Cellular and network mechanisms of rhythmic recurrent activity in neocortex.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {1027--1034},
pmid = {11017176},
title = {{Cellular and network mechanisms of rhythmic recurrent activity in neocortex.}},
volume = {3},
year = {2000}
}
@article{Merzenich1975,
abstract = {The representation of sound frequency (and of the cochlear partition) within primary auditory cortex has been investigated with use of microelectrode-mapping techniques in a series of 25 anesthetized cats. Among the results were the following: 1) Within vertical penetrations into AI, best frequency and remarkably constant for successively studied neurons across the active middle and deep cortical layers. 2) There is an orderly representation of frequency (and of represented cochlear place) within AI. Frequency is rerepresented across the mediolateral dimension of the field. On an axis perpendicular to this plane of rerepresentation, best-frequency (represented cochlear place) changes as a simple function of cortical location. 3) Any given frequency band (or sector of the cochlear partition) is represented across a belt of cortex of nearly constant width that runs on a nearly straight axis across AI. 4) There is a disproportionately large cortical surface representation of the highest-frequency octaves (basal cochlea) within AI. 5) The primary and secondary field locations were somewhat variable, when referenced to cortical surface landmarks. 6) Data from long penetrations passing down the rostral bank of the posterior ectosylvian sulcus were consistent with the existence of a vertical unit of organization in AI, akin to cortical columns described in primary visual and somatosensory cortex. 7) Responses to tonal stimuli were encountered in fields dorsocaudal, caudal, ventral, and rostral to AI. There is an orderly representation of the cochlea within the field rostal to AI, with a reversal in best frequencies across its border with AI. 8) Physiological definitions of AI boundaries are consistent with their cytoarchitectonic definition. Some of the implications of these findings are discussed.},
author = {Merzenich, M M and Knight, Paul L and Roth, G L},
doi = {10.1121/1.1920046},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Merzenich, Knight, Roth - 1975 - Representation of cochlea within primary auditory cortex in the cat.pdf:pdf},
isbn = {0022-3077 (Print)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
number = {2},
pages = {231--249},
pmid = {1092814},
title = {{Representation of cochlea within primary auditory cortex in the cat.}},
volume = {38},
year = {1975}
}
@article{Britten1996,
abstract = {We have previously documented the exquisite motion sensitivity of neurons in extrastriate area MT by studying the relationship between their responses and the direction and strength of visual motion signals delivered to their receptive fields. These results suggested that MT neurons might provide the signals supporting behavioral choice in visual discrimination tasks. To approach this question from another direction, we have now studied the relationship between the discharge of MT neurons and behavioral choice, independently of the effects of visual stimulation. We found that trial-to-trial variability in neuronal signals was correlated with the choices the monkey made. Therefore, when a directionally selective neuron in area MT fires more vigorously, the monkey is more likely to make a decision in favor of the preferred direction of the cell. The magnitude of the relationship was modest, on average, but was highly significant across a sample of 299 cells from four monkeys. The relationship was present for all stimuli (including those without a net motion signal), and for all but the weakest responses. The relationship was reduced or eliminated when the demands of the task were changed so that the directional signal carried by the cell was less informative. The relationship was evident within 50 ms of response onset, and persisted throughout the stimulus presentation. On average, neurons that were more sensitive to weak motion signals had a stronger relationship to behavior than those that were less sensitive. These observations are consistent with the idea that neuronal signals in MT are used by the monkey to determine the direction of stimulus motion. The modest relationship between behavioral choice and the discharge of any one neuron, and the prevalence of the relationship across the population, make it likely that signals from many neurons are pooled to form the data on which behavioral choices are based.},
author = {Britten, K. H. and Newsome, W. T. and Shadlen, M. N. and Celebrini, S. and Movshon, J. A.},
doi = {10.1017/S095252380000715X},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(17).pdf:pdf},
issn = {0952-5238},
journal = {Visual Neuroscience},
month = {jan},
number = {01},
pages = {87--100},
title = {{A relationship between behavioral choice and the visual responses of neurons in macaque MT}},
url = {http://www.journals.cambridge.org/abstract{\_}S095252380000715X},
volume = {13},
year = {1996}
}
@article{Ravbar2012,
abstract = {Exploratory variability is essential for sensorimotor learning, but it is not known how and at what timescales it is regulated. We manipulated song learning in zebra finches to experimentally control the requirements for vocal exploration in different parts of their song. We first trained birds to perform a one-syllable song, and once they mastered it, we added a new syllable to the song model. Remarkably, when practicing the modified song, birds rapidly alternated between high and low acoustic variability to confine vocal exploration to the newly added syllable. Furthermore, even within syllables, acoustic variability changed independently across song elements that were only milliseconds apart. Analysis of the entire vocal output during learning revealed that the variability of each song element decreased as it approached the target, correlating with momentary local distance from the target and less so with the overall distance within a syllable. We conclude that vocal error is computed locally in subsyllabic timescales and that song elements can be learned and crystallized independently. Songbirds have dedicated brain circuitry for vocal babbling in the anterior forebrain pathway (AFP), which generates exploratory song patterns that drive premotor neurons at the song nucleus RA. We hypothesize that either AFP adjusts the gain of vocal exploration in fine timescales or that the sensitivity of RA premotor neurons to AFP/HVC inputs varies across song elements.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ravbar, Primoz and Lipkind, Dina and Parra, Lucas C and Tchernichovski, Ofer},
doi = {10.1523/JNEUROSCI.3740-11.2012},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ravbar et al. - 2012 - Vocal exploration is locally regulated during song learning.pdf:pdf},
isbn = {0270-6474},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Animal,Animal: physiology,Animals,Female,Finches,Learning,Learning: physiology,Male,Prosencephalon,Prosencephalon: physiology,Vocalization},
number = {10},
pages = {3422--32},
pmid = {22399765},
title = {{Vocal exploration is locally regulated during song learning.}},
url = {http://www.jneurosci.org/content/jneuro/32/10/3422.full.pdf http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3312320{\&}tool=pmcentrez{\&}rendertype=abstract{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/22399765},
volume = {32},
year = {2012}
}
@article{Sadtler2014,
abstract = {Learning, whether motor, sensory or cognitive, requires networks of neurons to generate new activity patterns. As some behaviours are easier to learn than others, we asked if some neural activity patterns are easier to generate than others. Here we investigate whether an existing network constrains the patterns that a subset of its neurons is capable of exhibiting, and if so, what principles define this constraint. We employed a closed-loop intracortical brain-computer interface learning paradigm in which Rhesus macaques (Macaca mulatta) controlled a computer cursor by modulating neural activity patterns in the primary motor cortex. Using the brain-computer interface paradigm, we could specify and alter how neural activity mapped to cursor velocity. At the start of each session, we observed the characteristic activity patterns of the recorded neural population. The activity of a neural population can be represented in a high-dimensional space (termed the neural space), wherein each dimension corresponds to the activity of one neuron. These characteristic activity patterns comprise a low-dimensional subspace (termed the intrinsic manifold) within the neural space. The intrinsic manifold presumably reflects constraints imposed by the underlying neural circuitry. Here we show that the animals could readily learn to proficiently control the cursor using neural activity patterns that were within the intrinsic manifold. However, animals were less able to learn to proficiently control the cursor using activity patterns that were outside of the intrinsic manifold. These results suggest that the existing structure of a network can shape learning. On a timescale of hours, it seems to be difficult to learn to generate neural activity patterns that are not consistent with the existing network structure. These findings offer a network-level explanation for the observation that we are more readily able to learn new skills when they are related to the skills that we already possess.},
annote = {NULL},
author = {Sadtler, Patrick T and Quick, Kristin M and Golub, Matthew D and Chase, Steven M and Ryu, Stephen I and Tyler-Kabara, Elizabeth C and Yu, Byron M and Batista, Aaron P},
doi = {10.1038/nature13665},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sadtler et al. - 2014 - Neural constraints on learning(2).pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
keywords = {Animals,Brain-Computer Interfaces,Computers,Learning,Learning: physiology,Macaca mulatta,Male,Models,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,Motor Skills,Motor Skills: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology},
number = {7515},
pages = {423--426},
pmid = {25164754},
title = {{Neural constraints on learning}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4393644{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {512},
year = {2014}
}
@article{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard to compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories form taking much computation time.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.1901v1},
author = {Neal, Radford M.},
doi = {10.1201/b10905},
eprint = {arXiv:1206.1901v1},
isbn = {978-1-4200-7941-8},
issn = {{\textless}null{\textgreater}},
journal = {Handbook of Markov Chain Monte Carlo},
keywords = {hamiltonian dynamics,mcmc},
pages = {113--162},
pmid = {25246403},
title = {{Handbook of Markov Chain Monte Carlo}},
url = {http://www.crcnetbase.com/doi/book/10.1201/b10905},
volume = {20116022},
year = {2011}
}
@article{Dai,
abstract = {In the classic Bayesian restless multi-armed bandit (RMAB) prob-lem, there are N arms, with rewards on all arms evolving at each time as Markov chains with known parameters. A player seeks to activate K ≥ 1 arms at each time in order to maximize the expected total reward obtained over multiple plays. RMAB is a challenging problem that is known to be PSPACE-hard in general. We consider in this work the even harder non-Bayesian RMAB, in which the pa-rameters of the Markov chain are assumed to be unknown a priori. We develop an original approach to this problem that is applicable when the corresponding Bayesian problem has the structure that, de-pending on the known parameter values, the optimal solution is one of a prescribed finite set of policies. In such settings, we propose to learn the optimal policy for the non-Bayesian RMAB by employing a suitable meta-policy which treats each policy from this finite set as an arm in a different non-Bayesian multi-armed bandit problem for which a single-arm selection policy is optimal. We demonstrate this approach by developing a novel sensing policy for opportunistic spectrum access over unknown dynamic channels. We prove that our policy achieves near-logarithmic regret (the difference in expected reward compared to a model-aware genie), which leads to the same average reward that can be achieved by the optimal policy under a known model. This is the first such result in the literature for a non-Bayesian RMAB.},
author = {Dai, Wenhan and Gai, Yi and Krishnamachari, Bhaskar and Zhao, Qing and Hsieh, Ming},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Dai et al. - Unknown - THE NON-BAYESIAN RESTLESS MULTI-ARMED BANDIT A CASE OF NEAR-LOGARITHMIC REGRET.pdf:pdf},
keywords = {Index Terms— restless bandit,learning,non-Bayesian,opportunistic spectrum access,regret},
title = {{THE NON-BAYESIAN RESTLESS MULTI-ARMED BANDIT: A CASE OF NEAR-LOGARITHMIC REGRET}}
}
@article{Woolley2014,
abstract = {SUMMARY Context dependence is a key feature of cortical-basal ganglia circuit activity, and in songbirds the cortical outflow of a basal ganglia circuit specialized for song, LMAN, shows striking increases in trial-by-trial variability and bursting when birds sing alone rather than to females. To reveal where this variability and its social regulation emerge, we recorded step-wise from corticostriatal (HVC) neurons and their target spiny and pallidal neurons in Area X. We find that corticostriatal and spiny neurons both show precise singing-related firing across both social set-tings. Pallidal neurons, in contrast, exhibit markedly increased trial-by-trial variation when birds sing alone, created by highly variable pauses in firing. This variability persists even when recurrent inputs from LMAN are ablated. These data indicate that variability and its context sensitivity emerge within the basal ganglia network, suggest a network mech-anism for this emergence, and highlight variability generation and regulation as basal ganglia functions.},
author = {Woolley, Sarah C and Rajan, Raghav and Joshua, Mati and Doupe, Allison J},
doi = {10.1016/j.neuron.2014.01.039},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(2).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf},
journal = {Neuron},
keywords = {basal ganglia,hvc,lman,songbird,variability},
mendeley-tags = {basal ganglia,hvc,lman,songbird,variability},
pages = {208--223},
title = {{Emergence of Context-Dependent Variability across a Basal Ganglia Network}},
url = {http://dx.doi.org/10.1016/j.neuron.2014.01.039},
volume = {82},
year = {2014}
}
@article{Choromanska2014,
abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural net-work and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural net-work through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest crit-ical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local min-ima outside that band diminishes exponen-tially with the size of the network. We empir-ically verify that the mathematical model ex-hibits similar behavior as the computer sim-ulations, despite the presence of high depen-dencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large-and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Choromanska et al. - 2015 - The Loss Surfaces of Multilayer Networks.pdf:pdf},
journal = {arXiv preprint arXiv:},
title = {{The loss surfaces of multilayer networks}},
url = {http://arxiv.org/abs/1412.0233},
volume = {38},
year = {2014}
}
@article{Deisenroth2011,
author = {Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
doi = {10.1561/2300000021},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Deisenroth, Neumann, Peters - 2011 - A Survey on Policy Search for Robotics(3).pdf:pdf},
journal = {Foundations and Trends R in Robotics},
keywords = {Artificial Intelligence in Robotics,Markov Decision Processes,Planning and Control,Policy Search},
pages = {1--2},
title = {{A Survey on Policy Search for Robotics}},
volume = {2},
year = {2011}
}
@article{Ohyama2001,
abstract = {Evidence indicates that rabbit eyelid conditioning is mediated by plasticity in the interpositus cerebellar nucleus and in cerebellar cortex. Although the relative contributions of these sites are not fully characterized, evidence suggests that plasticity in the cerebellar cortex influences conditioned response amplitude and timing, whereas plasticity in the interpositus nucleus is necessary or permissive for conditioned response expression. Recent empirical and computational analyses suggest that, during training, plasticity is initially established in the cerebellar cortex, whereas conditioned response expression begins later as plasticity is induced in the interpositus nucleus. We used the dependence of response timing on the interstimulus interval (ISI) to test this latent learning hypothesis. Rabbits were initially trained using a tone conditioned stimulus (CS) with a relatively long ISI to a low-criterion threshold. The relative absence of plasticity in the interpositus nucleus was then examined via reversible disconnection of the cerebellar cortex. Later, to induce plasticity in the interpositus nucleus, subjects were trained to robust levels of conditioned response expression using a shorter ISI. Reversible disconnection of the cerebellar cortex at this time confirmed the presence of robust interpositus nucleus plasticity after the second phase. Subsequent probe trials with the long CS alone then revealed double-peaked responses whose peaks were appropriately timed to the two ISIs. The results are consistent with the hypothesis that temporally specific learning occurs first in the cerebellar cortex before the appearance of conditioned responses. This latent learning is expressed only after plasticity is induced in the interpositus nucleus.},
author = {Ohyama, Tatsuya and Mauk, M},
doi = {21/2/682 [pii]},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ohyama, Mauk - 2001 - Latent acquisition of timed responses in cerebellar cortex.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {cerebellar cortex,eyelid conditioning,interposi-tus nucleus,latent learning,learning,plasticity,response timing},
number = {2},
pages = {682--90},
pmid = {11160447},
title = {{Latent acquisition of timed responses in cerebellar cortex.}},
volume = {21},
year = {2001}
}
@article{Elstrott2008,
abstract = {Direction selectivity in the retina requires the asymmetric wiring of inhibitory inputs onto four subtypes of On-Off direction-selective ganglion cells (DSGCs), each preferring motion in one of four cardinal directions. The primary model for the development of direction selectivity is that patterned activity plays an instructive role. Here, we use a unique, large-scale multielectrode array to demonstrate that DSGCs are present at eye opening, in mice that have been reared in darkness and in mice that lack cholinergic retinal waves. These data suggest that direction selectivity in the retina is established largely independent of patterned activity and is therefore likely to emerge as a result of complex molecular interactions. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
annote = {NULL},
author = {Elstrott, Justin and Anishchenko, Anastasia and Greschner, Martin and Sher, Alexander and Litke, Alan M. and Chichilnisky, E.J. and Feller, Marla B.},
doi = {10.1016/j.neuron.2008.03.013},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/4UCNHD4A/S0896-6273(08)00259-6.pdf:pdf},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {CELLBIO,MOLNEURO,SYSNEURO,development,direction selectivity,mouse,retina},
language = {en},
mendeley-tags = {development,direction selectivity,mouse,retina},
month = {may},
number = {4},
pages = {499--506},
pmid = {18498732},
title = {{Direction Selectivity in the Retina Is Established Independent of Visual Experience and Cholinergic Retinal Waves}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627308002596 http://www.cell.com/neuron/pdf/S0896-6273(08)00259-6.pdf},
volume = {58},
year = {2008}
}
@article{Jia2014,
abstract = {Sensory information reaches the cortex through synchronously active thalamic axons, which provide a strong drive to layer 4 (L4) cortical neurons. Because of technical limitations, the dendritic signaling processes underlying the rapid and efficient activation of L4 neurons in vivo remained unknown. Here we introduce an approach that allows the direct monitoring of single dendritic spine Ca(2+) signals in L4 spiny stellate cells of the vibrissal mouse cortex in vivo. Our results demonstrate that activation of N-methyl-D-aspartate (NMDA) receptors is required for sensory-evoked action potential (AP) generation in these neurons. By analyzing NMDA receptor-mediated Ca(2+) signaling, we identify whisker stimulation-evoked large responses in a subset of dendritic spines. These sensory-stimulation-activated spines, representing predominantly thalamo-cortical input sites, were denser at proximal dendritic regions. The amplitude of sensory-evoked spine Ca(2+) signals was independent of the activity of neighboring spines, without evidence for cooperativity. Furthermore, we found that spine Ca(2+) signals evoked by back-propagating APs sum linearly with sensory-evoked synaptic Ca(2+) signals. Thus, our results identify in sensory information-receiving L4 cortical neurons a linear mode of dendritic integration that underlies the rapid and reliable transfer of peripheral signals to the cortical network.},
author = {Jia, Hongbo and Varga, Zsuzsanna and Sakmann, Bert and Konnerth, Arthur},
doi = {10.1073/pnas.1408525111},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Jia et al. - 2014 - Linear integration of spine Ca2 signals in layer 4 cortical neurons in vivo(2).pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {barrel cortex,layer 4 stellate cells,thalamo-cortical transmission,two-photon imaging},
month = {jun},
number = {25},
pages = {9277--82},
pmid = {24927564},
publisher = {National Academy of Sciences},
title = {{Linear integration of spine Ca2+ signals in layer 4 cortical neurons in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24927564 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4078833},
volume = {111},
year = {2014}
}
@article{Brunton2012,
author = {Brunton, B. W. and Botvinick, M. M. and Brody, C. D.},
doi = {10.1126/science.1233912},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Brunton, Botvinick, Brody - 2013 - Rats and Humans Can Optimally Accumulate Evidence for Decision-Making.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science},
month = {apr},
number = {6128},
pages = {95--98},
pmid = {23559253},
title = {{Rats and Humans Can Optimally Accumulate Evidence for Decision-Making}},
url = {www.sciencemag.org/cgi/content/full/340/6128/91/DC1 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3887341{\&}tool=pmcentrez{\&}rendertype=abstract http://www.sciencemag.org/cgi/doi/10.1126/science.1233912},
volume = {340},
year = {2013}
}
@article{Harris2011,
abstract = {The brain continuously adapts its processing machinery to behavioural demands. To achieve this, it rapidly modulates the operating mode of cortical circuits, controlling the way that information is transformed and routed. This article will focus on two experimental approaches by which the control of cortical information processing has been investigated: the study of state-dependent cortical processing in rodents and attention in the primate visual system. Both processes involve a modulation of low-frequency activity fluctuations and spiking correlation, and are mediated by common receptor systems. We suggest that selective attention involves processes that are similar to state change, and that operate at a local columnar level to enhance the representation of otherwise non-salient features while suppressing internally generated activity patterns.},
annote = {This paper, as a whole, pre-empts the locking to population rate that is described in the Okun paper.},
author = {Harris, Kenneth D and Thiele, Alexander},
doi = {10.1038/nrn3084},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Harris, Thiele - 2011 - Cortical state and attention.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {9},
pages = {509--523},
pmid = {21829219},
title = {{Cortical state and attention}},
url = {https://www.nature.com/nrn/journal/v12/n9/pdf/nrn3084.pdf http://www.nature.com/doifinder/10.1038/nrn3084},
volume = {12},
year = {2011}
}
@article{Huber2012a,
abstract = {The mechanisms linking sensation and action during learning are poorly understood. Layer 2/3 neurons in the motor cortex might participate in sensorimotor integration and learning; they receive input from sensory cortex and excite deep layer neurons, which control movement. Here we imaged activity in the same set of layer 2/3 neurons in the motor cortex over weeks, while mice learned to detect objects with their whiskers and report detection with licking. Spatially intermingled neurons represented sensory (touch) and motor behaviours (whisker movements and licking). With learning, the population-level representation of task-related licking strengthened. In trained mice, population-level representations were redundant and stable, despite dynamism of single-neuron representations. The activity of a subpopulation of neurons was consistent with touch driving licking behaviour. Our results suggest that ensembles of motor cortex neurons couple sensory input to multiple, related motor programs during learning.},
annote = {NULL},
author = {Huber, D and Gutnisky, D A and Peron, S and O'Connor, D. H. and Wiegert, J S and Tian, L and Oertner, T G and Looger, L L and Svoboda, Karel},
doi = {10.1038/nature11039},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Huber et al. - 2012 - Multiple dynamic representations in the motor cortex during sensorimotor learning(2).pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
keywords = {active whisker control,barrel cortex,mouse,whisker system},
number = {7395},
pages = {473--478},
pmid = {22538608},
title = {{Multiple dynamic representations in the motor cortex during sensorimotor learning}},
url = {http://www.nature.com/nature/journal/v484/n7395/pdf/nature11039.pdf http://dx.doi.org/10.1038/nature11039},
volume = {484},
year = {2012}
}
@article{Truccoloa,
abstract = {Multiple factors simultaneously affect the spiking activity of individual neurons. Determining the effects and relative importance of these factors is a challenging problem in neurophysiology. We propose a statistical framework based on the point process likelihood function to relate a neuron's spiking probability to three typical covariates: the neuron's own spiking history, concurrent ensemble activity, and extrinsic covariates such as stimuli or behavior. The framework uses parametric models of the conditional intensity function to define a neuron's spiking probability in terms of the covariates. The discrete time likelihood function for point processes is used to carry out model fitting and model analysis. We show that, by modeling the logarithm of the conditional intensity function as a linear combination of functions of the covariates, the discrete time point process likelihood function is readily analyzed in the generalized linear model (GLM) framework. We illustrate our approach for both GLM and non-GLM likelihood functions using simulated data and multivariate single-unit activity data simultaneously recorded from the motor cortex of a monkey performing a visuomotor pursuit-tracking task. The point process framework provides a flexible, computationally efficient approach for maximum likelihood estimation, goodness-of-fit assessment, residual analysis, model selection, and neural decoding. The framework thus allows for the formulation and analysis of point process models of neural spiking activity that readily capture the simultaneous effects of multiple covariates and enables the assessment of their relative importance.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Truccolo, Wilson},
doi = {10.1152/jn.00697.2004},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Truccolo et al. - Unknown - A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble, and Extr.pdf:pdf},
isbn = {0022-3077 (Print)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {2},
pages = {1074--1089},
pmid = {15356183},
title = {{A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble, and Extrinsic Covariate Effects}},
url = {http://jn.physiology.org/content/jn/93/2/1074.full.pdf http://jn.physiology.org/cgi/doi/10.1152/jn.00697.2004},
volume = {93},
year = {2004}
}
@article{RoianEgnor2016,
abstract = {In this review, we discuss the emerging field of computational behavioral analysis—the use of modern methods from computer science and engineering to quantitatively measure animal behavior. We discuss aspects of experiment design important to both obtaining biologically relevant behavioral data and enabling the use of machine vision and learning techniques for automation. These two goals are often in conflict. Restraining or restricting the environment of the animal can simplify automatic behavior quantification, but it can also degrade the quality or alter important aspects of behavior. To enable biologists to design experiments to obtain better behavioral measurements, and computer scientists to pinpoint fruitful directions for algorithm improvement, we review known effects of artificial manipulation of the animal on behavior. We also review machine vision and learning techniques for tracking, feature extraction, automated behavior classification, and automated behavior discovery, the assumptions they m...},
author = {Egnor, S.E. Roian and Branson, Kristin},
doi = {10.1146/annurev-neuro-070815-013845},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Egnor, Branson - 2016 - Computational Analysis of Behavior.pdf:pdf},
isbn = {9780879698171},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {animal behavior,automated behavioral analysis,computer vision,machine learning,tracking},
number = {1},
pages = {217--236},
pmid = {27090952},
title = {{Computational Analysis of Behavior}},
url = {http://www.annualreviews.org/doi/pdf/10.1146/annurev-neuro-070815-013845 http://www.annualreviews.org/doi/10.1146/annurev-neuro-070815-013845},
volume = {39},
year = {2016}
}
@article{Curto,
abstract = {The responses of neocortical cells to sensory stimuli are variable and state dependent. It has been hypothesized that intrinsic cortical dynamics play an important role in trial-to-trial variability; the precise nature of this dependence, however, is poorly understood. We show here that in auditory cortex of urethane-anesthetized rats, population responses to click stimuli can be quantitatively predicted on a trial-by-trial basis by a simple dynamical system model estimated from spontaneous activity immediately preceding stimulus presentation. Changes in cortical state correspond consistently to changes in model dynamics, reflecting a nonlinear, self-exciting system in synchronized states and an approximately linear system in desynchronized states. We propose that the complex and state-dependent pattern of trial-to-trial variability can be explained by a simple principle: sensory responses are shaped by the same intrinsic dynamics that govern ongoing spontaneous activity.},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Curto, Carina and Sakata, Shuzo and Marguet, Stephan and Itskov, Vladimir and Harris, Kenneth D},
doi = {10.1523/JNEUROSCI.2053-09.2009},
eprint = {1309.2848v1},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Curto et al. - Unknown - BehavioralSystemsCognitive A Simple Model of Cortical Dynamics Explains Variability and State Dependence of Sen.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {J. Neurosci.},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Anesthetics,Animals,Auditory,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: drug effects,Auditory Cortex: physiology,Auditory: physiology,Electric Stimulation,Electric Stimulation: methods,Evoked Potentials,Intravenous,Intravenous: pharmacology,Models,Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: drug effects,Neurons: physiology,Nonlinear Dynamics,Pedunculopontine Tegmental Nucleus,Pedunculopontine Tegmental Nucleus: physiology,Rats,Sprague-Dawley,Urethane,Urethane: pharmacology},
number = {34},
pages = {10600--10612},
pmid = {19710313},
title = {{A simple model of cortical dynamics explains variability and state-dependence of sensory responses in urethane-anesthetized auditory cortex}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2861166{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {29},
year = {2009}
}
@article{Vinyals,
abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6{\%} to 93.2{\%} and from 88.0{\%} to 93.8{\%} on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Vinyals, Blundell, Lillicrap - 2016 - Matching networks for one shot learning.pdf:pdf},
journal = {Advances In Neural},
title = {{Matching networks for one shot learning}},
url = {http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning},
year = {2016}
}
@article{Williamson2016,
abstract = {Sensory neurons are customarily characterized by one or more linearly weighted receptive fields describing sensitivity in sensory space and time. We show that in auditory cortical and thalamic neurons, the weight of each receptive field element depends on the pattern of sound falling within a local neighborhood surrounding it in time and frequency. Accounting for this change??in effective receptive field with spectrotemporal context improves predictions of both cortical and thalamic responses to stationary??complex sounds. Although context dependence varies among neurons and across brain areas, there are strong shared qualitative characteristics. In a spectrotemporally rich soundscape, sound elements modulate neuronal responsiveness more effectively when they coincide with sounds at other frequencies,??and less effectively when they are preceded by sounds at similar frequencies. This local-context-driven lability in the representation of complex sounds???a modulation of ???input-specific gain??? rather than ???output gain??????may be a widespread motif in sensory processing.},
author = {Williamson, Ross S and Ahrens, Misha B and Linden, Jennifer F and Sahani, Maneesh},
doi = {10.1016/j.neuron.2016.05.041},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Williamson et al. - 2016 - Input-Specific Gain Modulation by Local Sensory Context Shapes Cortical and Thalamic Responses to Complex Sou.pdf:pdf},
issn = {10974199},
journal = {Neuron},
number = {2},
pages = {467--481},
pmid = {27346532},
title = {{Input-Specific Gain Modulation by Local Sensory Context Shapes Cortical and Thalamic Responses to Complex Sounds}},
url = {http://www.cell.com/neuron/pdfExtended/S0896-6273(16)30252-5},
volume = {91},
year = {2016}
}
@article{Donahue,
abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing generators learn to " linearize semantics " in the latent space of such models. Intuitively, such latent spaces may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping – projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
author = {Donahue, Jeff and Kr{\"{a}}henb{\"{u}}hl, Philipp and Darrell, Trevor},
title = {{ADVERSARIAL FEATURE LEARNING}}
}
@article{Turaga,
abstract = {Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thou- sands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as fitting a latent dynamical sys- tem with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate us- ing recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs.},
author = {Turaga, S and Buesing, Lars and Packer, Adam M and Dalgleish, Henry and Pettit, Noah and Hausser, M and Macke, J},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Turaga et al. - 2013 - Inferring neural population dynamics from multiple partial recordings of the same neural circuit.pdf:pdf},
isbn = {978-1-63266-024-4},
issn = {10495258},
journal = {Neural Information Processing Systems},
pages = {1--9},
title = {{Inferring neural population dynamics from multiple partial recordings of the same neural circuit}},
year = {2013}
}
@article{Rota,
author = {Rota, Gian-Carlo},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Rota - Unknown - Ten Lessons I Wish I Had Been Taught.pdf:pdf},
title = {{Ten Lessons I Wish I Had Been Taught}},
url = {http://www.ams.org/notices/199701/comm-rota.pdf}
}
@article{Doucet2011,
abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented.},
annote = {NULL},
author = {Doucet, Arnaud and Johansen, Adam M},
doi = {10.1.1.157.772},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Doucet, Johansen - 2011 - A Tutorial on Particle filtering and smoothing Fiteen years later.pdf:pdf},
isbn = {978-0199532902},
issn = {01677152},
journal = {The Oxford handbook of nonlinear filtering},
keywords = {Central Limit Theorem,Filtering,Hidden Markov Models,Markov chain Monte Carlo,Particle methods,Resampling,Sequential Monte Carlo,Smoothing,State-Space models},
number = {December 2008},
pages = {656--705},
title = {{A Tutorial on Particle filtering and smoothing: Fiteen years later}},
url = {http://www.stats.ox.ac.uk/{~}doucet/doucet{\_}johansen{\_}tutorialPF2011.pdf http://webcat.warwick.ac.uk/record=b2490036{~}S1},
year = {2011}
}
@book{McCullagh1989,
abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and other applications.The authors focus on examining the way a response variable depends on a combination of explanatory variables, treatment, and classification variables. They give particular emphasis to the important case where the dependence occurs through some unknown, linear combination of the explanatory variables.The Second Edition includes topics added to the core of the first edition, including conditional and marginal likelihood methods, estimating equations, and models for dispersion effects and components of dispersion. The discussion of other topics-log-linear and related models, log odds-ratio regression models, multinomial response models, inverse linear and related models, quasi-likelihood functions, and model checking-was expanded and incorporates significant revisions.Comprehension of the material requires simply a knowledge of matrix theory and the basic ideas of probability theory, but for the most part, the book is self-contained. Therefore, with its worked examples, plentiful exercises, and topics of direct use to researchers in many disciplines, Generalized Linear Models serves as ideal text, self-study guide, and reference.},
author = {McCullagh, P.N.J.A. and Nelder, J.A.},
booktitle = {CRC Press Vol. 37},
doi = {10.1007/978-1-4899-3242-6},
isbn = {978-0412317606},
issn = {1098-6596},
pages = {1--514},
pmid = {25246403},
title = {{Generalized Linear Models}},
year = {1989}
}
@article{Rabinowitz2015,
abstract = {Responses of sensory neurons represent stimulus information, but are also influenced by internal state. For example, when monkeys direct their attention to a visual stimulus, the response gain of specific subsets of neurons in visual cortex changes. Here, we develop a functional model of population activity to investigate the structure of this effect. We fit the model to the spiking activity of bilateral neural populations in area V4, recorded while the animal performed a stimulus discrimination task under spatial attention. The model reveals four separate time-varying shared modulatory signals, the dominant two of which each target task-relevant neurons in one hemisphere. In attention-directed conditions, the associated shared modulatory signal decreases in variance. This finding provides an interpretable and parsimonious explanation for previous observations that attention reduces variability and noise correlations of sensory neurons. Finally, the recovered modulatory signals reflect previous reward, and are predictive of choice behavior.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rabinowitz, Neil C. and Goris, Robbe L. and Cohen, Marlene and Simoncelli, Eero P.},
doi = {10.7554/eLife.08998},
eprint = {arXiv:1011.1669v3},
file = {:Users/Yves/Downloads/elife-08998-v3.pdf:pdf},
isbn = {9780874216561},
issn = {2050084X},
journal = {eLife},
number = {NOVEMBER2015},
pages = {1--24},
pmid = {26523390},
title = {{Attention stabilizes the shared gain of V4 populations}},
volume = {4},
year = {2015}
}
@article{Haefner2013,
abstract = {The activity of cortical neurons in sensory areas covaries with perceptual decisions, a relationship that is often quantified by choice probabilities. Although choice probabilities have been measured extensively, their interpretation has remained fraught with difficulty. We derive the mathematical relationship between choice probabilities, read-out weights and correlated variability in the standard neural decision-making model. Our solution allowed us to prove and generalize earlier observations on the basis of numerical simulations and to derive new predictions. Notably, our results indicate how the read-out weight profile, or decoding strategy, can be inferred from experimentally measurable quantities. Furthermore, we developed a test to decide whether the decoding weights of individual neurons are optimal for the task, even without knowing the underlying correlations. We confirmed the practicality of our approach using simulated data from a realistic population model. Thus, our findings provide a theoretical foundation for a growing body of experimental results on choice probabilities and correlations.},
author = {Haefner, Ralf M and Gerwinn, Sebastian and Macke, Jakob H and Bethge, Matthias},
doi = {10.1038/nn.3309},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Haefner et al. - 2013 - Inferring decoding strategies from choice probabilities in the presence of correlated variability(3).pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {2},
pages = {235--242},
pmid = {23313912},
title = {{Inferring decoding strategies from choice probabilities in the presence of correlated variability}},
url = {http://www.nature.com/doifinder/10.1038/nn.3309},
volume = {16},
year = {2013}
}
@article{Lubke,
abstract = {Cortical columns are the functional units of the neocortex that are particularly prominent in the " barrel " field of the somatosensory cortex. Here we describe the morphology of two classes of synaptically coupled excitatory neurons in layer 4 of the barrel cortex, spiny stellate, and star pyramidal cells, respectively. Within a single barrel, their somata tend to be organized in clusters. The dendritic arbors are largely confined to layer 4, except for the distal part of the apical dendrite of star pyramidal neurons that extends into layer 2/3. In contrast, the axon of both types of neurons spans the cortex from layer 1 to layer 6. The most prominent axonal projections are those to layers 4 and 2/3 where they are largely restricted to a single cortical column. In layers 5 and 6, a small fraction of axon collaterals projects also across cortical columns. Consistent with the dense axonal pro-jection to layers 4 and 2/3, the total number and density of boutons per unit axonal length was also highest there. Electron microscopy combined with GABA postimmunogold labeling re-vealed that most (Ͼ90{\%}) of the synaptic contacts were estab-lished on dendritic spines and shafts of excitatory neurons in layers 4 and 2/3. The largely columnar organization of dendrites and axons of both cell types, combined with the preferential and dense pro-jections within cortical layers 4 and 2/3, suggests that spiny stellate and star pyramidal neurons of layer 4 serve to amplify thalamic input and relay excitation vertically within a single cor-tical column.},
author = {L{\"{u}}bke, Joachim and Egger, Veronica and Sakmann, Bert and Feldmeyer, Dirk},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/L{\"{u}} Bke et al. - Unknown - Columnar Organization of Dendrites and Axons of Single and Synaptically Coupled Excitatory Spiny Neurons in L.pdf:pdf},
keywords = {axonal projection,barrel cortex,cortical column,intracellular labeling,layer 4,paired record-ings,spiny stellate cell,star pyra-midal neuron},
title = {{Columnar Organization of Dendrites and Axons of Single and Synaptically Coupled Excitatory Spiny Neurons in Layer 4 of the Rat Barrel Cortex}}
}
@misc{CenterforHistoryandNewMedia,
annote = {Welcome to Zotero!View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.Thanks for installing Zotero.},
author = {{Center for History and New Media}},
title = {{Zotero Quick Start Guide}},
url = {http://zotero.org/support/quick{\_}start{\_}guide}
}
@book{Owen2013a,
annote = {NULL},
author = {Owen, Art B},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Owen - 2013 - Monte Carlo theory, methods and examples.pdf:pdf},
keywords = {Importance Sampling,Monte Carlo},
mendeley-tags = {Importance Sampling,Monte Carlo},
title = {{Monte Carlo theory, methods and examples}},
url = {http://statweb.stanford.edu/{~}owen/mc/Ch-var-is.pdf},
year = {2013}
}
@article{Katagiri2007,
abstract = {Local GABAergic circuits trigger visual cortical plasticity in early postnatal life. How these diverse connections contribute to critical period onset was investigated by nonstationary fluctuation analysis following laser photo-uncaging of GABA onto discrete sites upon individual pyramidal cells in slices of mouse visual cortex. The GABAA receptor number decreased on the soma-proximal dendrite (SPD), but not at the axon initial segment, with age and sensory deprivation. Benzodiazepine sensitivity was also higher on the immature SPD. Too many or too few SPD receptors in immature or dark-reared mice, respectively, were adjusted to critical period levels by benzodiazepine treatment in vivo, which engages ocular dominance plasticity in these animal models. Combining GAD65 deletion with dark rearing from birth confirmed that an intermediate number of SPD receptors enable plasticity. Site-specific optimization of perisomatic GABA response may thus trigger experience-dependent development in visual cortex. ?? 2007 Elsevier Inc. All rights reserved.},
annote = {NULL},
author = {Katagiri, Hiroyuki and Fagiolini, Michela and Hensch, Takao K.},
doi = {10.1016/j.neuron.2007.02.026},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/AA6TIAS5/S0896-6273(07)00146-8.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {DEVBIO,PROTEINS,SYSNEURO,critical period,development,inhibition},
language = {en},
mendeley-tags = {critical period,development,inhibition},
month = {mar},
number = {6},
pages = {805--812},
pmid = {17359916},
title = {{Optimization of Somatic Inhibition at Critical Period Onset in Mouse Visual Cortex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627307001468 http://www.cell.com/neuron/pdf/S0896-6273(07)00146-8.pdf},
volume = {53},
year = {2007}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
eprint = {1312.5602},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Chen2011,
author = {Chen, Xiaowei and Leischner, Ulrich and Rochefort, Nathalie L. and Nelken, Israel and Konnerth, Arthur},
doi = {10.1038/nature10193},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Chen et al. - 2011 - Functional mapping of single spines in cortical neurons in vivo.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {jun},
number = {7357},
pages = {501--505},
publisher = {Nature Research},
title = {{Functional mapping of single spines in cortical neurons in vivo}},
url = {http://www.nature.com/doifinder/10.1038/nature10193},
volume = {475},
year = {2011}
}
@article{Abbott1997,
abstract = {Cortical neurons receive synaptic inputs from thousands of afferents that fire action potentials at rates ranging from less than 1 hertz to more than 200 hertz. Both the number of afferents and their large dynamic range can mask changes in the spatial and temporal pattern of synaptic activity, limiting the ability of a cortical neuron to respond to its inputs. Modeling work based on experimental measurements indicates that short-term depression of intracortical synapses provides a dynamic gain-control mechanism that allows equal percentage rate changes on rapidly and slowly firing afferents to produce equal postsynaptic responses. Unlike inhibitory and adaptive mechanisms that reduce responsiveness to all inputs, synaptic depression is input-specific, leading to a dramatic increase in the sensitivity of a neuron to subtle changes in the firing patterns of its afferents.},
author = {Abbott, L F and Varela, J A and Sen, K and Nelson, S B},
doi = {10:275(5297):220-4},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bruick et al. - 2001 - References and Notes.pdf:pdf},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = {jan},
number = {5297},
pages = {220--4},
pmid = {8985017},
title = {{Synaptic depression and cortical gain control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8985017},
volume = {275},
year = {1997}
}
@article{Clements1997,
abstract = {Spontaneous synaptic events can be difficult to detect when their amplitudes are close to the background noise level. Here we report a sensitive new technique for automatic detection of small asynchronous events. A waveform with the time course of a typical synaptic event (a template) is slid along the current or voltage trace and optimally scaled to fit the data at each position. A detection criterion is calculated based on the optimum scaling factor and the quality of the fit. An event is detected when this criterion crosses a threshold level. The algorithm automatically compensates for changes in recording noise. The sensitivity and selectivity of the method were tested using real and simulated data, and the influence of the template parameter settings was investigated. Its performance was comparable to that obtained by visual event detection, and it was more sensitive than previously described threshold detection techniques. Under typical recording conditions, all fast synaptic events with amplitudes of at least three times the noise standard deviation (3 sigma) could be detected, as could 75{\%} of events with amplitudes of 2 sigma. The scaled template technique is implemented within a commercial data analysis application and can be applied to many standard electrophysiological data file formats.},
author = {Clements, J D and Bekkers, J M},
doi = {10.1016/S0006-3495(97)78062-7},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Clements, Bekkers - 1997 - Detection of spontaneous synaptic events with an optimally scaled template.pdf:pdf},
isbn = {0006-3495 (Print)},
issn = {0006-3495},
journal = {Biophysical journal},
keywords = {Animals,Computer Simulation,Dentate Gyrus,Dentate Gyrus: physiology,Electric Stimulation,Evoked Potentials,Evoked Potentials: physiology,Hippocampus,Hippocampus: physiology,In Vitro Techniques,Models,Neurological,Rats,Software,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Wistar},
number = {1},
pages = {220--9},
pmid = {9199786},
title = {{Detection of spontaneous synaptic events with an optimally scaled template.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1180923{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {73},
year = {1997}
}
@article{Schwartz,
abstract = {We describe a form of nonlinear decomposition that is well-suited for efficient encoding of natural signals. Signals are initially decomposed using a bank of linear filters. Each filter response is then rectified and divided by a weighted sum of rectified responses of neighboring filters. We show that this decomposition, with parameters optimized for the statistics of a generic ensemble of natural images or sounds, provides a good characterization of the nonlinear response properties of typical neurons in primary visual cortex or auditory nerve, respectively. These results suggest that nonlinear response properties of sensory neurons are not an accident of biological implementation, but have an important functional role.},
author = {Schwartz, Odelia and Simoncelli, Eero P},
doi = {10.1038/90526},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Schwartz, Simoncelli - Unknown - Natural signal statistics and sensory gain control.pdf:pdf},
isbn = {1097-6256 (Print)},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Perception,Auditory Perception: physiology,Central Nervous System,Central Nervous System: physiology,Cochlear Nerve,Cochlear Nerve: physiology,Data Interpretation,Macaca,Macaca: anatomy {\&} histology,Macaca: physiology,Models,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Photic Stimulation,Reaction Time,Reaction Time: physiology,Saimiri,Saimiri: anatomy {\&} histology,Saimiri: physiology,Sensation,Sensation: physiology,Signal Transduction,Signal Transduction: physiology,Statistical,Synaptic Transmission,Synaptic Transmission: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {8},
pages = {819--25},
pmid = {11477428},
title = {{Natural signal statistics and sensory gain control.}},
url = {http://www.nature.com/neuro/journal/v4/n8/pdf/nn0801{\_}819.pdf http://www.ncbi.nlm.nih.gov/pubmed/11477428},
volume = {4},
year = {2001}
}
@article{Sober,
abstract = {The brain uses sensory feedback to correct behavioral errors. Larger errors by definition require greater corrections, and many models of learning assume that larger sensory feedback errors drive larger motor changes. However, an alternative perspective is that larger errors drive learning less effectively because such errors fall outside the range of errors normally experienced and are therefore unlikely to reflect accurate feedback. This is especially crucial in vocal control because auditory feedback can be contaminated by environmental noise or sensory processing errors. A successful control strategy must therefore rely on feedback to correct errors while disregarding aberrant auditory signals that would lead to maladaptive vocal corrections. We hypothesized that these constraints result in compensation that is greatest for smaller imposed errors and least for larger errors. To test this hypothesis, we manipulated the pitch of auditory feedback in singing Bengalese finches. We found that learning driven by larger sensory errors was both slower than that resulting from smaller errors and showed less complete compensation for the imposed error. Additionally, we found that a simple principle could account for these data: the amount of compensation was proportional to the overlap between the baseline distribution of pitch production and the distribution experienced during the shift. Correspondingly, the fraction of compensation approached zero when pitch was shifted outside of the song's baseline pitch distribution. Our data demonstrate that sensory errors drive learning best when they fall within the range of production variability, suggesting that learning is constrained by the statistics of sensorimotor experience.},
author = {Sober, Samuel J and Brainard, Michael S},
doi = {10.1073/pnas.1213622109},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sober, Brainard - 2012 - Vocal learning is constrained by the statistics of sensorimotor experience.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$n0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Acoustic Stimulation,Acoustics,Animal,Animals,Auditory Perception,Feedback,Finches,Finches: physiology,Learning,Male,Models,Motor Skills,Pitch Perception,Reproducibility of Results,Sensory,Singing,Statistical,Vocalization,Voice},
number = {51},
pages = {21099--103},
pmid = {23213223},
title = {{Vocal learning is constrained by the statistics of sensorimotor experience.}},
url = {http://www.pnas.org/content/109/51/21099.full.pdf http://www.pnas.org/cgi/content/long/109/51/21099},
volume = {109},
year = {2012}
}
@article{Pitkow2015a,
abstract = {Single sensory neurons can be surprisingly predictive of behavior in discrimination tasks. We propose this ispossible because sensory information extracted from neural populations is severely restricted, either by near-optimal decoding of a population with information-limiting correlations or by suboptimal decoding that is blind to correlations. These have different consequences for choice correlations, the correlations between neural responses and behavioral choices. In the vestibular and cerebellar nuclei and the dorsal medial superior temporal area, we found that choice correlations during heading discrimination are consistent with near-optimal decoding ofneuronal responses corrupted by information-limiting correlations. In the ventral intraparietal area, the choice correlations are also consistent with the presence of information-limiting correlations, but this area does not appear to influence behavior, although the choice correlations are particularly large. These findings demonstrate how choice correlations can be used to assess the efficiency of the downstream readout and detect the presence of information-limiting correlations. The activity of just one sensory neuron in the brain often accurately predicts what an animal will perceive in simple tests. Pitkow etal. provide a new theory of why this happens, and offer experimental data that support their theory.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Pitkow, Xaq and Liu, Sheng and Angelaki, Dora E and DeAngelis, Gregory C. and Pouget, Alexandre},
doi = {10.1016/j.neuron.2015.06.033},
eprint = {15334406},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pitkow et al. - 2015 - How Can Single Sensory Neurons Predict Behavior(3).pdf:pdf;:Users/Yves/Downloads/mmc1 (22).pdf:pdf},
isbn = {doi:10.1016/j.neuron.2015.06.033},
issn = {10974199},
journal = {Neuron},
number = {2},
pages = {411--424},
pmid = {26182422},
title = {{How Can Single Sensory Neurons Predict Behavior?}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.06.033},
volume = {87},
year = {2015}
}
@article{Dayan2000,
abstract = {Selective attention involves the differential processing of different stimuli, and has widespread psychological and neural consequences. Although computational modeling should offer a powerful way of linking observable phenomena at different levels, most work has focused on the relatively narrow issue of constraints on processing resources. By contrast, we consider statistical and informational aspects of selective attention, divorced from resource constraints, which are evident in animal conditioning experiments involving uncertain predictions and unreliable stimuli. Neuromodulatory systems and limbic structures are known to underlie attentional effects in such tasks.},
author = {Dayan, Peter and Kakade, Sham and Montague, P. Read},
doi = {10.1038/81504},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Dayan, Kakade, Montague - 2000 - Learning and selective attention.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature neuroscience},
month = {nov},
number = {november},
pages = {1218--1223},
pmid = {11127841},
title = {{Learning and selective attention.}},
url = {http://www.nature.com/neuro/journal/v3/n11s/abs/nn1100{\_}1218.html http://www.nature.com/doifinder/10.1038/81504},
volume = {3 Suppl},
year = {2000}
}
@article{Soares2016,
abstract = {Time is a subjective experience
Time, like space, is one of the fundamental dimensions of all our experiences. However, organisms do not work like clocks, and our judgment about the passage of time is variable, depending on circumstances. Soares et al. systematically investigated midbrain dopaminergic neurons during timing behavior in mice (see the Perspective by Simen and Matell). When measuring and manipulating mouse activity, the authors observed that dopaminergic neurons controlled temporal judgments on a time scale of seconds.
Science, this issue p. 1273; see also p. 1231
Our sense of time is far from constant. For instance, time flies when we are having fun, and it slows to a trickle when we are bored. Midbrain dopamine neurons have been implicated in variable time estimation. However, a direct link between signals carried by dopamine neurons and temporal judgments is lacking. We measured and manipulated the activity of dopamine neurons as mice judged the duration of time intervals. We found that pharmacogenetic suppression of dopamine neurons decreased behavioral sensitivity to time and that dopamine neurons encoded information about trial-to-trial variability in time estimates. Last, we found that transient activation or inhibition of dopamine neurons was sufficient to slow down or speed up time estimation, respectively. Dopamine neuron activity thus reflects and can directly control the judgment of time.
Mouse studies suggest that higher dopaminergic brain activity is associated with a subjective slowing down of time.
Mouse studies suggest that higher dopaminergic brain activity is associated with a subjective slowing down of time.},
annote = {NULL},
author = {Soares, Sofia and Atallah, Bassam V. and Paton, Joseph J.},
doi = {10.1126/science.aah5234},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/47EUN396/Soares et al. - 2016 - Midbrain dopamine neurons control judgment of time.pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/FF96I63V/1273.html:html},
isbn = {1095-9203 (Electronic) 0036-8075 (Linking)},
issn = {0036-8075, 1095-9203},
journal = {Science},
keywords = {dopamine,timing},
language = {en},
mendeley-tags = {dopamine,timing},
month = {dec},
number = {6317},
pages = {1273--1277},
pmid = {26393431},
title = {{Midbrain dopamine neurons control judgment of time}},
url = {http://science.sciencemag.org/content/354/6317/1273 http://science.sciencemag.org/content/sci/354/6317/1273.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/27940870},
volume = {354},
year = {2016}
}
@article{Chapman1993,
abstract = {The orientation selectivity of cells in ferret primary visual cortex was studied during normal development and in animals deprived of vision or of visual cortical activity. In normal animals from the age when visual responses were first recorded (postnatal day 23) through postnatal week 5, only about 25{\%} of cells showed orientation-selective responses. By postnatal week 7, cortical responses had matured to an adult-like state, with approximately 75{\%} of cells clearly selective for orientation. This development of orientation selectivity was not merely a reflection of the development of cortical cell responsiveness: at all ages studied, there was no correlation between responsiveness and selectivity. Infusion of TTX into visual cortex to silence neuronal activity completely blocked the maturation of orientation selectivity. Visual deprivation by bilateral lid suture impaired but did not completely block the normal development of orientation selectivity. We conclude that the maturation of orientation-selective responses in ferret primary visual cortex requires cortical neuronal activity, and that normal development requires visually driven activity.},
annote = {NULL},
author = {Chapman, B. and Stryker, M. P.},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/QMXWKU5E/Chapman and Stryker - 1993 - Development of orientation selectivity in ferret v.pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/QB9B44IR/5251.html:html},
isbn = {0270-6474 (Print) 0270-6474 (Linking)},
issn = {0270-6474, 1529-2401},
journal = {Journal of Neuroscience},
keywords = {activity,column,development,direction selectivity,ferret,orientation,orientation selectivity,plasticity,privation,ttx,visual de-},
language = {en},
mendeley-tags = {development,direction selectivity,ferret,orientation selectivity},
month = {dec},
number = {12},
pages = {5251--5262},
pmid = {8254372},
title = {{Development of orientation selectivity in ferret visual cortex and effects of deprivation}},
url = {http://www.jneurosci.org/content/13/12/5251 http://www.jneurosci.org/content/jneuro/13/12/5251.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/8254372},
volume = {13},
year = {1993}
}
@article{Deisenroth2011,
author = {Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
doi = {10.1561/2300000021},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Deisenroth, Neumann, Peters - 2011 - A Survey on Policy Search for Robotics(3).pdf:pdf},
journal = {Foundations and Trends R in Robotics},
keywords = {Artificial Intelligence in Robotics,Markov Decision Processes,Planning and Control,Policy Search},
pages = {1--2},
title = {{A Survey on Policy Search for Robotics}},
volume = {2},
year = {2011}
}
@article{Greene2016,
abstract = {The optimal foraging strategy in a given environment depends on the number of competing individuals and their behavioural strategies. Little is known about the genes and neural circuits that integrate social information into foraging decisions. Here we show that ascaroside pheromones, small glycolipids that signal population density, suppress exploratory foraging in Caenorhabditis elegans, and that heritable variation in this behaviour generates alternative foraging strategies. We find that natural C. elegans isolates differ in their sensitivity to the potent ascaroside icas{\#}9 (IC-asc-C5). A quantitative trait locus (QTL) regulating icas{\#}9 sensitivity includes srx-43, a G-protein-coupled icas{\#}9 receptor that acts in the ASI class of sensory neurons to suppress exploration. Two ancient haplotypes associated with this QTL confer competitive growth advantages that depend on ascaroside secretion, its detection by srx-43 and the distribution of food. These results suggest that balancing selection at the srx-43 locus generates alternative density-dependent behaviours, fulfilling a prediction of foraging game theory.},
author = {Greene, Joshua S and Brown, Maximillian and Dobosiewicz, May and Ishida, Itzel G and Macosko, Evan Z and Zhang, Xinxing and Butcher, Rebecca A and Cline, Devin J and McGrath, Patrick T and Bargmann, Cornelia I},
doi = {10.1038/nature19848},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7628},
pages = {254--258},
pmid = {27799655},
title = {{Balancing selection shapes density-dependent foraging behaviour}},
url = {http://dx.doi.org/10.1038/nature19848{\%}5Cnhttp://10.0.4.14/nature19848{\%}5Cnhttp://www.nature.com/nature/journal/v539/n7628/abs/nature19848.html{\#}supplementary-information},
volume = {539},
year = {2016}
}
@article{Poddar2013,
abstract = {Addressing the neural mechanisms underlying complex learned behaviors requires training animals in well-controlled tasks, an often time-consuming and labor-intensive process that can severely limit the feasibility of such studies. To overcome this constraint, we developed a fully computer-controlled general purpose system for high-throughput training of rodents. By standardizing and automating the implementation of predefined training protocols within the animal's home-cage our system dramatically reduces the efforts involved in animal training while also removing human errors and biases from the process. We deployed this system to train rats in a variety of sensorimotor tasks, achieving learning rates comparable to existing, but more laborious, methods. By incrementally and systematically increasing the difficulty of the task over weeks of training, rats were able to master motor tasks that, in complexity and structure, resemble ones used in primate studies of motor sequence learning. By enabling fully automated training of rodents in a home-cage setting this low-cost and modular system increases the utility of rodents for studying the neural underpinnings of a variety of complex behaviors.},
author = {Poddar, Rajesh and Kawai, Risa and {\"{O}}lveczky, Bence P},
doi = {10.1371/journal.pone.0083171},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Poddar et al. - 2013 - A Fully Automated High-Throughput Training System for Rodents.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pmid = {24349451},
title = {{A fully automated high-throughput training system for rodents}},
volume = {8},
year = {2013}
}
@article{Stephens2008,
abstract = {A major challenge in analyzing animal behavior is to discover some underlying simplicity in complex motor actions. Here, we show that the space of shapes adopted by the nematode Caenorhabditis elegans is low dimensional, with just four dimensions accounting for 95{\%} of the shape variance. These dimensions provide a quantitative description of worm behavior, and we partially reconstruct "equations of motion" for the dynamics in this space. These dynamics have multiple attractors, and we find that the worm visits these in a rapid and almost completely deterministic response to weak thermal stimuli. Stimulus-dependent correlations among the different modes suggest that one can generate more reliable behaviors by synchronizing stimuli to the state of the worm in shape space. We confirm this prediction, effectively "steering" the worm in real time.},
archivePrefix = {arXiv},
arxivId = {arXiv:0705.1548v1},
author = {Stephens, Greg J and Johnson-Kerner, Bethany and Bialek, William and Ryu, William S},
doi = {10.1371/journal.pcbi.1000028},
eprint = {arXiv:0705.1548v1},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Stephens et al. - 2008 - Dimensionality and dynamics in the behavior of C. elegans.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {4},
pmid = {18389066},
title = {{Dimensionality and dynamics in the behavior of C. elegans}},
url = {https://www.princeton.edu/{~}wbialek/our{\_}papers/stephens+al{\_}08a.pdf},
volume = {4},
year = {2008}
}
@article{Martinez,
abstract = {Recent research suggests the brain can learn almost any brain computer interface (BCI) configuration, however contrasting behavioral evidence from structural learning theory argues that previous experience facilitates-or impedes-future learning. An article by Sadtler and colleagues (Nature, 512(7515):423-426) uses BCI to demonstrate that neural network structural characteristics constrain learning, a finding that might also provide insight into how the brain responds to and recovers after injury.},
author = {Martinez, Clarisa and Wang, Chunji},
doi = {10.1152/jn.00971.2014},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Martinez, Wang - Unknown - Structural constraints on learning in the neural network.pdf:pdf},
issn = {1522-1598},
journal = {Journal of Neurophysiology},
pages = {jn.00971.2014},
pmid = {25810487},
title = {{Structural constraints on learning in the neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25810487},
year = {2015}
}
@article{Huber2012,
abstract = {The mechanisms linking sensation and action during learning are poorly understood. Layer 2/3 neurons in the motor cortex might participate in sensorimotor integration and learning; they receive input from sensory cortex and excite deep layer neurons, which control movement. Here we imaged activity in the same set of layer 2/3 neurons in the motor cortex over weeks, while mice learned to detect objects with their whiskers and report detection with licking. Spatially intermingled neurons represented sensory (touch) and motor behaviours (whisker movements and licking). With learning, the population-level representation of task-related licking strengthened. In trained mice, population-level representations were redundant and stable, despite dynamism of single-neuron representations. The activity of a subpopulation of neurons was consistent with touch driving licking behaviour. Our results suggest that ensembles of motor cortex neurons couple sensory input to multiple, related motor programs during learning.},
author = {Huber, D and Gutnisky, D A and Peron, S and O'Connor, D. H. and Wiegert, J S and Tian, L and Oertner, T G and Looger, L L and Svoboda, Karel},
doi = {10.1038/nature11039},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Huber et al. - 2012 - Multiple dynamic representations in the motor cortex during sensorimotor learning(2).pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
keywords = {active whisker control,barrel cortex,mouse,whisker system},
number = {7395},
pages = {473--478},
pmid = {22538608},
title = {{Multiple dynamic representations in the motor cortex during sensorimotor learning}},
url = {http://dx.doi.org/10.1038/nature11039},
volume = {484},
year = {2012}
}
@article{Gu2015,
abstract = {Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterised proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterisations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a neural network-based deep recurrent generative model achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.},
archivePrefix = {arXiv},
arxivId = {1506.03338},
author = {Gu, Shixiang and Ghahramani, Zoubin and Turner, Richard E},
eprint = {1506.03338},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Gu, Ghahramani, Turner - Unknown - Neural Adaptive Sequential Monte Carlo.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1--10},
title = {{Neural Adaptive Sequential Monte Carlo}},
url = {https://papers.nips.cc/paper/5961-neural-adaptive-sequential-monte-carlo.pdf http://arxiv.org/abs/1506.03338},
year = {2015}
}
@article{Goldberg,
abstract = {Young songbirds produce vocal "babbling," and the variability of their songs is thought to underlie a process of trial-and-error vocal learning. It is known that this exploratory variability requires the "cortical" component of a basal ganglia (BG) thalamocortical loop, but less understood is the role of the BG and thalamic components in this behavior. We found that large bilateral lesions to the songbird BG homolog Area X had little or no effect on song variability during vocal babbling. In contrast, lesions to the BG-recipient thalamic nucleus DLM (medial portion of the dorsolateral thalamus) largely abolished normal vocal babbling in young birds and caused a dramatic increase in song stereotypy. These findings support the idea that the motor thalamus plays a key role in the expression of exploratory juvenile behaviors during learning.},
author = {Goldberg, Jesse H and Fee, Michale S},
doi = {10.1152/jn.00823.2010},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Goldberg, Fee - 2011 - Vocal babbling in songbirds requires the basal ganglia-recipient motor thalamus but not the basal ganglia.pdf:pdf},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Animal,Animal: physiology,Animals,Basal Ganglia,Basal Ganglia: drug effects,Basal Ganglia: physiology,Brain Mapping,Finches,Male,N-Methylaspartate,N-Methylaspartate: analogs {\&} derivatives,N-Methylaspartate: toxicity,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Sound Localization,Sound Localization: physiology,Thalamus,Thalamus: cytology,Thalamus: drug effects,Thalamus: physiology,Vocalization},
number = {6},
pages = {2729--39},
pmid = {21430276},
title = {{Vocal babbling in songbirds requires the basal ganglia-recipient motor thalamus but not the basal ganglia.}},
url = {http://jn.physiology.org/content/jn/105/6/2729.full.pdf http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3118735{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2011}
}
@article{Gilra2017,
abstract = {Brains need to predict how our muscles and body react to motor commands. How networks of spiking neurons can learn to reproduce these non-linear dynamics, using local, online and stable learning rules, is an important, open question. Here, we present a supervised learning scheme for the feedforward and recurrent connections in a network of heterogeneous spiking neurons. The error in the output is fed back through fixed random connections with a negative gain, causing the network to follow the desired dynamics, while an online and local rule changes the weights; hence we call the scheme FOLLOW (Feedback-based Online Local Learning Of Weights) The rule is local in the sense that weight changes depend on the presynaptic activity and the error signal projected onto the post-synaptic neuron. We provide examples of learning linear, non-linear and chaotic dynamics, as well as the dynamics of a two-link arm. Using the Lyapunov method, and under reasonable assumptions and approximations, we show that FOLLOW learning is uniformly stable, with the error going to zero asymptotically.},
archivePrefix = {arXiv},
arxivId = {1702.06463},
author = {Gilra, Aditya and Gerstner, Wulfram},
eprint = {1702.06463},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Gilra, Gerstner - Unknown - Predicting non-linear dynamics a stable local learning scheme for recurrent spiking neural networks.pdf:pdf},
title = {{Predicting non-linear dynamics: a stable local learning scheme for recurrent spiking neural networks}},
url = {http://arxiv.org/abs/1702.06463},
year = {2017}
}
@article{Marcos2016,
abstract = {We studied how cortical circuits combine new information with ongoing activity dynamics as mice accumulated visual evidence for decision-making in a virtual-navigation task. As single trials unfolded, the posterior parietal cortex (PPC) transitioned rapidly between distinguishable activity patterns made up of mostly different sets of active neurons. Using new methods to analyze population activity dynamics, we found that each event in a trial — whether an evidence cue or a behavioral choice — caused seconds-long modifications to the probabilities that govern how one activity pattern transitions to the next, forming a short-term memory. A sequence of evidence cues triggered a chain of these modifications from which a signal for accumulated evidence emerged. Multiple distinguishable activity patterns were possible for the same level of accumulated evidence because representations of ongoing events were influenced by the sequence of previous within and across trial events. Our results indicate that evidence accumulation need not require the explicit competition between groups of neurons, as in winner-take-all models. Instead, we propose evidence accumulation emerges implicitly from general dynamical properties of the PPC that instantiate short-term memory. 2 Introduction The activity patterns in a cortical microcircuit are determined both by the characteristics of the external inputs it receives and the dynamic, ongoing changes in its internal activity state. Combining ongoing activity with new inputs is essential for many complex neural computations, including evidence accumulation during decision-making. Much work has focused on identifying the neuronal algorithms and mechanisms by which evidence accumulation occurs 1,2 . Considerable focus has been placed on the posterior parietal cortex (PPC) 3-7 , which is thought to be necessary for the accumulation of visual evidence in rodents 8 . Previous work has emphasized a conceptual model in which evidence accumulation occurs as a winner-take-all competition between neuronal activity patterns associated with different decisions 2,9 . This view predicts that as evidence is accumulated, activity converges to one of several attractor states, with each possible decision associated with a different attractor. Winner-take-all dynamics have commonly been implemented as a highly structured competition between distinct recurrently connected pools of neurons with mutual inhibition across pools 10-12 . These features lead to long-lasting firing rate changes in individual neurons that are homogeneous within a pool. Although this implementation is supported by some experimental data 3-7,13 , recent work showing the prevalence of time-varying activity patterns in neuronal populations 14-18 provides initial suggestions of potential alternatives. For example, alternate implementations of winner-take-all competitions could also be possible, such as competitions between sequences of population activity. Or, entirely different algorithms for evidence accumulation might be present that do not require winner-take-all mechanisms. The study of evidence accumulation has in part been restricted in two important ways. First, the experimental methods available to study neuronal activity during evidence accumulation have been limited. Previous work has in large part emphasized independent recordings from selected subsets of individual neurons, typically summarized as averages across trials and cells. However, because animals make decisions on single trials, the study of neuronal population activity dynamics on a moment-by-moment basis could be essential for uncovering the key underlying neuronal mechanisms. Second, models proposing mechanisms other than winner-take-all competitions have not emerged, such that much recent work has focused on examining possible implementations of winner-take-all models instead of testing the overarching algorithms for evidence accumulation.},
author = {Marcos, Ari S. and Harvey, Christorpher D},
doi = {10.1038/nn.4403},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature neuroscience},
month = {oct},
number = {12},
pages = {1672--1680},
pmid = {27694990},
publisher = {Nature Research},
title = {{History-dependent variability in population dynamics during evidence accumulation in cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.4403},
volume = {19},
year = {2016}
}
@article{Geramifard2013,
author = {Geramifard, Alborz and Walsh, Thomas J and Tellex, Stefanie and Chowdhary, Girish and Roy, Nicholas and How, Jonathan P},
doi = {10.1561/2200000042},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Geramifard et al. - 2013 - A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning.pdf:pdf},
journal = {Foundations and Trends R in Machine Learning},
number = {4},
pages = {375--454},
title = {{A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning}},
volume = {6},
year = {2013}
}
@article{Linderman2017,
abstract = {Computational neuroscience is, to first order, dominated by two approaches: the " bottom-up " approach, which searches for statistical patterns in large-scale neural record-ings, and the " top-down " approach, which begins with a theory of computation and considers plausible neural implementations. While this division is not clear-cut, we argue that these approaches should be much more intimately linked. From a Bayesian perspective, computational theories provide constrained prior distributions on neural data—albeit highly sophisticated ones. By connecting theory to observation via a proba-bilistic model, we provide the link necessary to test, evaluate, and revise our theories in a data-driven and statistically rigorous fashion. This review highlights examples of this theory-driven pipeline for neural data analysis in recent literature and illustrates it with a worked example based on the temporal difference learning model of dopamine.},
author = {Linderman, Scott W and Gershman, Samuel J},
doi = {10.1101/104737},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Linderman, Gershman - 2017 - Using computational theory to constrain statistical models of neural data A Theory-driven Pipeline for Neur.pdf:pdf},
pages = {1--14},
title = {{Using computational theory to constrain statistical models of neural data A Theory-driven Pipeline for Neural Data Analysis}},
year = {2017}
}
@article{Buesing2011,
abstract = {The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.},
author = {Buesing, Lars and Bill, Johannes and Nessler, Bernhard and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1002211},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Buesing et al. - 2011 - Neural Dynamics as Sampling A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$n1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pmid = {22096452},
title = {{Neural dynamics as sampling: A model for stochastic computation in recurrent networks of spiking neurons}},
url = {http://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1002211{\&}type=printable},
volume = {7},
year = {2011}
}
@article{Mynarski2017,
abstract = {Interaction with the world requires an organism to transform sensory signals into repre-sentations in which behaviorally meaningful properties of the environment are made explicit. These representations are derived through cascades of neuronal processing stages in which neurons at each stage recode the output of preceding stages. Explanations of sensory cod-ing may thus involve understanding how low-level patterns are combined into more complex structures. Although models exist in the visual domain to explain how mid-level features such as junctions and curves might be derived from oriented filters in early visual cortex, lit-tle is known about analogous grouping principles for mid-level auditory representations. We propose a hierarchical generative model of natural sounds that learns combinations of spec-trotemporal features from natural stimulus statistics. In the first layer the model forms a sparse convolutional code of spectrograms using a dictionary of learned spectrotemporal ker-nels. To generalize from specific kernel activation patterns, the second layer encodes patterns of time-varying magnitude of multiple first layer coefficients. Because second-layer features are sensitive to combinations of spectrotemporal features, the representation they support en-codes more complex acoustic patterns than the first layer. When trained on corpora of speech and environmental sounds, some second-layer units learned to group spectrotemporal features that occur together in natural sounds. Others instantiate opponency between dissimilar sets of spectrotemporal features. Such groupings might be instantiated by neurons in the auditory cortex, providing a hypothesis for mid-level neuronal computation.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1701.07138v2},
author = {M{\l}ynarski, Wiktor and Mcdermott, Josh H},
eprint = {1701.07138v2},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/M{\l}ynarski, Mcdermott - 2017 - Learning Mid-Level Auditory Codes from Natural Sound Statistics.pdf:pdf},
title = {{Learning Mid-Level Auditory Codes from Natural Sound Statistics}},
url = {https://arxiv.org/pdf/1701.07138.pdf},
year = {2017}
}
@article{Cruikshank,
abstract = {The thalamus provides fundamental input to the neocortex. This input activates inhibitory interneurons more strongly than excitatory neurons, triggering powerful feedforward inhibition. We studied the mechanisms of this selective neuronal activation using a mouse somatosensory thalamocortical preparation. Notably, the greater responsiveness of inhibitory interneurons was not caused by their distinctive intrinsic properties but was instead produced by synaptic mechanisms. Axons from the thalamus made stronger and more frequent excitatory connections onto inhibitory interneurons than onto excitatory cells. Furthermore, circuit dynamics allowed feedforward inhibition to suppress responses in excitatory cells more effectively than in interneurons. Thalamocortical excitatory currents rose quickly in interneurons, allowing them to fire action potentials before significant feedforward inhibition emerged. In contrast, thalamocortical excitatory currents rose slowly in excitatory cells, overlapping with feedforward inhibitory currents that suppress action potentials. These results demonstrate the importance of selective synaptic targeting and precise timing in the initial stages of neocortical processing. The neocortex, which comprises the majority of the mammalian brain, is critical for sensation, perception, goal-directed behavior and cogni-tion 1 . It contains two general classes of neurons: excitatory cells that release the neurotransmitter glutamate and inhibitory interneurons that release the neurotransmitter GABA. Subsets of both types of cells are directly innervated by excitatory thalamic relay neurons, which are the main source of extrinsic input to the neocortex. Curiously, inhibitory interneurons respond much more strongly than excitatory cells to thalamic input 2–5 . These interneurons, in turn, synapse locally in the neocortex, producing robust feedforward inhibition in the same cells that receive direct thalamocortical excitation 6–11 . Although the consequences of feedforward inhibition have been extensively consid-ered 12–14 , little is known about the mechanisms of the strong inter-neuron activation that produces it. Obviously, understanding how both inhibitory and excitatory neurons in the neocortex respond to their principle external input is an essential step in understanding sensory information processing and perhaps other neocortex-depen-dent processes such as perception and cognition. Here we demonstrate that the greater thalamocortical activation of inhibitory interneurons, compared with excitatory cells, is mediated by differences in their synaptic mechanisms, rather than their intrinsic membrane properties. The synaptic mechanisms include differences in the strength of direct thalamocortical excitation and the effectiveness of disynaptic feedforward inhibition. The latter is not due to a simple difference in inhibitory synaptic strength, but instead to dynamic properties of the cortical microcircuits, arising from cell type–specific differences in the relative kinetics of excitatory and inhibitory synaptic currents. RESULTS To test the mechanisms of thalamocortical responsiveness, we used an in vitro preparation, from mouse brain, that has intact connections between primary somatosensory thalamus and cortex (that is, ventro-basal thalamus (VB) and barrel cortex) 15 . We stimulated the VB with extracellular electrodes and recorded evoked responses simultaneously from pairs of layer 4 cells located in an aligned cortical barrel (Methods, Fig. 1a). Each pair consisted of one fast-spiking inhibitory interneuron (FS cell) and one regular-spiking excitatory neuron (RS cell), both of which received direct (monosynaptic) thalamic input (Methods and Fig. 1 and Supplementary Fig. 1 online) 3,8,10 . We chose closely spaced FS and RS cells (o50-mm separation) to ensure localization within common thalamocortical arbors. Initially, responses were recorded in a cell-attached configuration, so that the cell membrane and cytoplasm would remain intact. In pairs studied this way, thalamic stimuli usually evoked action potential responses in the FS cell (20/30 pairs), but rarely evoked action potentials in the RS cell (1/30 pairs), confirming and extending previous studies (Fig. 1b) 3,9,11 . In principle, the greater propensity of FS cells to spike in response to thalamic stimulation could have been due to differences in intrinsic membrane properties, synaptic mechanisms or both. In regard to intrinsic membrane properties, we hypothesized that FS cells would be more responsive if the difference between their resting potential and spike threshold was smaller than that of RS cells 16,17 . Whole-cell current clamp measurements showed, however, that the voltage differences between rest and threshold were not different for FS versus RS cells (Fig. 1c,d; P ¼ 0.182, paired t-test; FS resting ¼ –78.0 ± 0.8 mV, FS threshold ¼ –48.8 ± 0.4 mV; RS resting ¼ –79.3 ± 1.3 mV,},
author = {Cruikshank, Scott J and Lewis, Timothy J and Connors, Barry W},
doi = {10.1038/nn1861},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cruikshank, Lewis, Connors - Unknown - Synaptic basis for intense thalamocortical activation of feedforward inhibitory cells in neoco(2).pdf:pdf},
keywords = {Thalamocortical,inhibitory interneuronons},
mendeley-tags = {Thalamocortical,inhibitory interneuronons},
title = {{Synaptic basis for intense thalamocortical activation of feedforward inhibitory cells in neocortex}}
}
@article{Yang2015,
abstract = {During perceptual decisions about faint or ambiguous sensory stimuli, even identical stimuli can produce different choices. Spike trains from sensory cortex neurons can predict trial-to-trial variability in choice. Choice-related spiking is widely studied as a way to link cortical activity to perception, but its origins remain unclear. Using imaging and electrophysiology, we found that mouse primary somatosensory cortex neurons showed robust choice-related activity during a tactile detection task. Spike trains from primary mechanoreceptive neurons did not predict choices about identical stimuli. Spike trains from thalamic relay neurons showed highly transient, weak choice-related activity. Intracellular recordings in cortex revealed a prolonged choice-related depolarization in most neurons that was not accounted for by feed-forward thalamic input. Top-down axons projecting from secondary to primary somatosensory cortex signaled choice. An intracellular measure of stimulus sensitivity determined which neurons converted choice-related depolarization into spiking. Our results reveal how choice-related spiking emerges across neural circuits and within single neurons.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Yang, Hongdian and Kwon, Sung E and Severson, Kyle S and O'Connor, Daniel H},
doi = {10.1038/nn.4183},
eprint = {15334406},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Yang et al. - 2015 - Origins of choice-related activity in mouse somatosensory cortex(3).pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {1},
pages = {127--134},
pmid = {26642088},
title = {{Origins of choice-related activity in mouse somatosensory cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.4183},
volume = {19},
year = {2015}
}
@article{Li2008,
annote = {NULL},
author = {Li, Ye and {Van Hooser}, Stephen D. and Mazurek, Mark and White, Leonard E. and Fitzpatrick, David},
doi = {10.1038/nature07417},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/UHDR96KE/nature07417.pdf:pdf},
issn = {0028-0836, 1476-4687},
journal = {Nature},
keywords = {development,direction selectivity,ferret},
mendeley-tags = {development,direction selectivity,ferret},
month = {dec},
number = {7224},
pages = {952--956},
title = {{Experience with moving visual stimuli drives the early development of cortical direction selectivity}},
url = {http://www.nature.com/doifinder/10.1038/nature07417 http://www.nature.com/nature/journal/v456/n7224/pdf/nature07417.pdf},
volume = {456},
year = {2008}
}
@article{Vyazovskiy2011,
author = {Vyazovskiy, Vladyslav V and Olcese, Umberto and Hanlon, Erin C and Nir, Yuval and Cirelli, Chiara and Tononi, Giulio},
doi = {10.1038/nature10009},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Vyazovskiy et al. - 2011 - Local sleep in awake rats.pdf:pdf},
journal = {Nature},
keywords = {local sleep,sleep},
mendeley-tags = {local sleep,sleep},
title = {{Local sleep in awake rats}},
volume = {472},
year = {2011}
}
@article{Goodfellow2016a,
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Goodfellow, Ian},
doi = {10.1001/jamainternmed.2016.8245},
eprint = {1701.00160},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Outcomes - 2017 - GAN TUTORIAL.pdf:pdf},
isbn = {1581138285},
issn = {2168-6106},
journal = {NIPS},
month = {jan},
pages = {1--8},
pmid = {15040217},
title = {{NIPS 2016 Tutorial: Generative Adversarial Networks Ian Goodfellow OpenAI, ian@openai.com Abstract}},
url = {http://arxiv.org/abs/1701.00160 http://archinte.jamanetwork.com/article.aspx?doi=10.1001/jamainternmed.2016.8245},
volume = {2016},
year = {2017}
}
@article{Clancy2014,
abstract = {Brain-machine interfaces are not only promising for neurological applications, but also powerful for investigating neuronal ensemble dynamics during learning. We trained mice to operantly control an auditory cursor using spike-related calcium signals recorded with two-photon imaging in motor and somatosensory cortex. Mice rapidly learned to modulate activity in layer 2/3 neurons, evident both across and within sessions. Learning was accompanied by modifications of firing correlations in spatially localized networks at fine scales.},
author = {Clancy, Kelly B and Koralek, Aaron C and Costa, Rui M and Feldman, Daniel E and Carmena, Jose M},
doi = {10.1038/nn.3712},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Clancy et al. - 2014 - Volitional modulation of optically recorded calcium signals during neuroprosthetic learning.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {6},
pages = {807--809},
pmid = {24728268},
title = {{Volitional modulation of optically recorded calcium signals during neuroprosthetic learning}},
url = {https://www.nature.com/neuro/journal/v17/n6/pdf/nn.3712.pdf http://www.nature.com/doifinder/10.1038/nn.3712},
volume = {17},
year = {2014}
}
@article{Hoyer,
abstract = {The responses of cortical sensory neurons are notoriously variable, with the number of spikes evoked by identical stimuli varying significantly from trial to trial. This variability is most often interpreted as ‘noise', purely detrimental to the sensory system. In this paper, we propose},
author = {Hoyer, Patrik O and Hyv{\"{a}}rinen, Aapo},
doi = {10.1.1.71.1731},
journal = {Advances in neural information processing systems},
number = {1},
pages = {293--300},
title = {{Interpreting neural response variability as monte carlo sampling of the posterior}},
url = {http://www.cis.hut.fi/phoyer/},
year = {2003}
}
@article{Green1966,
abstract = {(Created by APA) Presents a reprint of the 1966 edition, containing introductions to probability theory, statistical decision theory, and waveform analysis and reviewing the basic experiments which support the application of detection theory to psychophysics and to a variety of substantive psychological problems. (11 p ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Green, David M. and Swets, John A.},
doi = {10.1901/jeab.1969.12-475},
isbn = {0932146236},
issn = {00225002},
journal = {Society},
pages = {521},
title = {{Signal detection theory and psychophysics}},
url = {http://andrei.gorea.free.fr/Teaching{\_}fichiers/SDT and Psytchophysics.pdf},
volume = {1},
year = {1966}
}
@article{Hamming1986,
abstract = {The art of research from horse's mouth. Richard Hamming explaining his gardening life and ways.},
author = {Hamming, Richard},
doi = {10.1007/s00287-006-0135-3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Hamming - 1986 - You and Your Research.pdf:pdf},
isbn = {4445105678},
issn = {01706012},
journal = {Simula Research Laboratory},
number = {March},
pages = {37--60},
pmid = {11933064},
title = {{You and Your Research}},
url = {http://www.springerlink.com/index/P147824132441575.pdf},
volume = {30},
year = {1986}
}
@article{Communications2003,
annote = {NULL},
author = {Communications, Personal},
doi = {10.3987/Contents-12-85-7},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Owen - 2013 - Monte Carlo theory, methods and examples.pdf:pdf},
issn = {0385-5414},
journal = {Pacific Conservation Biology},
number = {August},
pages = {1--28},
title = {{Contents 9.}},
year = {2003}
}
@article{Woolley2014,
abstract = {SUMMARY Context dependence is a key feature of cortical-basal ganglia circuit activity, and in songbirds the cortical outflow of a basal ganglia circuit specialized for song, LMAN, shows striking increases in trial-by-trial variability and bursting when birds sing alone rather than to females. To reveal where this variability and its social regulation emerge, we recorded step-wise from corticostriatal (HVC) neurons and their target spiny and pallidal neurons in Area X. We find that corticostriatal and spiny neurons both show precise singing-related firing across both social set-tings. Pallidal neurons, in contrast, exhibit markedly increased trial-by-trial variation when birds sing alone, created by highly variable pauses in firing. This variability persists even when recurrent inputs from LMAN are ablated. These data indicate that variability and its context sensitivity emerge within the basal ganglia network, suggest a network mech-anism for this emergence, and highlight variability generation and regulation as basal ganglia functions.},
author = {Woolley, Sarah C and Rajan, Raghav and Joshua, Mati and Doupe, Allison J},
doi = {10.1016/j.neuron.2014.01.039},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(2).pdf:pdf},
journal = {Neuron},
keywords = {basal ganglia,hvc,lman,songbird,variability},
mendeley-tags = {basal ganglia,hvc,lman,songbird,variability},
pages = {208--223},
title = {{Emergence of Context-Dependent Variability across a Basal Ganglia Network}},
url = {http://dx.doi.org/10.1016/j.neuron.2014.01.039},
volume = {82},
year = {2014}
}
@article{Kuchibhotla2016,
abstract = {Physical features of sensory stimuli are fixed, but sensory perception is context dependent. The precise mechanisms that govern contextual modulation remain unknown. Here, we trained mice to switch between two contexts: passively listening to pure tones and performing a recognition task for the same stimuli. Two-photon imaging showed that many excitatory neurons in auditory cortex were suppressed during behavior, while some cells became more active. Whole-cell recordings showed that excitatory inputs were affected only modestly by context, but inhibition was more sensitive, with PV(+), SOM(+), and VIP(+) interneurons balancing inhibition and disinhibition within the network. Cholinergic modulation was involved in context switching, with cholinergic axons increasing activity during behavior and directly depolarizing inhibitory cells. Network modeling captured these findings, but only when modulation coincidently drove all three interneuron subtypes, ruling out either inhibition or disinhibition alone as sole mechanism for active engagement. Parallel processing of cholinergic modulation by cortical interneurons therefore enables context-dependent behavior.},
author = {Kuchibhotla, Kishore V and Gill, Jonathan V and Lindsay, Grace W and Papadoyannis, Eleni S and Field, Rachel E and Sten, Tom A Hindmarsh and Miller, Kenneth D and Froemke, Robert C},
doi = {10.1038/nn.4436},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kuchibhotla et al. - 2016 - Parallel processing by cortical inhibition enables context-dependent behavior.pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kuchibhotla et al. - 2016 - Parallel processing by cortical inhibition enables context-dependent behavior(2).pdf:pdf},
isbn = {1546-1726 (Electronic) 1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {1},
pages = {62--71},
pmid = {27798631},
title = {{Parallel processing by cortical inhibition enables context-dependent behavior}},
url = {http://www.nature.com/doifinder/10.1038/nn.4436},
volume = {20},
year = {2016}
}
@article{Stringer2016,
abstract = {Our brains contain billions of neurons, which are continually producing electrical signals to relay information around the brain. Yet most of our knowledge of how the brain works comes from studying the activity of one neuron at a time. Recently, studies of multiple neurons have shown that they tend to be active together in short bursts called “up” states, which are followed by periods in which they are less active called “down” states. When we are sleeping or under a general anesthetic, the neurons may be completely silent during down states, but when we are awake the difference in activity between the two states is usually less extreme. However, it is still not clear how the neurons generate these patterns of activity. To address this question, Stringer et al. studied the activity of neurons in the brains of awake and anesthetized rats, mice and gerbils. The experiments recorded electrical activity from many neurons at the same time and found a wide range of different activity patterns. A computational model based on these data suggests that differences in the degree to which some neurons suppress the activity of other neurons may account for this variety. Increasing the strength of these inhibitory signals in the model decreased the fluctuations in electrical activity across entire areas of the brain. Further analysis of the experimental data supported the model's predictions by showing that inhibitory neurons – which act to reduce electrical activity in other neurons – were more active when there were fewer fluctuations in activity across the brain. The next step following on from this work would be to develop ways to build computer models that can mimic the activity of many more neurons at the same time. The models could then be used to interpret the electrical activity produced by many different kinds of neuron. This will enable researchers to test more sophisticated hypotheses about how the brain works.},
author = {Abbott, L F and Dayan, Peter},
doi = {10.1162/089976699300016827},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Abbott, Dayan - 1999 - The Effect of Correlated Variability on the Accuracy of a Population Code.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Gerbil,Mouse,Rat,inhibition,neural networks},
month = {jan},
number = {1},
pages = {91--101},
pmid = {27926356},
publisher = {eLife Sciences Publications Limited},
title = {{The Effect of Correlated Variability on the Accuracy of a Population Code}},
url = {http://www.mitpressjournals.org/doi/10.1162/089976699300016827},
volume = {11},
year = {1999}
}
@article{Guez2013,
abstract = {Bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately, planning optimally in the face of uncertainty is notoriously taxing, since the search space is enormous. In this paper we introduce a tractable, sample-based method for approximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our approach avoids expensive applications of Bayes rule within the search tree by sampling models from current beliefs, and furthermore performs this sampling in a lazy manner. This enables it to outperform previous Bayesian model-based reinforcement learning algorithms by a significant margin on several well-known benchmark problems. As we show, our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in Bayesian exploration.},
author = {Guez, Arthur and Silver, David and Dayan, Peter},
doi = {10.1613/jair.4117},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Guez, Silver, Dayan - 2013 - Scalable and Efficient Bayes-Adaptive Reinforcement Learning Based on Monte-Carlo Tree Search.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {841--883},
title = {{Scalable and efficient bayes-adaptive reinforcement learning based on Monte-Carlo tree search}},
volume = {48},
year = {2013}
}
@article{McNamara2006,
abstract = {Bayesian decision theory can be used to model animal behaviour. In this paper we give an overview of the theoretical concepts in such models. We also review the biological contexts in which Bayesian models have been applied, and outline some directions where future studies would be useful. Bayesian decision theory, when applied to animal behaviour, is based on the assumption that the individual has some sort of "prior opinion" of the possible states of the world. This may, for example, be a previously experienced distribution of qualities of food patches, or qualities of potential mates. The animal is then assumed to be able use sampling information to arrive at a "posterior opinion", concerning e.g. the quality of a given food patch, or the average qualities of mates in a year. A correctly formulated Bayesian model predicts how animals may combine previous experience with sampling information to make optimal decisions. We argue that the assumption that animals may have "prior opinions" is reasonable. Their priors may come from one or both of two sources: either from their own individual experience, gained while sampling the environment, or from an adaptation to the environment experienced by previous generations. This means that we should often expect to see "Bayesian-like" decision-making in nature.},
author = {McNamara, J M and Green, R F and Olsson, Ola},
doi = {10.1111/j.0030-1299.2006.14228.x},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/McNamara et al. - Unknown - Bayes' theorem and its applications in animal behaviour Bayes' theorem.pdf:pdf},
isbn = {0030-1299},
issn = {00301299},
journal = {Oikos},
keywords = {decision,environment,exploitation,food,foragers,gaining ecological information,mate choice,patch use,predation risk,rules},
number = {2},
pages = {243--251},
pmid = {1894},
title = {{Bayes' theorem and its applications in animal behaviour}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.603.6735{\&}rep=rep1{\&}type=pdf},
volume = {112},
year = {2006}
}
@article{Dauphin,
abstract = {A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. We apply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.},
archivePrefix = {arXiv},
arxivId = {1406.2572},
author = {Dauphin, Yann and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
eprint = {1406.2572},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Dauphin et al. - 2014 - Identifying and attacking the saddle point problem in high-dimensional non-convex optimization.pdf:pdf},
isbn = {1406.2572},
issn = {10495258},
journal = {arXiv},
pages = {1--14},
title = {{Identifying and attacking the saddle point problem in high-dimensional non-convex optimization}},
url = {http://arxiv.org/abs/1406.2572},
year = {2014}
}
@article{Fairhall2001,
abstract = {We examine the dynamics of a neural code in the context of stimuli whose statistical properties are themselves evolving dynamically. Adaptation to these statistics occurs over a wide range of timescales-from tens of milliseconds to minutes. Rapid components of adaptation serve to optimize the information that action potentials carry about rapid stimulus variations within the local statistical ensemble, while changes in the rate and statistics of action-potential firing encode information about the ensemble itself, thus resolving potential ambiguities. The speed with which information is optimized and ambiguities are resolved approaches the physical limit imposed by statistical sampling and noise.},
author = {Fairhall, Adrienne L and Lewen, Geoffrey D and Bialek, William and {de Ruyter Van Steveninck}, R R},
doi = {10.1038/35090500},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Fairhall et al. - 2001 - Ef{\textregistered}ciency and ambiguity in an adaptive neural code.pdf:pdf},
isbn = {0028-0836 (Print)},
issn = {0028-0836},
journal = {Nature},
keywords = {Adaptation,Animals,Data Interpretation,Diptera,Physiological,Reaction Time,Statistical,Synaptic Transmission,Visual Pathways,Visual Pathways: physiology},
number = {6849},
pages = {787--92},
pmid = {11518957},
title = {{Efficiency and ambiguity in an adaptive neural code.}},
url = {http://www.nature.com/nature/journal/v412/n6849/pdf/412787a0.pdf http://www.ncbi.nlm.nih.gov/pubmed/11518957},
volume = {412},
year = {2001}
}
@article{Donahue,
abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing generators learn to " linearize semantics " in the latent space of such models. Intuitively, such latent spaces may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping – projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
author = {Donahue, Jeff and Kr{\"{a}}henb{\"{u}}hl, Philipp and Darrell, Trevor},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Donahue, Kr{\"{a}}henb{\"{u}}hl, Darrell - Unknown - ADVERSARIAL FEATURE LEARNING.pdf:pdf},
title = {{ADVERSARIAL FEATURE LEARNING}}
}
@article{Guo2014,
abstract = {The mouse is an increasingly prominent model for the analysis of mammalian neuronal circuits. Neural circuits ultimately have to be probed during behaviors that engage the circuits. Linking circuit dynamics to behavior requires precise control of sensory stimuli and measurement of body movements. Head-fixation has been used for behavioral research, particularly in non-human primates, to facilitate precise stimulus control, behavioral monitoring and neural recording. However, choice-based, perceptual decision tasks by head-fixed mice have only recently been introduced. Training mice relies on motivating mice using water restriction. Here we describe procedures for head-fixation, water restriction and behavioral training for head-fixed mice, with a focus on active, whisker-based tactile behaviors. In these experiments mice had restricted access to water (typically 1 ml/day). After ten days of water restriction, body weight stabilized at approximately 80{\%} of initial weight. At that point mice were trained to discriminate sensory stimuli using operant conditioning. Head-fixed mice reported stimuli by licking in go/no-go tasks and also using a forced choice paradigm using a dual lickport. In some cases mice learned to discriminate sensory stimuli in a few trials within the first behavioral session. Delay epochs lasting a second or more were used to separate sensation (e.g. tactile exploration) and action (i.e. licking). Mice performed a variety of perceptual decision tasks with high performance for hundreds of trials per behavioral session. Up to four months of continuous water restriction showed no adverse health effects. Behavioral performance correlated with the degree of water restriction, supporting the importance of controlling access to water. These behavioral paradigms can be combined with cellular resolution imaging, random access photostimulation, and whole cell recordings.},
author = {Guo, Zengcai V and Hires, S Andrew and Li, Nuo and O'Connor, Daniel H. and Komiyama, Takaki and Ophir, Eran and Huber, Daniel and Bonardi, Claudia and Morandell, Karin and Gutnisky, Diego and Peron, Simon and Xu, Ning-long and Cox, James and Svoboda, Karel},
doi = {10.1371/journal.pone.0088678},
editor = {Simon, Sidney Arthur},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - 2014 - Procedures for Behavioral Experiments in Head-Fixed Mice.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {1932-6203},
journal = {PLoS ONE},
month = {feb},
number = {2},
pages = {e88678},
pmid = {24520413},
title = {{Procedures for Behavioral Experiments in Head-Fixed Mice}},
url = {http://dx.plos.org/10.1371/journal.pone.0088678},
volume = {9},
year = {2014}
}
@article{Polack2013,
abstract = {Visual cortical neurons fire at higher rates to visual stimuli during locomotion than during immobility, while maintaining orientation selectivity. The mechanisms underlying this change in gain are not understood. We performed whole-cell recordings from layer 2/3 and layer 4 visual cortical excitatory neurons and from parvalbumin-positive and somatostatin-positive inhibitory neurons in mice that were free to rest or run on a spherical treadmill. We found that the membrane potential of all cell types became more depolarized and (with the exception of somatostatin-positive interneurons) less variable during locomotion. Cholinergic input was essential for maintaining the unimodal membrane potential distribution during immobility, whereas noradrenergic input was necessary for the tonic depolarization associated with locomotion. Our results provide a mechanism for how neuromodulation controls the gain and signal-to-noise ratio of visual cortical neurons during changes in the state of vigilance.},
author = {Polack, Pierre-Olivier and Friedman, Jonathan and Golshani, Peyman},
doi = {10.1038/nn.3464},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Polack, Friedman, Golshani - 2013 - Cellular mechanisms of brain state–dependent gain modulation in visual cortex.pdf:pdf},
isbn = {1546-1726 (Electronic){\$}\backslash{\$}r1097-6256 (Linking)},
issn = {1097-6256, 1546-1726},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cortex,DNA-Binding Proteins,DNA-Binding Proteins: genetics,Female,Gain control,Immobilization,Inbred C57BL,Locomotion,Locomotion: drug effects,Locomotion: physiology,Male,Mice,Models,Neurological,Neurons,Neurons: classification,Neurons: drug effects,Neurons: physiology,Neurotransmitter Agents,Neurotransmitter Agents: pharmacology,Orientation,Orientation: drug effects,Orientation: physiology,Orientation: radiation effects,Parvalbumins,Parvalbumins: genetics,Patch-Clamp Techniques,Photic Stimulation,Signal-To-Noise Ratio,Transcription Factors,Transcription Factors: genetics,Transgenic,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,brain state},
mendeley-tags = {Cortex,Gain control,brain state},
month = {jul},
number = {9},
pages = {1331--1339},
pmid = {23872595},
title = {{Cellular mechanisms of brain state–dependent gain modulation in visual cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.3464 http://www.nature.com/neuro/journal/v16/n9/pdf/nn.3464.pdf},
volume = {16},
year = {2013}
}
@article{Silver,
abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic pol- icy gradient has a particularly appealing form: it is the expected gradient of the action-value func- tion. This simple form means that the deter- ministic policy gradient can be estimated much more efficiently than the usual stochastic pol- icy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counter- parts in high-dimensional action spaces.},
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Silver et al. - Unknown - Deterministic Policy Gradient Algorithms.pdf:pdf},
isbn = {9781634393973},
journal = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
pages = {387--395},
title = {{Deterministic Policy Gradient Algorithms}},
year = {2014}
}
@article{Goodfellow2016,
abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Goodfellow, Ian},
eprint = {1701.00160},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Outcomes - 2017 - GAN TUTORIAL.pdf:pdf},
month = {dec},
title = {{NIPS 2016 Tutorial: Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1701.00160},
year = {2016}
}
@article{Guo2014a,
abstract = {Perceptual decisions involve distributed cortical activity. Does information flow sequentially from one cortical area to another, or do networks of interconnected areas contribute at the same time? Herewe delineate when and how activity in specific areas drives a whisker-based decision in mice. Ashort-term memory component temporally separated tactile "sensation" and "action" (licking). Using optogenetic inhibition (spatial resolution, 2mm; temporal resolution, 100ms), we surveyed the neocortex for regions driving behavior during specific behavioral epochs. Barrel cortex was critical for sensation. During the short-term memory, unilateral inhibition of anterior lateral motor cortex biased responses to the ipsilateral side. Consistently, barrel cortex showed stimulus-specific activity during sensation, whereas motor cortex showed choice-specific preparatory activity and movement-related activity, consistent with roles in motor planning and movement. These results suggest serial information flow from sensory to motor areas during perceptual decision making. {\textcopyright} 2014 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {1512.01655},
author = {Guo, ZengcaiV and Li, Nuo and Huber, Daniel and Ophir, Eran and Gutnisky, Diego and Ting, JonathanT and Feng, Guoping and Svoboda, Karel},
doi = {10.1016/j.neuron.2013.10.020},
eprint = {1512.01655},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - 2014 - Flow of Cortical Activity Underlying a Tactile Decision in Mice.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {179--194},
pmid = {24361077},
title = {{Flow of cortical activity underlying a tactile decision in mice}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.10.020},
volume = {81},
year = {2014}
}
@article{Pillow2010,
abstract = {One of the central problems in systems neuroscience is to understand how neural spike trains convey sensory information. Decoding methods, which provide an explicit means for reading out the information contained in neural spike responses, offer a powerful set of tools for studying the neural coding problem. Here we develop several decoding methods based on point-process neural encoding models, or forward models that predict spike responses to stimuli. These models have concave log-likelihood functions, which allow efficient maximum-likelihood model fitting and stimulus decoding. We present several applications of the encoding model framework to the problem of decoding stimulus information from population spike responses: (1) a tractable algorithm for computing the maximum a posteriori estimate of the stimulus, the most probable stimulus to have generated an observed single- or multiple-neuron spike train response, given some prior distribution over the stimulus; (2) a gaussian approximation to the posterior stimulus distribution that can be used to quantify the fidelity with which various stimulus features are encoded; (3) an efficient method for estimating the mutual information between the stimulus and the spike trains emitted by a neural population; and (4) a framework for the detection of change-point times (the time at which the stimulus undergoes a change in mean or variance) by marginalizing over the posterior stimulus distribution. We provide several examples illustrating the performance of these estimators with simulated and real neural data.},
annote = {NULL},
author = {Pillow, Jonathan W and Ahmadian, Yashar and Paninski, Liam},
doi = {10.1162/NECO_a_00058},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pillow, Ahmadian, Paninski - 2010 - Model-Based Decoding, Information Estimation, and Change-Point Detection Techniques for Multineuron.pdf:pdf},
isbn = {1530-888X (Electronic)$\backslash$r0899-7667 (Linking)},
issn = {1530-888X},
journal = {Neural computation},
number = {1},
pages = {1--45},
pmid = {20964538},
title = {{Model-Based Decoding, Information Estimation, and Change-Point Detection Techniques for Multineuron Spike Trains.}},
url = {http://www.stat.columbia.edu/{~}liam/research/pubs/decoding-nc.pdf http://www.ncbi.nlm.nih.gov/pubmed/20964538{\%}5Cnhttp://dx.doi.org/10.1162/NECO{\_}a{\_}00058{\%}5Cnhttp://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00058{\#}.VQgNMRCsVCw{\%}5Cnhttp://www.mitpressjourn},
volume = {45},
year = {2010}
}
@inproceedings{Park,
abstract = {Neural population activity often exhibits rich variability. This variability can arise from single-neuron stochasticity, neural dynamics on short time-scales, as well as from modulations of neural firing properties on long time-scales, often referred to as neural non-stationarity. To better understand the nature of co-variability in neural circuits and their impact on cortical information processing, we introduce a hierarchical dynamics model that is able to capture both slow inter-trial modula-tions in firing rates as well as neural population dynamics. We derive a Bayesian Laplace propagation algorithm for joint inference of parameters and population states. On neural population recordings from primary visual cortex, we demon-strate that our model provides a better account of the structure of neural firing than stationary dynamics models.},
author = {Park, Mijung and Bohner, Gergo and Macke, Jakob H},
booktitle = {Advances in Neural Information Processing Systems},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Park, Bohner, Macke - Unknown - Unlocking neural population non-stationarity using a hierarchical dynamics model.pdf:pdf},
pages = {145--153},
title = {{Unlocking neural population non-stationarities using hierarchical dynamics models}},
year = {2015}
}
@article{Ahmadian2010,
abstract = {Stimulus reconstruction or decoding methods provide an important tool for understanding how sensory and motor information is represented in neural activity. We discuss Bayesian decoding methods based on an encoding generalized linear model (GLM) that accurately describes how stimuli are transformed into the spike trains of a group of neurons. The form of the GLM likelihood ensures that the posterior distribution over the stimuli that caused an observed set of spike trains is log concave so long as the prior is. This allows the maximum a posteriori (MAP) stimulus estimate to be obtained using efficient optimization algorithms. Unfortunately, the MAP estimate can have a relatively large average error when the posterior is highly nongaussian. Here we compare several Markov chain Monte Carlo (MCMC) algorithms that allow for the calculation of general Bayesian estimators involving posterior expectations (conditional on model parameters). An efficient version of the hybrid Monte Carlo (HMC) algorithm was signif...},
author = {Ahmadian, Yashar and Pillow, Jonathan W and Paninski, Liam},
doi = {10.1162/NECO_a_00059},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ahmadian, Pillow, Paninski - 2010 - Efficient Markov Chain Monte Carlo Methods for Decoding Neural Spike Trains(2).pdf:pdf},
issn = {1530-888X},
journal = {http://dx.doi.org/10.1162/NECO{\_}a{\_}00059},
pages = {1--51},
pmid = {20964539},
title = {{Efficient Markov Chain Monte Carlo Methods for Decoding Neural Spike Trains}},
url = {http://www.stat.columbia.edu/{~}liam/research/pubs/yashar-nc08.pdf papers2://publication/uuid/905F3B39-D2E6-4608-9B4C-DF251FD3A8F6{\%}5Cnhttp://pillowlab.cps.utexas.edu/pubs/Ahmadian{\_}etal{\_}NC2011.pdf{\%}5Cnpapers2://publication/uuid/DCEE55BA-40E6-4A43-BC55-ED2FFA7},
year = {2010}
}
@article{Allen2017,
abstract = {The successful planning and execution of adaptive behaviors in mammals may require long-range coordination of neural networks throughout cerebral cortex. The neuronal implementation of signals that could orchestrate cortex-wide activity remains unclear. Here, we develop and apply methods for cortex-wide Ca2+ imaging in mice performing decision-making behavior and identify a global cortical representation of task engagement encoded in the activity dynamics of both single cells and superficial neuropil distributed across the majority of dorsal cortex. The activity of multiple molecularly defined cell types was found to reflect this representation with type-specific dynamics. Focal optogenetic inhibition tiled across cortex revealed a crucial role for frontal cortex in triggering this cortex-wide phenomenon; local inhibition of this region blocked both the cortex-wide response to task-initiating cues and the voluntary behavior. These findings reveal cell-type-specific processes in cortex for globally representing goal-directed behavior and identify a major cortical node that gates the global broadcast of task-related information.},
author = {Allen, William E and Kauvar, Isaac V and Chen, Michael Z and Richman, Ethan B and Yang, Samuel J and Chan, Ken and Gradinaru, Viviana and Deverman, Benjamin E and Luo, Liqun and Deisseroth, Karl},
doi = {10.1016/j.neuron.2017.04.017},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Allen et al. - 2017 - Global Representations of Goal-Directed Behavior in Distinct Cell Types of Mouse Neocortex(2).pdf:pdf},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
keywords = {calcium imaging,cell type,cortex,goal-directed behavior,optogenetics,widefield},
number = {4},
pages = {891--907.e6},
pmid = {28521139},
title = {{Global Representations of Goal-Directed Behavior in Distinct Cell Types of Mouse Neocortex}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.04.017},
volume = {94},
year = {2017}
}
@article{Goldberg2012,
abstract = {The pallido-recipient thalamus transmits information from the basal ganglia to the cortex and is critical for motor initiation and learning. Thalamic activity is strongly inhibited by pallidal inputs from the basal ganglia, but the role of nonpallidal inputs, such as excitatory inputs from cortex, remains unclear. We simultaneously recorded from presynaptic pallidal axon terminals and postsynaptic thalamocortical neurons in a basal ganglia-recipient thalamic nucleus that is necessary for vocal variability and learning in zebra finches. We found that song-locked rate modulations in the thalamus could not be explained by pallidal inputs alone and persisted following pallidal lesion. Instead, thalamic activity was likely driven by inputs from a motor cortical nucleus that is also necessary for singing. These findings suggest a role for cortical inputs to the pallido-recipient thalamus in driving premotor signals that are important for exploratory behavior and learning.},
author = {Goldberg, Jesse H and Fee, Michale S},
doi = {10.1038/nn.3047},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Goldberg, Fee - 2012 - A cortical motor nucleus drives the basal ganglia-recipient thalamus in singing birds.pdf:pdf},
isbn = {1097-6256},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animal: physiology,Animals,Basal Ganglia,Basal Ganglia: physiology,Finches,Finches: physiology,Male,Motor Cortex,Motor Cortex: physiology,Neural Pathways,Neural Pathways: physiology,Songbirds,Thalamus,Thalamus: physiology,Vocalization},
number = {4},
pages = {620--7},
pmid = {22327474},
title = {{A cortical motor nucleus drives the basal ganglia-recipient thalamus in singing birds.}},
url = {http://www.nature.com/neuro/journal/v15/n4/pdf/nn.3047.pdf http://dx.doi.org/10.1038/nn.3047},
volume = {15},
year = {2012}
}
@misc{Gowanlock2016,
abstract = {Despite significant advances in neuroscience, the neural bases of intelligence remain poorly understood. Arguably the most elusive aspect of intelligence is the ability to make robust inferences that go far beyond one's experience. Animals categorize objects, learn to vocalize and may even estimate causal relationships - all in the face of data that is often ambiguous and sparse. Such inductive leaps are thought to result from the brain's ability to infer latent structure that governs the environment. However, we know little about the neural computations that underlie this ability. Recent advances in developing computational frameworks that can support efficient structure learning and inductive inference may provide insight into the underlying component processes and help pave the path for uncovering their neural implementation.},
author = {Tervo, D. Gowanlock R and Tenenbaum, Joshua B and Gershman, Samuel J},
booktitle = {Current Opinion in Neurobiology},
doi = {10.1016/j.conb.2016.01.014},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Tervo, Tenenbaum, Gershman - 2016 - Toward the neural implementation of structure learning.pdf:pdf},
isbn = {1873-6882 (Electronic) 0959-4388 (Linking)},
issn = {18736882},
pages = {99--105},
pmid = {26874471},
title = {{Toward the neural implementation of structure learning}},
url = {http://dx.doi.org/10.1016/j.conb.2016.01.014},
volume = {37},
year = {2016}
}
@article{Wu2014,
abstract = {Nature Neuroscience 17, 312 (2014). doi:10.1038/nn.3616},
author = {Wu, Howard G and Miyamoto, Yohsuke R and Castro, Luis Nicolas Gonzalez and {\"{O}}lveczky, Bence P and Smith, Maurice A},
doi = {10.1038/nn.3616},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2014 - Temporal structure of motor variability is dynamically regulated and predicts motor learning ability.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {2},
pages = {312--321},
pmid = {24413700},
title = {{Temporal structure of motor variability is dynamically regulated and predicts motor learning ability}},
url = {http://www.nature.com/neuro/journal/v17/n2/pdf/nn.3616.pdf http://dx.doi.org/10.1038/nn.3616{\%}5Cnpapers2://publication/doi/10.1038/nn.3616},
volume = {17},
year = {2014}
}
@article{Drew2005,
abstract = {The peak procedure was used to characterize response timing during acquisition and maintenance of conditioned responding in goldfish. Subjects received light-shock pairings with a 5- or 15-s interstimulus interval. On interspersed peak trials, the conditioned stimulus light was presented for 45 s and no shock was delivered. Peaks in the conditioned response, general activity, occurred at about the time of the expected unconditioned stimulus, and variability in the activity distribution was scalar. Modeling of the changes in the activity distributions over sessions revealed that the temporal features of the conditioned response changed very little during acquisition. The data suggest that times are learned early in training, and, contrary to I. P. Pavlov's (1927/1960) concept of "inhibition of delay," that timing is learning when to respond rather than learning when not to respond.},
author = {Drew, Michael R. and Zupan, Bojana and Cooke, Anna and Couvillon, P. A. and Balsam, Peter D.},
doi = {10.1037/0097-7403.31.1.31},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Drew et al. - 2005 - Temporal Control of Conditioned Responding in Goldfish.pdf:pdf},
issn = {1939-2184},
journal = {Journal of Experimental Psychology: Animal Behavior Processes},
month = {jan},
number = {1},
pages = {31--39},
pmid = {15656725},
title = {{Temporal Control of Conditioned Responding in Goldfish.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15656725 http://doi.apa.org/getdoi.cfm?doi=10.1037/0097-7403.31.1.31},
volume = {31},
year = {2005}
}
@article{Whittle1988,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. Abstract We consider a population of n projects which in general continue to evolve whether in operation or not (although by different rules). It is desired to choose the projects in operation at each instant of time so as to maximise the expected rate of reward, under a constraint upon the expected number of projects in operation. The Lagrange multiplier associated with this constraint defines an index which reduces to the Gittins index when projects not being operated are static. If one is constrained to operate m projects exactly then arguments are advanced to support the conjecture that, for m and n large in constant ratio, the policy of operating the m projects of largest current index is nearly optimal. The index is evaluated for some particular projects.},
author = {Whittle, P},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Whittle - 1988 - Restless Bandits Activity Allocation in a Changing World.pdf:pdf},
journal = {Journal of Applied Probability A Celebration of Applied Probability},
keywords = {GITTINS INDEX,INDEXABILITY,MULTI-ARMED BANDITS,SEQUENTIAL SCHEDULING,STIMULATING PRICES},
pages = {287--298},
title = {{Restless Bandits: Activity Allocation in a Changing World}},
url = {http://www.jstor.org/stable/3214163 http://about.jstor.org/terms},
volume = {25},
year = {1988}
}
@article{Hires2015,
abstract = {Cortical spike trains often appear noisy, with the timing and number of spikes varying across repetitions of stimuli. Spiking variability can arise from internal (behavioral state, unreliable neurons, or chaotic dynamics in neural circuits) and external (uncontrolled behavior or sensory stimuli) sources. The amount of irreducible internal noise in spike trains, an important constraint on models of cortical networks, has been difficult to estimate, since behavior and brain state must be precisely controlled or tracked. We recorded from excitatory barrel cortex neurons in layer 4 during active behavior, where mice control tactile input through learned whisker movements. Touch was the dominant sensorimotor feature, with {\textgreater}70{\%} spikes occurring in millisecond timescale epochs after touch onset. The variance of touch responses was smaller than expected from Poisson processes, often reaching the theoretical minimum. Layer 4 spike trains thus reflect the millisecond-timescale structure of tactile input with little noise.},
author = {Hires, Samuel Andrew and Gutnisky, Diego A. and Yu, Jianing and O'Connor, Daniel H. and Svoboda, Karel},
doi = {10.7554/eLife.06619},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Hires et al. - 2015 - Low-noise encoding of active touch by layer 4 in the somatosensory cortex.pdf:pdf},
isbn = {2050-084X (Electronic)$\backslash$r2050-084X (Linking)},
issn = {2050084X},
journal = {eLife},
keywords = {barrel cortex,mouse,neuroscience,noise,sensory coding,somatosensation},
month = {aug},
number = {AUGUST2015},
pages = {14921--14926},
pmid = {26245232},
publisher = {eLife Sciences Publications Limited},
title = {{Low-noise encoding of active touch by layer 4 in the somatosensory cortex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26245232 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4525079 http://elifesciences.org/lookup/doi/10.7554/eLife.06619},
volume = {4},
year = {2015}
}
@article{Besbes,
abstract = {In a multi-armed bandit (MAB) problem a gambler needs to choose at each round of play one of K arms, each characterized by an unknown reward distribution. Reward realizations are only observed when an arm is selected, and the gambler's objective is to maximize his cumulative expected earnings over some given hori-zon of play T . To do this, the gambler needs to acquire information about arms (exploration) while simultaneously optimizing immediate rewards (exploitation); the price paid due to this trade off is often referred to as the regret, and the main question is how small can this price be as a function of the horizon length T . This problem has been studied extensively when the reward distributions do not change over time; an assumption that supports a sharp characterization of the regret, yet is often violated in practical settings. In this paper, we focus on a MAB formulation which allows for a broad range of temporal uncertainties in the rewards, while still maintaining mathematical tractability. We fully characterize the (regret) complex-ity of this class of MAB problems by establishing a direct link between the extent of allowable reward " variation " and the minimal achievable regret, and by estab-lishing a connection between the adversarial and the stochastic MAB frameworks.},
author = {Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Besbes, Gur, Zeevi - Unknown - Stochastic Multi-Armed-Bandit Problem with Non-stationary Rewards.pdf:pdf},
title = {{Stochastic Multi-Armed-Bandit Problem with Non-stationary Rewards}}
}
@article{Ko2013,
abstract = {Sensory processing occurs in neocortical microcircuits in which synaptic connectivity is highly structured and excitatory neurons form subnetworks that process related sensory information. However, the developmental mechanisms underlying the formation of functionally organized connectivity in cortical microcircuits remain unknown. Here we directly relate patterns of excitatory synaptic connectivity to visual response properties of neighbouring layer 2/3 pyramidal neurons in mouse visual cortex at different postnatal ages, using two-photon calcium imaging in vivo and multiple whole-cell recordings in vitro. Although neural responses were already highly selective for visual stimuli at eye opening, neurons responding to similar visual features were not yet preferentially connected, indicating that the emergence of feature selectivity does not depend on the precise arrangement of local synaptic connections. After eye opening, local connectivity reorganized extensively: more connections formed selectively between neurons with similar visual responses and connections were eliminated between visually unresponsive neurons, but the overall connectivity rate did not change. We propose a sequential model of cortical microcircuit development based on activity-dependent mechanisms of plasticity whereby neurons first acquire feature preference by selecting feedforward inputs before the onset of sensory experience--a process that may be facilitated by early electrical coupling between neuronal subsets--and then patterned input drives the formation of functional subnetworks through a redistribution of recurrent synaptic connections.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ko, Ho and Cossell, Lee and Baragli, Chiara and Antolik, Jan and Clopath, Claudia and Hofer, Sonja B. and Mrsic-Flogel, Thomas D.},
doi = {10.1038/nature12015},
eprint = {arXiv:1011.1669v3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/QXA2JZTC/nature12015.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
keywords = {Animals,Eye,Eyelids,Eyelids: physiology,Inbred C57BL,Mice,Models,Movement,Neural Pathways,Neural Pathways: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Newborn,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Synapses,Synapses: metabolism,Synapses: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology,circuits,development,visual cortex},
mendeley-tags = {circuits,development,visual cortex},
month = {apr},
number = {7443},
pages = {96--100},
pmid = {23552948},
title = {{The emergence of functional microcircuits in visual cortex}},
url = {http://www.nature.com/doifinder/10.1038/nature12015 http://www.nature.com/nature/journal/v496/n7443/pdf/nature12015.pdf},
volume = {496},
year = {2013}
}
@article{Olshausen1993,
abstract = {We present a biologically plausible model of an attentional mechanism for forming position-and scale-invariant repre-sentations of objects in the visual world. The model relies on a set of control neurons to dynamically modify the syn-aptic strengths of intracortical connections so that information from a windowed region of primary visual cortex (VI) is selectively routed to higher cortical areas. Local spatial re-lationships (i.e., topography) within the attentional window are preserved as information is routed through the cortex. This enables attended objects to be represented in higher cortical areas within an object-centered reference frame that is position and scale invariant. We hypothesize that the pul-vinar may provide the control signals for routing information through the cortex. The dynamics of the control neurons are governed by simple differential equations that could be re-alized by neurobiologically plausible circuits. In preattentive mode, the control neurons receive their input from a low-level " saliency map " representing potentially interesting regions of a scene. During the pattern recognition phase, control neurons are driven by the interaction between top-down (memory) and bottom-up (retinal input) sources. The model respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions. Of all the visual tasks humans can perform, pattern recognition is arguably the most computationally difficult. This can be at-tributed primarily to two major factors. The first is that in order to recognize a particular object, the brain must go through a matching process to determine which of the countless objects it has seen before best matches a particular object under scrutiny. The second factor is that any particular object can appear at different positions, sizes, and orientations on the retina, thus giving rise to very different neural representations at early stages of the visual system.},
author = {Olshausen, Bruno A and Anderson, Charles H and Essenla, David C Van},
doi = {10.1.1.66.2555},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Oishausen, Anderson, Essenla - 1993 - A Neurobiological Model of Visual Attention and Invariant Pattern Recognition Based on Dynamic Rou.pdf:pdf},
journal = {The Journal of Neuroscience},
keywords = {[Key words,control],model,pulvinar,recognition,sating,visual attention,visual cortex},
number = {11},
pages = {4700--4719},
pmid = {8229193},
title = {{A Neurobiological Model of Visual Attention and Invariant Pattern Recognition Based on Dynamic Routing of Information}},
volume = {13},
year = {1993}
}
@article{Liu2007,
author = {Liu, Bao-hua and Wu, Guangying K and Arbuckle, Robert and Tao, Huizhong W and Zhang, Li I},
doi = {10.1038/nn2012},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2007 - Defining cortical frequency tuning with recurrent excitatory circuitry.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {12},
pages = {1594--1600},
publisher = {Nature Publishing Group},
title = {{Defining cortical frequency tuning with recurrent excitatory circuitry}},
url = {http://www.nature.com/doifinder/10.1038/nn2012},
volume = {10},
year = {2007}
}
@article{Kingma,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
doi = {10.1051/0004-6361/201527329},
eprint = {1312.6114},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kingma, Welling - Unknown - Auto-Encoding Variational Bayes.pdf:pdf},
isbn = {1312.6114v10},
issn = {1312.6114v10},
journal = {Iclr},
number = {Ml},
pages = {1--14},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2014}
}
@article{Dayan,
abstract = {The standard reinforcement learning view of the involvement of neuromodulatory systems in instrumental conditioning in-cludes a rather straightforward conception of motivation as prediction of sum future reward. Competition between actions is based on the motivating characteristics of their consequent states in this sense. Substantial, careful, experiments reviewed in Dickinson {\&} Balleine, 12,13 into the neurobiology and psychol-ogy of motivation shows that this view is incomplete. In many cases, animals are faced with the choice not between many dif-ferent actions at a given state, but rather whether a single re-sponse is worth executing at all. Evidence suggests that the motivational process underlying this choice has different psy-chological and neural properties from that underlying action choice. We describe and model these motivational systems, and consider the way they interact.},
author = {Dayan, Peter},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Dayan - Unknown - Motivated Reinforcement Learning(2).pdf:pdf},
title = {{Motivated Reinforcement Learning}}
}
@article{Aitchison2016,
abstract = {Probabilistic inference offers a principled framework for understanding both behaviour and cortical computation. However, two basic and ubiquitous properties of cortical responses seem difficult to reconcile with probabilistic inference: neural activity displays prominent oscillations in response to constant input, and large transient changes in response to stimu-lus onset. Indeed, cortical models of probabilistic inference have typically either concen-trated on tuning curve or receptive field properties and remained agnostic as to the underlying circuit dynamics, or had simplistic dynamics that gave neither oscillations nor transients. Here we show that these dynamical behaviours may in fact be understood as hallmarks of the specific representation and algorithm that the cortex employs to perform probabilistic inference. We demonstrate that a particular family of probabilistic inference algorithms, Hamiltonian Monte Carlo (HMC), naturally maps onto the dynamics of excit-atory-inhibitory neural networks. Specifically, we constructed a model of an excitatory-inhibi-tory circuit in primary visual cortex that performed HMC inference, and thus inherently gave rise to oscillations and transients. These oscillations were not mere epiphenomena but served an important functional role: speeding up inference by rapidly spanning a large vol-ume of state space. Inference thus became an order of magnitude more efficient than in a non-oscillatory variant of the model. In addition, the network matched two specific properties of observed neural dynamics that would otherwise be difficult to account for using probabilis-tic inference. First, the frequency of oscillations as well as the magnitude of transients increased with the contrast of the image stimulus. Second, excitation and inhibition were balanced, and inhibition lagged excitation. These results suggest a new functional role for the separation of cortical populations into excitatory and inhibitory neurons, and for the neu-ral oscillations that emerge in such excitatory-inhibitory networks: enhancing the efficiency of cortical computations.},
author = {Aitchison, Laurence and Lengyel, M{\'{a}}t{\'{e}} and Knill, DC and Jacobs, RA and van Beers, RJ and Sittig, AC and van der Gon, JJD and Ernst, MO and Banks, MS and Wolpert, DM and Ghahramani, Z and Jordan, MI and K{\"{o}}rding, KP and Wolpert, DM and Gopnik, A and Glymour, C and Sobel, DM and Schulz, LE and Kushnir, T and Danks, D and Chater, N and Tenenbaum, JB and Yuille, A and Tenenbaum, JB and Griffiths, TL and Kemp, C and Berkes, P and Orb{\'{a}}n, G and Lengyel, M and Fiser, J and Orb{\'{a}}n, G and Berkes, P and Fiser, J and Lengyel, M and Hyv{\"{a}}rinen, A and Olshausen, BA and Field, DJ and Schwartz, O and Simoncelli, EP and Karklin, Y and Lewicki, MS and Coen-Cagli, R and Dayan, P and Schwartz, O and Pouget, A and Beck, JM and Ma, WJ and Latham, PE and Rao, RP and Ballard, DH and Deneve, S and Latham, PE and Pouget, A and Zemel, RS and Dayan, P and Pouget, A and Sahani, M and Dayan, P and Ma, WJ and Beck, JM and Latham, PE and Pouget, A and Beck, JM and Ma, WJ and Kiani, R and Hanks, T and Churchland, AK and Roitman, J and Beck, JM and Latham, PE and Pouget, A and Hoyer, PO and Hyvarinen, A and Buesing, L and Bill, J and Nessler, B and Maass, W and Basar, E and Guntekin, B and M{\"{u}}ller, JR and Metha, AB and Krauskopf, J and Lennie, P and M{\"{u}}ller, JR and Metha, AB and Krauskopf, J and Lennie, P and Ray, S and Maunsell, JHR and Armstrong, KM and Moore, T and Luczak, A and Bartho, P and Harris, KD and Li, Z and Dayan, P and Rubin, DB and Hooser, SD Van and Miller, KD and Fiser, J and Berkes, P and Orb{\'{a}}n, G and Lengyel, M and Duane, S and Kennedy, AD and Pendleton, BJ and Roweth, D and Neal, R and Okun, M and Lampl, I and Roberts, MJ and Lowet, E and Brunet, NM and Wal, M Ter and Tiesinga, P and Fries, P and Wainwright, MJ and Simoncelli, EP and Schwartz, O and Sejnowski, TJ and Dayan, P and Karklin, Y and Lewicki, MS and Berkes, P and Turner, RE and Sahani, M and Coen-Cagli, R and Dayan, P and Schwartz, O and Churchland, MM and Yu, BM and Cunningham, JP and Sugrue, LP and Cohen, MR and Schwartz, O and Sejnowski, TJ and Dayan, P and Tsodyks, MV and Skaggs, WE and Sejnowski, TJ and McNaughton, BL and Murphy, BK and Miller, KD and Hennequin, G and Vogels, TP and Gerstner, W and Pfister, JP and Dayan, P and Lengyel, M and Ujfalussy, BB and Makara, JK and Branco, T and Lengyel, M and Loebel, A and Nelken, I and Tsodyks, M and Turaga, S and Buesing, L and Packer, AM and Dalgleish, H and Pettit, N and Hausser, M and Macke, JH and Buesing, L and Cunningham, JP and Byron, MY and Shenoy, KV and Sahani, M and Roberts, GO and Tweedie, RL and Hennequin, G and Aitchison, Laurence and Lengyel, M and Buzsaki, G and Wilson, HR and Cowan, JD and Milotti, E and Contreras, EJ Bermudez and Schjetnan, AGP and Muhammad, A and Bartho, P and McNaughton, BL and Kolb, B and Wang, X and Lu, T and Snider, RK and Liang, L and Buzs{\'{a}}ki, G and Watson, BO and Savin, C and Peter, D and Lengyel, M and Neal, RM and Womelsdorf, T and Schoffelen, JM and Oostenveld, R and Singer, W and Desimone, R and Engel, AK and Fries, P and Singer, W and Markram, H and Gerstner, W and Sj{\"{o}}str{\"{o}}m, PJ and Kullmann, DM and Moreau, AW and Bakiri, Y and Nicholson, E and Dayan, P and Abbott, LF and Dempster, AP and Laird, NM and Rubin, DB and Tripathy, SJ and Burton, SD and Geramita, M and Gerkin, RC and Urban, NN and Watson, AB and Reid, RC and Alonso, JM and Tripathy, SJ and Savitskaya, J and Burton, SD and Urban, NN and Gerkin, RC and Mizuseki, K and Buzs{\'{a}}ki, G and O'Connor, DH and Peron, SP and Huber, D and Svoboda, K and Branco, T and Staras, K and Song, S and Sj{\"{o}}str{\"{o}}m, PJ and Reigl, M and Nelson, S and Chklovskii, DB and Bremaud, A and West, DC and Thomson, AM and Stern, EA and Kincaid, AE and Wilson, CJ},
doi = {10.1371/JOURNAL.PCBI.1005186},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Aitchison, T{\'{e}} Lengyel - 2016 - The Hamiltonian Brain Efficient Probabilistic Inference with Excitatory-Inhibitory Neural Circuit Dynami.pdf:pdf},
issn = {1553-7358},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1005186},
title = {{The Hamiltonian Brain: Efficient Probabilistic Inference with Excitatory-Inhibitory Neural Circuit Dynamics}},
volume = {12},
year = {2016}
}
@article{Sahani,
abstract = {An essential step in understanding the function of sensory nervous systems is to characterize as accurately as possible the stimulus-response function (SRF) of the neurons that relay and process sensory information.},
author = {Sahani, Maneesh and Linden, Jf},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sahani, Linden - 2003 - Evidence optimization techniques for estimating stimulus-response functions.pdf:pdf},
isbn = {0-262-02550-7},
issn = {10495258},
journal = {Advances in neural information processing {\ldots}},
pages = {317--324},
title = {{Evidence optimization techniques for estimating stimulus-response functions}},
url = {http://discovery.ucl.ac.uk/120944/},
year = {2003}
}
@article{Ioannou1996,
abstract = {This book was previously published by Pearson Education, Inc., formerly known as Prentice-Hall, Inc. No part of this book should be published or used for commercial purposes or sold without the prior written approval of the authors.},
author = {Ioannou, Petros a. and Sun, Jing and List, Preface},
doi = {10.1007/978-1-4757-1895-9_1},
isbn = {0486498174 {\textless}a href="javascript:" cref="CitaviPicker0486498174"{\textgreater}{\textless}img style="border: 0px none;height: px;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAsZJREFUeNpkU11IFVEQ/s7u5k/},
issn = {0486498174 {\textless}a href="javascript:" cref="CitaviPicker0486498174"{\textgreater}{\textless}img style="border: 0px none;height: px;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAsZJREFUeNpkU11IFVEQ/s7u5k/},
journal = {N/a},
keywords = {Adaptive,Control,Introduction},
pages = {821},
title = {{Robust Adaptive Control}},
url = {http://www-rcf.usc.edu/{~}ioannou/Robust{\_}Adaptive{\_}Control.htm},
volume = {N/A},
year = {1996}
}
@article{Lin,
abstract = {Channelrhodopsin 2 (ChR2), a light-activated nonselective cationic channel from Chlamydomonas reinhardtii, has become a useful tool to excite neurons into which it is transfected. The other ChR from Chlamydomonas, ChR1, has attracted less attention because of its proton-selective permeability. By making chimeras of the transmembrane domains of ChR1 and ChR2, combined with site-directed mutagenesis, we developed a ChR variant, named ChEF, that exhibits significantly less inactivation during persistent light stimulation. ChEF undergoes only 33{\%} inactivation, compared with 77{\%} for ChR2. Point mutation of Ile170 of ChEF to Val (yielding "ChIEF") accelerates the rate of channel closure while retaining reduced inactivation, leading to more consistent responses when stimulated above 25 Hz in both HEK293 cells and cultured hippocampal neurons. In addition, these variants have altered spectral responses, light sensitivity, and channel selectivity. ChEF and ChIEF allow more precise temporal control of depolarization, and can induce action potential trains that more closely resemble natural spiking patterns. ?? 2009 by the Biophysical Society.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lin, John Y. and Lin, Michael Z and Steinbach, Paul and Tsien, Roger Y},
doi = {10.1016/j.bpj.2008.11.034},
eprint = {arXiv:1011.1669v3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Lin et al. - Unknown - Characterization of Engineered Channelrhodopsin Variants with Improved Properties and Kinetics.pdf:pdf},
isbn = {1542-0086},
issn = {00063495},
journal = {Biophysical Journal},
number = {5},
pages = {1803--1814},
pmid = {19254539},
title = {{Characterization of engineered channelrhodopsin variants with improved properties and kinetics}},
url = {http://ac.els-cdn.com/S0006349509000162/1-s2.0-S0006349509000162-main.pdf?{\_}tid=69f697cc-6d30-11e7-85ea-00000aab0f6b{\&}acdnat=1500544216{\_}86ae194f760f0ccbd9d383dd090b8e26},
volume = {96},
year = {2009}
}
@article{Orban2016,
abstract = {Neural responses in the visual cortex are variable, and there is now an abundance of data characterizing how the magnitude and structure of this variability depends on the stimulus. Current theories of cortical computation fail to account for these data; they either ignore variability altogether or only model its unstructured Poisson-like aspects. We develop a theory in which the cortex performs probabilistic inference such that population activity patterns represent statistical samples from the inferred probability distribution. Our main prediction is that perceptual uncertainty is directly encoded by the variability, rather than the average, of cortical responses. Through direct comparisons to previously published data as well as original data analyses, we show that a sampling-based probabilistic representation accounts for the structure of noise, signal, and spontaneous response variability and correlations in the primary visual cortex. These results suggest a novel role for neural variability in cortical dynamics and computations.},
author = {Orb{\'{a}}n, Gergő and Berkes, Pietro and Fiser, J{\'{o}}zsef and Lengyel, M{\'{a}}t{\'{e}}},
doi = {10.1016/j.neuron.2016.09.038},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(7).pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {Bayesian computations,V1,natural images,noise correlations,normative model,spontaneous activity,stochastic sampling,theory,variability,vision},
month = {oct},
number = {2},
pages = {530--543},
pmid = {27764674},
title = {{Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316306390},
volume = {92},
year = {2016}
}
@misc{Seung2003a,
abstract = {It is well-known that chemical synaptic transmission is an unreliable process, but the function of such unreliability remains unclear. Here I consider the hypothesis that the randomness of synaptic transmission is harnessed by the brain for learning, in analogy to the way that genetic mutation is utilized by Darwinian evolution. This is possible if synapses are "hedonistic," responding to a global reward signal by increasing their probabilities of vesicle release or failure, depending on which action immediately preceded reward. Hedonistic synapses learn by computing a stochastic approximation to the gradient of the average reward. They are compatible with synaptic dynamics such as short-term facilitation and depression and with the intricacies of dendritic integration and action potential generation. A network of hedonistic synapses can be trained to perform a desired computation by administering reward appropriately, as illustrated here through numerical simulations of integrate-and-fire model neurons.},
author = {Seung, H Sebastian},
booktitle = {Neuron},
doi = {10.1016/S0896-6273(03)00761-X},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Seung - 2003 - Viewpoint Learning in Spiking Neural Networks by Reinforcement of Stochastic Synaptic Transmission.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
number = {6},
pages = {1063--1073},
pmid = {14687542},
title = {{Learning in spiking neural networks by reinforcement of stochastic synaptic transmission}},
volume = {40},
year = {2003}
}
@article{Yosinski2015,
abstract = {Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.},
archivePrefix = {arXiv},
arxivId = {1506.06579},
author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
eprint = {1506.06579},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Yosinski et al. - 2015 - Understanding Neural Networks Through Deep Visualization.pdf:pdf},
journal = {International Conference on Machine Learning - Deep Learning Workshop 2015},
pages = {12},
title = {{Understanding Neural Networks Through Deep Visualization}},
url = {http://arxiv.org/abs/1506.06579},
year = {2015}
}
@article{QuianQuiroga2009,
abstract = {To a large extent, progress in neuroscience has been driven by the study of single-cell responses averaged over several repetitions of stimuli or behaviours. However,the brain typically makes decisions based on single events by evaluating the activity of large neuronal populations. Therefore, to further understand how the brain processes information, it is important to shift from a single-neuron, multiple-trial framework to multiple-neuron, single-trial methodologies. Two related approaches--decoding and information theory--can be used to extract single-trial information from the activity of neuronal populations. Such population analysis can give us more information about how neurons encode stimulus features than traditional single-cell studies.},
annote = {NULL},
author = {{Quian Quiroga}, Rodrigo and Panzeri, Stefano},
doi = {10.1038/nrn2578},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(6).pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Brain,Brain: physiology,Computer-Assisted,Humans,Information Theory,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Neurophysiology,Neurophysiology: methods,Signal Processing},
number = {3},
pages = {173--85},
pmid = {19229240},
title = {{Extracting information from neuronal populations: information theory and decoding approaches.}},
url = {http://www.nature.com/doifinder/10.1038/nrn2578{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/19229240},
volume = {10},
year = {2009}
}
@article{Bialek1991,
abstract = {Traditional approaches to neural coding characterize the encoding of known stimuli in average neural responses. Organisms face nearly the opposite task--extracting information about an unknown time-dependent stimulus from short segments of a spike train. Here the neural code was characterized from the point of view of the organism, culminating in algorithms for real-time stimulus estimation based on a single example of the spike train. These methods were applied to an identified movement-sensitive neuron in the fly visual system. Such decoding experiments determined the effective noise level and fault tolerance of neural computation, and the structure of the decoding algorithms suggested a simple model for real-time analog signal processing with spiking neurons.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0005235},
author = {Bialek, William and Rieke, Fred and {de Ruyter van Steveninck}, R. and Warland, David},
doi = {10.1126/science.2063199},
eprint = {0005235},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Steveninck et al. - Unknown - Reading a Neural Code.pdf:pdf},
isbn = {0036-8075 (Print)},
issn = {0036-8075},
journal = {Science},
number = {5014},
pages = {1854--1857},
pmid = {2063199},
primaryClass = {cond-mat},
title = {{Reading a neural code}},
url = {https://papers.nips.cc/paper/272-reading-a-neural-code.pdf http://www.sciencemag.org/cgi/doi/10.1126/science.2063199},
volume = {252},
year = {1991}
}
@article{Smith,
abstract = {Understanding how an animal's ability to learn relates to neural activity or is altered by lesions, different attentional states, pharmacological interventions, or genetic manipulations are central questions in neuroscience. Although learning is a dynamic process, current analyses do not use dynamic estimation methods, require many trials across many animals to establish the occurrence of learning, and provide no consensus as how best to identify when learning has occurred. We develop a state-space model paradigm to characterize learning as the probability of a correct response as a function of trial number (learning curve). We compute the learning curve and its confidence intervals using a state-space smoothing algorithm and define the learning trial as the first trial on which there is reasonable certainty ({\textgreater}0.95) that a subject performs better than chance for the balance of the experiment. For a range of simulated learning experiments, the smoothing algorithm estimated learning curves with smaller mean integrated squared error and identified the learning trials with greater reliability than commonly used methods. The smoothing algorithm tracked easily the rapid learning of a monkey during a single session of an association learning experiment and identified learning 2 to 4 d earlier than accepted criteria for a rat in a 47 d procedural learning experiment. Our state-space paradigm estimates learning curves for single animals, gives a precise definition of learning, and suggests a coherent statistical framework for the design and analysis of learning experiments that could reduce the number of animals and trials per animal that these studies require.},
author = {Smith, Anne C and Frank, Loren M and Wirth, Sylvia and Yanike, Marianna and Hu, Dan and Kubota, Yasuo and Graybiel, Ann M and Suzuki, Wendy A and Brown, Emery N},
doi = {10.1523/JNEUROSCI.2908-03.2004},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Smith et al. - Unknown - BehavioralSystemsCognitive Dynamic Analysis of Learning in Behavioral Experiments.pdf:pdf},
isbn = {1529-2401 (Electronic)},
issn = {1529-2401},
journal = {J. Neurosci.},
keywords = {a previously,a result of experience,an animal can perform,association task,be defined as a,behavior,change in behavior as,change-point test,em algorithm,hidden markov model,investigated by showing that,learning,learning is a dynamic,learning is usually,process that generally can,space model,state},
number = {2},
pages = {447--461},
pmid = {14724243},
title = {{Dynamic Analysis of Learning in Behavioral Experiments}},
url = {http://www.jneurosci.org/content/jneuro/24/2/447.full.pdf http://www.jneurosci.org/cgi/content/abstract/24/2/447{\%}5Cnhttp://www.jneurosci.org/cgi/reprint/24/2/447.pdf},
volume = {24},
year = {2004}
}
@article{Guo,
abstract = {Topographically organized maps of the sensory receptor epithelia are regarded as cornerstones of cortical organization as well as valuable readouts of diverse biological processes ranging from evolution to neural plasticity. However, maps are most often derived from multi-unit activity recorded in the thalamic input layers of anesthetized animals using near-threshold stimuli. Less distinct topography has been described by studies that deviated from the formula above, which brings into question the generality of the principle. Here, we explicitly compared the strength of tonotopic organization at various depths within core and belt regions of the auditory cortex using electrophysiological measurements ranging from single units to delta-band local field potentials (LFP) in the awake and anesthetized mouse. Unit recordings in the middle cortical layers revealed a precise tonotopic organization in core, but not belt, regions of auditory cortex that was similarly robust in awake and anesthetized conditions. In core fields, tonotopy was degraded outside the middle layers or when LFP signals were substituted for unit activity, due to an increasing proportion of recording sites with irregular tuning for pure tones. However, restricting our analysis to clearly defined receptive fields revealed an equivalent tonotopic organization in all layers of the cortical column and for LFP activity ranging from gamma to theta bands. Thus, core fields represent a transition between topographically organized simple receptive field arrangements that extend throughout all layers of the cortical column and the emergence of nontono-topic representations outside the input layers that are further elaborated in the belt fields.},
author = {Guo, Wei and Chambers, Anna R and Darrow, Keith N and Hancock, Kenneth E and Shinn-Cunningham, Barbara G and Polley, Daniel B},
doi = {10.1523/JNEUROSCI.0065-12.2012},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - Unknown - BehavioralSystemsCognitive Robustness of Cortical Topography across Fields, Laminae, Anesthetic States, and Ne(2).pdf:pdf},
keywords = {anaesthesia,auditory,cortex,topography},
mendeley-tags = {anaesthesia,auditory,cortex,topography},
title = {{Behavioral/Systems/Cognitive Robustness of Cortical Topography across Fields, Laminae, Anesthetic States, and Neurophysiological Signal Types}}
}
@article{Pitkow2015,
abstract = {Single sensory neurons can be surprisingly predictive of behavior in discrimination tasks. We propose this ispossible because sensory information extracted from neural populations is severely restricted, either by near-optimal decoding of a population with information-limiting correlations or by suboptimal decoding that is blind to correlations. These have different consequences for choice correlations, the correlations between neural responses and behavioral choices. In the vestibular and cerebellar nuclei and the dorsal medial superior temporal area, we found that choice correlations during heading discrimination are consistent with near-optimal decoding ofneuronal responses corrupted by information-limiting correlations. In the ventral intraparietal area, the choice correlations are also consistent with the presence of information-limiting correlations, but this area does not appear to influence behavior, although the choice correlations are particularly large. These findings demonstrate how choice correlations can be used to assess the efficiency of the downstream readout and detect the presence of information-limiting correlations. The activity of just one sensory neuron in the brain often accurately predicts what an animal will perceive in simple tests. Pitkow etal. provide a new theory of why this happens, and offer experimental data that support their theory.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Pitkow, Xaq and Liu, Sheng and Angelaki, Dora E and DeAngelis, Gregory C. and Pouget, Alexandre},
doi = {10.1016/j.neuron.2015.06.033},
eprint = {15334406},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pitkow et al. - 2015 - How Can Single Sensory Neurons Predict Behavior.pdf:pdf},
isbn = {doi:10.1016/j.neuron.2015.06.033},
issn = {10974199},
journal = {Neuron},
number = {2},
pages = {411--424},
pmid = {26182422},
title = {{How Can Single Sensory Neurons Predict Behavior?}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.06.033},
volume = {87},
year = {2015}
}
@article{Hershenhoren2014,
abstract = {Stimulus-specific adaptation (SSA) is the reduction in response to a common stimulus that does not generalize, or only partially generalizes, to rare stimuli. SSA is strong and widespread in primary auditory cortex (A1) of rats, but is weak or absent in the main input station to A1, the ventral division of the medial geniculate body. To study SSA in A1, we recorded neural activity in A1 intracellularly using sharp electrodes. We studied the responses to tone pips of the same frequency in different contexts: as Standard and Deviants in Oddball sequences; in equiprobable sequences; in sequences consisting of rare tone presentations; and in sequences composed of many different frequencies, each of which was rare. SSA was found both in subthreshold membrane potential fluctuations and in spiking responses of A1 neurons. SSA for changes in frequency was large at a frequency difference of 44{\%} between Standard and Deviant, and clearly present with tones separated by as little as 4{\%}, near the behavioral frequency difference limen in rats. When using equivalent measures, SSA in spiking responses was generally larger than the SSA at the level of the membrane potential. This effect can be traced to the nonlinearity of the transformation between membrane potential to spikes. Using the responses to the same tone in different contexts made it possible to demonstrate that cortical SSA could not be fully explained by adaptation in narrow frequency channels, even at the level of the membrane potential. We conclude that local processing significantly contributes to the generation of cortical SSA.},
annote = {NULL},
author = {Hershenhoren, I. and Taaseh, N. and Antunes, F. M. and Nelken, I.},
doi = {10.1523/JNEUROSCI.2166-13.2014},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/HAKDT94G/3303.full.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {J Neurosci},
keywords = {Acoustic Stimulation,Action Potentials/physiology,Adaptation,Animals,Auditory Cortex/cytology/*physiology,Auditory Perception/*physiology,Auditory/*physiology,Biological,Evoked Potentials,Female,Gain control,Models,Neurons/*physiology,Physiological/*physiology,Psychoacoustics,Rats,SSA,intracellular,patch clamp,stimulus specific adaptation},
language = {en},
mendeley-tags = {Gain control,SSA,intracellular,patch clamp,stimulus specific adaptation},
month = {feb},
number = {9},
pages = {3303--3319},
pmid = {24573289},
title = {{Intracellular correlates of stimulus-specific adaptation}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2166-13.2014 http://www.jneurosci.org/content/jneuro/34/9/3303.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/24573289},
volume = {34},
year = {2014}
}
@article{Choromanska2015,
abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural net-work and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural net-work through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest crit-ical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local min-ima outside that band diminishes exponen-tially with the size of the network. We empir-ically verify that the mathematical model ex-hibits similar behavior as the computer sim-ulations, despite the presence of high depen-dencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large-and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.0233v3},
author = {Choromanska, Anna and LeCunn, Yan and {Ben Arous}, Gerard},
eprint = {arXiv:1412.0233v3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Choromanska, LeCunn, Ben Arous - 2015 - Open Problem The landscape of the loss surfaces of multilayer networks.pdf:pdf},
isbn = {1412.0233},
issn = {15337928},
journal = {Conference on Learning Theory},
keywords = {deep learning,hamiltonian,multilayer networks,non-,spherical spin-glass model},
number = {2014},
pages = {1--5},
title = {{Open Problem : The landscape of the loss surfaces of multilayer networks}},
volume = {40},
year = {2015}
}
@article{Stringer2016,
abstract = {Our brains contain billions of neurons, which are continually producing electrical signals to relay information around the brain. Yet most of our knowledge of how the brain works comes from studying the activity of one neuron at a time. Recently, studies of multiple neurons have shown that they tend to be active together in short bursts called “up” states, which are followed by periods in which they are less active called “down” states. When we are sleeping or under a general anesthetic, the neurons may be completely silent during down states, but when we are awake the difference in activity between the two states is usually less extreme. However, it is still not clear how the neurons generate these patterns of activity. To address this question, Stringer et al. studied the activity of neurons in the brains of awake and anesthetized rats, mice and gerbils. The experiments recorded electrical activity from many neurons at the same time and found a wide range of different activity patterns. A computational model based on these data suggests that differences in the degree to which some neurons suppress the activity of other neurons may account for this variety. Increasing the strength of these inhibitory signals in the model decreased the fluctuations in electrical activity across entire areas of the brain. Further analysis of the experimental data supported the model's predictions by showing that inhibitory neurons – which act to reduce electrical activity in other neurons – were more active when there were fewer fluctuations in activity across the brain. The next step following on from this work would be to develop ways to build computer models that can mimic the activity of many more neurons at the same time. The models could then be used to interpret the electrical activity produced by many different kinds of neuron. This will enable researchers to test more sophisticated hypotheses about how the brain works.},
author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas A and Okun, Michael and Bartho, Peter and Harris, Kenneth D and Sahani, Maneesh and Lesica, Nicholas A and Abbott, LF. and Dayan, P. and Amit, DJ. and Brunel, N. and Averbeck, BB. and Latham, PE. and Pouget, A. and Barth{\'{o}}, P. and Hirase, H. and Monconduit, L. and Zugaro, M. and Harris, KD. and Buzs{\'{a}}ki, G. and Bathellier, B. and Ushakova, L. and Rumpel, S. and Bennett, C. and Arroyo, S. and Hestrin, S. and Berridge, CW. and Waterhouse, BD. and Buran, BN. and von Trapp, G. and Sanes, DH. and Cardin, JA. and Carl{\'{e}}n, M. and Meletis, K. and Knoblich, U. and Zhang, F. and Deisseroth, K. and Tsai, LH. and Moore, CI. and Castro-Alamancos, MA. and Gulati, T. and Chen, N. and Sugihara, H. and Sur, M. and Cho, KH. and Jang, JH. and Jang, HJ. and Kim, MJ. and Yoon, SH. and Fukuda, T. and Tennigkeit, F. and Singer, W. and Rhie, DJ. and Churchland, MM. and Abbott, LF. and Churchland, MM. and Yu, BM. and Cunningham, JP. and Sugrue, LP. and Cohen, MR. and Corrado, GS. and Newsome, WT. and Clark, AM. and Hosseini, P. and Scott, BB. and Bradley, DC. and Smith, MA. and Kohn, A. and Movshon, JA. and Armstrong, KM. and Moore, T. and Chang, SW. and Snyder, LH. and Lisberger, SG. and Priebe, NJ. and Finn, IM. and Ferster, D. and Ryu, SI. and Santhanam, G. and Sahani, M. and Shenoy, KV. and Cohen, L. and Mizrahi, A. and Cohen, MR. and Kohn, A. and Cohen, MR. and Maunsell, JH. and Malina, K. Cohen-Kashi and Mohar, B. and Rappaport, AN. and Lampl, I. and Compte, A. and Sanchez-Vives, MV. and McCormick, DA. and Wang, XJ. and Constantinople, CM. and Bruno, RM. and Cossell, L. and Iacaruso, MF. and Muir, DR. and Houlton, R. and Sader, EN. and Ko, H. and Hofer, SB. and Mrsic-Flogel, TD. and Crochet, S. and Poulet, JF. and Kremer, Y. and Petersen, CC. and Curto, C. and Sakata, S. and Marguet, S. and Itskov, V. and Harris, KD. and de la Rocha, J. and Doiron, B. and Shea-Brown, E. and Josi{\'{c}}, K. and Reyes, A. and Destexhe, A. and Doiron, B. and Litwin-Kumar, A. and Rosenbaum, R. and Ocker, GK. and Josi{\'{c}}, K. and Ecker, AS. and Berens, P. and Cotton, RJ. and Subramaniyan, M. and Denfield, GH. and Cadwell, CR. and Smirnakis, SM. and Bethge, M. and Tolias, AS. and Ecker, AS. and Berens, P. and Keliris, GA. and Bethge, M. and Logothetis, NK. and Tolias, AS. and Ecker, AS. and Berens, P. and Tolias, AS. and Bethge, M. and Erisken, S. and Vaiceliunaite, A. and Jurjut, O. and Fiorini, M. and Katzner, S. and Busse, L. and Fino, E. and Yuste, R. and Garcia-Lazaro, JA. and Belliveau, LA. and Lesica, NA. and Gentet, LJ. and Avermann, M. and Matyas, F. and Staiger, JF. and Petersen, CC. and Gentet, LJ. and Kremer, Y. and Taniguchi, H. and Huang, ZJ. and Staiger, JF. and Petersen, CC. and Goard, M. and Dan, Y. and Goris, RL. and Movshon, JA. and Simoncelli, EP. and Gutierrez, GJ. and O'Leary, T. and Marder, E. and Haider, B. and H{\"{a}}usser, M. and Carandini, M. and Hansen, BJ. and Chelaru, MI. and Dragoi, V. and Harris, KD. and Thiele, A. and Hofer, SB. and Ko, H. and Pichler, B. and Vogelstein, J. and Ros, H. and Zeng, H. and Lein, E. and Lesica, NA. and Mrsic-Flogel, TD. and Isaacson, JS. and Scanziani, M. and Izhikevich, EM. and Edelman, GM. and Jones, BE. and Kato, HK. and Gillet, SN. and Peters, AJ. and Isaacson, JS. and Komiyama, T. and Kawaguchi, Y. and Kubota, Y. and Kuchibhotla, K. and Gill, J. and Papadoyannis, E. and Sten, H. and Froemke, R. and Latham, PE. and Richmond, BJ. and Nelson, PG. and Nirenberg, S. and Lee, AM. and Hoy, JL. and Bonci, A. and Wilbrecht, L. and Stryker, MP. and Niell, CM. and Lee, SH. and Kwan, AC. and Zhang, S. and Phoumthipphavong, V. and Flannery, JG. and Masmanidis, SC. and Taniguchi, H. and Huang, ZJ. and Zhang, F. and Boyden, ES. and Deisseroth, K. and Dan, Y. and Lee, WC. and Bonin, V. and Reed, M. and Graham, BJ. and Hood, G. and Glattfelder, K. and Reid, RC. and Litwin-Kumar, A. and Doiron, B. and Loebel, A. and Nelken, I. and Tsodyks, M. and London, M. and Roth, A. and Beeren, L. and H{\"{a}}usser, M. and Latham, PE. and Luczak, A. and Barth{\'{o}}, P. and Harris, KD. and Lyamzin, DR. and Barnes, SJ. and Donato, R. and Garcia-Lazaro, JA. and Keck, T. and Lesica, NA. and Macke, JH. and Buesing, L. and Cunningham, JP. and Byron, MY. and Shenoy, KV. and Sahani, M. and Madisen, L. and Mao, T. and Koch, H. and Zhuo, JM. and Berenyi, A. and Fujisawa, S. and Hsu, YW. and Garcia, AJ. and Gu, X. and Zanella, S. and Kidney, J. and Gu, H. and Mao, Y. and Hooks, BM. and Boyden, ES. and Buzs{\'{a}}ki, G. and Ramirez, JM. and Jones, AR. and Svoboda, K. and Han, X. and Turner, EE. and Zeng, H. and Marder, E. and Goeritz, ML. and Otopalik, AG. and Markram, H. and Muller, E. and Ramaswamy, S. and Reimann, MW. and Abdellah, M. and Sanchez, CA. and Ailamaki, A. and Alonso-Nanclares, L. and Antille, N. and Arsever, S. and Kahou, GA. and Berger, TK. and Bilgili, A. and Buncic, N. and Chalimourda, A. and Chindemi, G. and Courcol, JD. and Delalondre, F. and Delattre, V. and Druckmann, S. and Dumusc, R. and Dynes, J. and Eilemann, S. and Gal, E. and Gevaert, ME. and Ghobril, JP. and Gidon, A. and Graham, JW. and Gupta, A. and Haenel, V. and Hay, E. and Heinis, T. and Hernando, JB. and Hines, M. and Kanari, L. and Keller, D. and Kenyon, J. and Khazen, G. and Kim, Y. and King, JG. and Kisvarday, Z. and Kumbhar, P. and Lasserre, S. and B{\'{e}}, JV. Le and Magalh{\~{a}}es, BR. and Merch{\'{a}}n-P{\'{e}}rez, A. and Meystre, J. and Morrice, BR. and Muller, J. and Mu{\~{n}}oz-C{\'{e}}spedes, A. and Muralidhar, S. and Muthurasa, K. and Nachbaur, D. and Newton, TH. and Nolte, M. and Ovcharenko, A. and Palacios, J. and Pastor, L. and Perin, R. and Ranjan, R. and Riachi, I. and Rodr{\'{i}}guez, JR. and Riquelme, JL. and R{\"{o}}ssert, C. and Sfyrakis, K. and Shi, Y. and Shillcock, JC. and Silberberg, G. and Silva, R. and Tauheed, F. and Telefont, M. and Toledo-Rodriguez, M. and Tr{\"{a}}nkler, T. and Geit, W. Van and D{\'{i}}az, JV. and Walker, R. and Wang, Y. and Zaninetta, SM. and DeFelipe, J. and Hill, SL. and Segev, I. and Sch{\"{u}}rmann, F. and Markram, H. and Toledo-Rodriguez, M. and Wang, Y. and Gupta, A. and Silberberg, G. and Wu, C. and McGinley, MJ. and David, SV. and McCormick, DA. and McGinley, MJ. and Vinck, M. and Reimer, J. and Batista-Brito, R. and Zagha, E. and Cadwell, CR. and Tolias, AS. and Cardin, JA. and McCormick, DA. and Mitchell, JF. and Sundberg, KA. and Reynolds, JH. and Mochol, G. and Hermoso-Mendizabal, A. and Sakata, S. and Harris, KD. and de la Rocha, J. and Moore, AK. and Wehr, M. and Moreno-Bote, R. and Beck, J. and Kanitscheider, I. and Pitkow, X. and Latham, P. and Pouget, A. and Niell, CM. and Stryker, MP. and Nowak, LG. and Azouz, R. and Sanchez-Vives, MV. and Gray, CM. and McCormick, DA. and Okun, M. and Steinmetz, NA. and Cossell, L. and Iacaruso, MF. and Ko, H. and Barth{\'{o}}, P. and Moore, T. and Hofer, SB. and Mrsic-Flogel, TD. and Carandini, M. and Harris, KD. and Otazu, GH. and Tai, LH. and Yang, Y. and Zador, AM. and Pachitariu, M. and Lyamzin, DR. and Sahani, M. and Lesica, NA. and Pachitariu, M. and Petreska, B. and Sahani, M. and Pachitariu, M. and Steinmetz, N. and Kadir, S. and Carandini, M. and Harris, KD. and Packer, AM. and Yuste, R. and Pakan, JM. and Lowe, SC. and Dylda, E. and Keemink, SW. and Currie, SP. and Coutts, CA. and Rochefort, NL. and Parga, N. and Abbott, LF. and Pfeffer, CK. and Xue, M. and He, M. and Huang, ZJ. and Scanziani, M. and Pillow, JW. and Shlens, J. and Paninski, L. and Sher, A. and Litke, AM. and Chichilnisky, EJ. and Simoncelli, EP. and Polack, PO. and Friedman, J. and Golshani, P. and Renart, A. and de la Rocha, J. and Bartho, P. and Hollender, L. and Parga, N. and Reyes, A. and Harris, KD. and Rossant, C. and Kadir, SN. and Goodman, DF. and Schulman, J. and Hunter, ML. and Saleem, AB. and Grosmark, A. and Belluscio, M. and Denfield, GH. and Ecker, AS. and Tolias, AS. and Solomon, S. and Buzs{\'{a}}ki, G. and Carandini, M. and Harris, KD. and Rubin, DB. and Hooser, SD. Van and Miller, KD. and Sachidhanandam, S. and Sreenivasan, V. and Kyriakatos, A. and Kremer, Y. and Petersen, CC. and Sakata, S. and Harris, KD. and Sakata, S. and Harris, KD. and Sakata, S. and Sanchez-Vives, MV. and Mattia, M. and Compte, A. and Perez-Zabalza, M. and Winograd, M. and Descalzo, VF. and Reig, R. and Sanchez-Vives, MV. and McCormick, DA. and Schneider, DM. and Nelson, A. and Mooney, R. and Sch{\"{o}}lvinck, ML. and Saleem, AB. and Benucci, A. and Harris, KD. and Carandini, M. and Seybold, BA. and Phillips, EA. and Schreiner, CE. and Hasenstaub, AR. and Shadlen, MN. and Britten, KH. and Newsome, WT. and Movshon, JA. and Shapcott, KA. and Schmiedt, JT. and Saunders, RC. and Maier, A. and Leopold, DA. and Schmid, MC. and Sippy, T. and Yuste, R. and Stark, E. and Eichler, R. and Roux, L. and Fujisawa, S. and Rotstein, HG. and Buzs{\'{a}}ki, G. and Tan, AY. and Chen, Y. and Scholl, B. and Seidemann, E. and Priebe, NJ. and Tasic, B. and Menon, V. and Nguyen, TN. and Kim, TK. and Jarsky, T. and Yao, Z. and Levi, B. and Gray, LT. and Sorensen, SA. and Dolbeare, T. and Bertagnolli, D. and Goldy, J. and Shapovalova, N. and Parry, S. and Lee, C. and Smith, K. and Bernard, A. and Madisen, L. and Sunkin, SM. and Hawrylycz, M. and Koch, C. and Zeng, H. and Tsodyks, M. and Pawelzik, K. and Markram, H. and van Vreeswijk, C. and Sompolinsky, H. and Vinck, M. and Batista-Brito, R. and Knoblich, U. and Cardin, JA. and Vogels, TP. and Abbott, LF. and Wehr, M. and Zador, AM. and Wertz, A. and Trenholm, S. and Yonehara, K. and Hillier, D. and Raics, Z. and Leinweber, M. and Szalay, G. and Ghanem, A. and Keller, G. and R{\'{o}}zsa, B. and Conzelmann, KK. and Roska, B. and Wilson, NR. and Runyan, CA. and Wang, FL. and Sur, M. and Wolf, F. and Engelken, R. and Puelma-Touzel, M. and Weidinger, JD. and Neef, A. and Yu, X. and Ye, Z. and Houston, CM. and Zecharia, AY. and Ma, Y. and Zhang, Z. and Uygun, DS. and Parker, S. and Vyssotski, AL. and Yustos, R. and Franks, NP. and Brickley, SG. and Wisden, W. and Zhou, M. and Liang, F. and Xiong, XR. and Li, L. and Li, H. and Xiao, Z. and Tao, HW. and Zhang, LI. and Zhu, Y. and Qiao, W. and Liu, K. and Zhong, H. and Yao, H. and Zhuang, J. and Bereshpolova, Y. and Stoelzel, CR. and Huff, JM. and Hei, X. and Alonso, JM. and Swadlow, HA.},
doi = {10.1162/089976699300016827},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Abbott, Dayan - 1999 - The Effect of Correlated Variability on the Accuracy of a Population Code.pdf:pdf},
issn = {2050-084X},
journal = {Neural Computation},
keywords = {Gerbil,Mouse,Rat,inhibition,neural networks},
pages = {91--101},
pmid = {27926356},
publisher = {eLife Sciences Publications Limited},
title = {{Inhibitory control of correlated intrinsic variability in cortical networks}},
volume = {5},
year = {2016}
}
@article{Vidne2012,
abstract = {Synchronized spontaneous firing among retinal ganglion cells (RGCs), on timescales faster than visual responses, has been reported in many studies. Two candidate mechanisms of synchronized firing include direct coupling and shared noisy inputs. In neighboring parasol cells of primate retina, which exhibit rapid synchronized firing that has been studied extensively, recent experimental work indicates that direct electrical or synaptic coupling is weak, but shared synaptic input in the absence of modulated stimuli is strong. However, previous modeling efforts have not accounted for this aspect of firing in the parasol cell population. Here we develop a new model that incorporates the effects of common noise, and apply it to analyze the light responses and synchronized firing of a large, densely-sampled network of over 250 simultaneously recorded parasol cells. We use a generalized linear model in which the spike rate in each cell is determined by the linear combination of the spatio-temporally filtered visual input, the temporally filtered prior spikes of that cell, and unobserved sources representing common noise. The model accurately captures the statistical structure of the spike trains and the encoding of the visual stimulus, without the direct coupling assumption present in previous modeling work. Finally, we examined the problem of decoding the visual stimulus from the spike train given the estimated parameters. The common-noise model produces Bayesian decoding performance as accurate as that of a model with direct coupling, but with significantly more robustness to spike timing perturbations.},
author = {Vidne, Michael and Ahmadian, Yashar and Shlens, Jonathon and Pillow, Jonathan W and Kulkarni, Jayant and Litke, Alan M and Chichilnisky, E J and Simoncelli, Eero and Paninski, Liam},
doi = {10.1007/s10827-011-0376-2},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Vidne et al. - 2012 - Modeling the impact of common noise inputs on the network activity of retinal ganglion cells.pdf:pdf},
isbn = {1573-6873 (Electronic)$\backslash$r0929-5313 (Linking)},
issn = {09295313},
journal = {Journal of Computational Neuroscience},
keywords = {Generalized linear model,Multielectrode,Random-effects model,Recording,Retina,State-space model},
number = {1},
pages = {97--121},
pmid = {22203465},
title = {{Modeling the impact of common noise inputs on the network activity of retinal ganglion cells}},
url = {http://download.springer.com/static/pdf/714/art{\%}253A10.1007{\%}252Fs10827-011-0376-2.pdf?originUrl=http{\%}3A{\%}2F{\%}2Flink.springer.com{\%}2Farticle{\%}2F10.1007{\%}2Fs10827-011-0376-2{\&}token2=exp=1496228360{~}acl={\%}2Fstatic{\%}2Fpdf{\%}2F714{\%}2Fart{\%}25253A10.1007{\%}25252Fs10827-011-037},
volume = {33},
year = {2012}
}
@article{Durstewitz,
abstract = {One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight. {\textcopyright} 2010 Elsevier Inc.},
author = {Durstewitz, Daniel and Vittoz, Nicole M and Floresco, Stan B and Seamans, Jeremy K},
doi = {10.1016/j.neuron.2010.03.029},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Durstewitz et al. - Unknown - Abrupt Transitions between Prefrontal Neural Ensemble States Accompany Behavioral Transitions during Rule.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
number = {3},
pages = {438--448},
pmid = {20471356},
title = {{Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning}},
url = {http://ac.els-cdn.com/S0896627310002321/1-s2.0-S0896627310002321-main.pdf?{\_}tid=97fb7292-1f7d-11e7-b62c-00000aab0f26{\&}acdnat=1492001173{\_}fb889ddff26e3808ee6ee82b80dfdc72},
volume = {66},
year = {2010}
}
@article{Cossell2015,
abstract = {The strength of synaptic connections fundamentally determines how neurons influence each other's firing. Excitatory connection ampli-tudes between pairs of cortical neurons vary over two orders of mag-nitude, comprising only very few strong connections among many weaker ones 1–9 . Although this highly skewed distribution of connec-tion strengths is observed in diverse cortical areas 1–9 , its functional significance remains unknown: it is not clear how connection strength relates to neuronal response properties, nor how strong and weak in-puts contribute to information processing in local microcircuits. Here we reveal that the strength of connections between layer 2/3 (L2/3) pyramidal neurons in mouse primary visual cortex (V1) obeys a simple rule—the few strong connections occur between neurons with most correlated responses, while only weak connections link neurons with uncorrelated responses. Moreover, we show that strong and reciprocal connections occur between cells with similar spatial receptive field structure. Although weak connections far outnumber strong connec-tions, each neuron receives the majority of its local excitation from a small number of strong inputs provided by the few neurons with similar responses to visual features. By dominating recurrent excita-tion, these infrequent yet powerful inputs disproportionately contrib-ute to feature preference and selectivity. Therefore, our results show that the apparently complex organization of excitatory connection strength reflects the similarity of neuronal responses, and suggest that rare, strong connections mediate stimulus-specific response amp-lification in cortical microcircuits. To determine the relationship between connection strength and neur-onal responses, we used a combination of two-photon calcium imaging in vivo and whole-cell recordings in vitro in L2/3 of mouse V1 10 (Fig. 1). We first examined how connection strength relates to the degree of correlated firing between pairs of neurons. We obtained pairwise correla-tion coefficients of responses to a sequence of static natural images (see Methods) from L2/3 neurons labelled with the calcium-sensitive indicator OGB-1 (ref. 11; imaged volumes ,260 3 260 3 56 mm; Fig. 1a, b). The distribution of pairwise response correlations was highly skewed: correla-tions were generally low, and only a small fraction of pairs were highly correlated during visual stimulation (median correlation coefficient: 0.012; mean correlation coefficient 6 s.d.: 0.021 6 0.051; range: 20.12 to 0.67; Fig. 1c; Extended Data Fig.},
author = {Cossell, Lee and Iacaruso, Maria Florencia and Muir, Dylan R and Houlton, Rachael and Sader, Elie N and Ko, Ho and Hofer, Sonja B and Mrsic-Flogel, Thomas D},
doi = {10.1038/nature14182},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cossell et al. - 2015 - Functional organization of excitatory synaptic strength in primary visual cortex.pdf:pdf},
journal = {Nature},
title = {{Functional organization of excitatory synaptic strength in primary visual cortex}},
volume = {518},
year = {2015}
}
@article{Wang2003,
abstract = {Policy gradient methods based on REINFORCEr$\backslash$n$\backslash$ne model-free in the sense that they$\backslash$n$\backslash$nestimate the gradient using only online experiences$\backslash$n$\backslash$nexecuting the current stochastic policy.$\backslash$n$\backslash$nThis is extremely wasteful of training$\backslash$n$\backslash$ndata as well as being computationally inefficient.$\backslash$n$\backslash$nThis paper presents a new modelbased$\backslash$n$\backslash$npolicy gradient algorithm that uses$\backslash$n$\backslash$ntraining experiences much more efficiently.$\backslash$n$\backslash$nOur approach constructs a series of incomplete$\backslash$n$\backslash$nmodels of the MDP, and then applies$\backslash$n$\backslash$nthese models to compute the policy gradient$\backslash$n$\backslash$nin closed form. The paper describes an algorithm$\backslash$n$\backslash$nthat alternates between pruning (to remove$\backslash$n$\backslash$nirrelevant parts of the incomplete MDP$\backslash$n$\backslash$nmodel), exploration (to gather training data$\backslash$n$\backslash$nin the relevant parts of the state space), and$\backslash$n$\backslash$ngradient ascent search. We show experimental$\backslash$n$\backslash$nresults on several benchmarkp roblemsi ncluding$\backslash$n$\backslash$nresource-constrained scheduling. The$\backslash$n$\backslash$noverall feasibility of this approach depends$\backslash$n$\backslash$non whether a sufficiently informative partial$\backslash$n$\backslash$nmodel can fit into available memory.},
author = {Wang, Xin and Dietterich, Thomas G},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Dietterlch - Unknown - Model-based Policy Gradient Reinforcement Learning.pdf:pdf},
isbn = {1577351894},
journal = {International Conference on Machine Learning},
pages = {776--783},
title = {{Model-based Policy Gradient Reinforcement Learning}},
url = {http://www.citeulike.org/user/szityu/article/219678},
year = {2003}
}
@article{Crunelli2010,
abstract = {The slow ({\textless}1 Hz) rhythm, the most important electroencephalogram (EEG) signature of non–rapid eye movement (NREM) sleep, is generally viewed as originating exclusively from neocortical networks. Here we argue that the full manifestation of this fundamental sleep oscillation in a corticothalamic module requires the dynamic interaction of three cardinal oscillators: one predominantly synaptically based cortical oscillator and two intrinsic, conditional thalamic oscillators. The functional implications of this hypothesis are discussed in relation to other EEG features of NREM sleep, with respect to coordinating activities in local and distant neuronal assemblies and in the context of facilitating cellular and network plasticity during slow-wave sleep.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Crunelli, Vincenzo and Hughes, Stuart W},
doi = {http://www.nature.com/neuro/journal/v13/n1/suppinfo/nn.2445_S1.html},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Crunelli, Hughes - 2010 - The slow (1 Hz) rhythm of non-REM sleep a dialogue between three cardinal oscillators.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {1},
pages = {9--17},
pmid = {19966841},
title = {{The slow ({\textless}1 Hz) rhythm of non-REM sleep: a dialogue between three cardinal oscillators}},
url = {http://www.nature.com/neuro/journal/v13/n1/pdf/nn.2445.pdf http://dx.doi.org/10.1038/nn.2445},
volume = {13},
year = {2010}
}
@article{Sadtler2014a,
abstract = {Learning, whether motor, sensory or cognitive, requires networks of neurons to generate new activity patterns. As some behaviours are easier to learn than others, we asked if some neural activity patterns are easier to generate than others. Here we investigate whether an existing network constrains the patterns that a subset of its neurons is capable of exhibiting, and if so, what principles define this constraint. We employed a closed-loop intracortical brain-computer interface learning paradigm in which Rhesus macaques (Macaca mulatta) controlled a computer cursor by modulating neural activity patterns in the primary motor cortex. Using the brain-computer interface paradigm, we could specify and alter how neural activity mapped to cursor velocity. At the start of each session, we observed the characteristic activity patterns of the recorded neural population. The activity of a neural population can be represented in a high-dimensional space (termed the neural space), wherein each dimension corresponds to the activity of one neuron. These characteristic activity patterns comprise a low-dimensional subspace (termed the intrinsic manifold) within the neural space. The intrinsic manifold presumably reflects constraints imposed by the underlying neural circuitry. Here we show that the animals could readily learn to proficiently control the cursor using neural activity patterns that were within the intrinsic manifold. However, animals were less able to learn to proficiently control the cursor using activity patterns that were outside of the intrinsic manifold. These results suggest that the existing structure of a network can shape learning. On a timescale of hours, it seems to be difficult to learn to generate neural activity patterns that are not consistent with the existing network structure. These findings offer a network-level explanation for the observation that we are more readily able to learn new skills when they are related to the skills that we already possess.},
author = {Sadtler, Patrick T and Quick, Kristin M and Golub, Matthew D and Chase, Steven M and Ryu, Stephen I and Tyler-Kabara, Elizabeth C and Yu, Byron M and Batista, Aaron P},
doi = {10.1038/nature13665},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sadtler et al. - 2014 - Neural constraints on learning(2).pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7515},
pages = {423--426},
pmid = {25164754},
title = {{Neural constraints on learning}},
url = {https://www.nature.com/nature/journal/v512/n7515/pdf/nature13665.pdf http://www.nature.com/doifinder/10.1038/nature13665},
volume = {512},
year = {2014}
}
@article{Sutton1999,
abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the ¯rst time that a version of policy iteration with arbitrary di{\textregistered}erentiable function approximation is convergent to a locally optimal policy.},
author = {Sutton, Richard S and Mcallester, David and Singh, Satinder and Mansour, Yishay},
doi = {10.1.1.37.9714},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sutton et al. - 1999 - Policy Gradient Methods for Reinforcement Learning with Function Approximation.pdf:pdf},
isbn = {0-262-19450-3},
issn = {0047-2875},
journal = {Advances in Neural Information Processing Systems 12},
pages = {1057--1063},
publisher = {MIT Press},
title = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},
year = {1999}
}
@article{Williams1992,
author = {Williams, Ronald J.},
doi = {10.1007/BF00992696},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(2).pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {may},
number = {3-4},
pages = {229--256},
title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
url = {http://link.springer.com/10.1007/BF00992696},
volume = {8},
year = {1992}
}
@article{Ruderman1994,
abstract = {We study the statistics of an ensemble of images taken in the woods. Distributions of local quantities such as contrast are scale invariant and have nearly exponential tails. Power spectra exhibit scaling with a nontrivial exponent. These data limit the information content of natural images and point to the importance of gain-control strategies in visual processing. PACS numbers: 42.30.Yc, 05.70,Jk, 42.66.Le Efficient signal processing systems take advantage of statistical structure in their input signals, both to reduce the effects of noise and to generate compact representa-tions of seemingly complex data. Since Barlow's discus-sion in 1959 [1], many authors have explored the possibil-ity that biological vision systems are designed to exploit the statistics of natural images [2]. It is diKcult, how-ever, to compare these ideas with experiment, because we know relatively little about the statistics of natural scenes. The fact that objects can appear on all possible angular scales leads to the hypothesis that natural im-ages should exhibit some form of scaling or self-similarity [3). Here we analyze an ensemble of images taken in the woods of Hacklebarney State Park in central New Jersey. These provide strong evidence for nontrivial scaling in the sense of statistical mechanics, and we discuss some im-plications of these results for our understanding of early},
author = {Ruderman, Daniel L and Bialek, William},
doi = {10.1103/PhysRevLett.73.814},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ruderman, Bialek ' - 1994 - Statistics of Natural Images Scaling in the Woods.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {aug},
number = {6},
pages = {814--817},
title = {{Statistics of natural images: Scaling in the woods}},
url = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.73.814 papers2://publication/uuid/99D494DE-3995-4949-9350-71AD231B8C97 https://link.aps.org/doi/10.1103/PhysRevLett.73.814},
volume = {73},
year = {1994}
}
@article{Ishizuka2005,
abstract = {Neurons become photosensitive by genetically introducing one of green algae-derived protein, channelrhodopsin-2 (ChR2). Here, we quantitatively investigated the rapidness of the light-gated current of ChR2 expressed in PC12 cells using blue light-emitting diode (LED) light. The light-gated current consists of two components, inactivating and non-inactivating. The magnitude of inactivating component was almost linearly related to the light intensity. The non-inactivating component showed a tendency to saturate at high illumination. Both the activation and inactivation rates of the light-gated current were linearly dependent on the light intensity. However, the activation rate (turning-on rate) is about 10-fold faster than the inactivation rate. Although the turning-off time constant was little dependent on the light intensity, that at the end of 1 s light pulse was about two-fold larger than that at 20 ms. Neurons are also made photosensitive by the expression of ChR2 in the living animal. Since both the turning-on and turning-off time constants of light-gated current was smaller than the membrane time constant of neurons, the LED light illumination of the photosensitive neurons was enough to evoke action potentials in a pulse-to-pulse manner in an acute slice of hippocampus. ?? 2005 Elsevier Ireland Ltd and the Japan Neuroscience Society. All rights reserved.},
author = {Ishizuka, Toru and Kakuda, Masaaki and Araki, Rikita and Yawo, Hiromu},
doi = {10.1016/j.neures.2005.10.009},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ishizuka et al. - 2005 - Kinetic evaluation of photosensitivity in genetically engineered neurons expressing green algae light-gated cha.pdf:pdf},
isbn = {0168-0102 (Print)$\backslash$n0168-0102 (Linking)},
issn = {01680102},
journal = {Neuroscience Research},
keywords = {Channel kinetics,Chlamydomonas,Hippocampus,Light-emitting diode (LED),PC12,Rhodopsin,Time constant},
number = {2},
pages = {85--94},
pmid = {16298005},
title = {{Kinetic evaluation of photosensitivity in genetically engineered neurons expressing green algae light-gated channels}},
url = {http://ac.els-cdn.com/S0168010205002762/1-s2.0-S0168010205002762-main.pdf?{\_}tid=cfde9af2-6d31-11e7-9a93-00000aab0f27{\&}acdnat=1500544816{\_}6718d1c36369465b13abaa0a1978bd98},
volume = {54},
year = {2006}
}
@article{Tervo2014,
abstract = {Behavioral choices that ignore prior experience promote exploration and unpredictability but are seemingly at odds with the brain's tendency to use experience to optimize behavioral choice. Indeed, when faced with virtual competitors, primates resort to strategic counterprediction rather than to stochastic choice. Here, we show that rats also use history- and model-based strategies when faced with similar competitors but can switch to a "stochastic" mode when challenged with a competitor that they cannot defeat by counterprediction. In this mode, outcomes associated with an animal's actions are ignored, and normal engagement of anterior cingulate cortex (ACC) is suppressed. Using circuit perturbations in transgenic rats, we demonstrate that switching between strategic and stochastic behavioral modes is controlled by locus coeruleus input into ACC. Our findings suggest that, under conditions of uncertainty about environmental rules, changes in noradrenergic input alter ACC output and prevent erroneous beliefs from guiding decisions, thus enabling behavioral variation. PaperClip},
author = {Tervo, Dougal G R and Proskurin, Mikhail and Manakov, Maxim and Kabra, Mayank and Vollmer, Alison and Branson, Kristin and Karpova, Alla Y},
doi = {10.1016/j.cell.2014.08.037},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Tervo et al. - 2014 - Behavioral variability through stochastic choice and its gating by anterior cingulate cortex.pdf:pdf},
isbn = {1097-4172 (Electronic)$\backslash$r0092-8674 (Linking)},
issn = {10974172},
journal = {Cell},
number = {1},
pages = {21--32},
pmid = {25259917},
title = {{Behavioral variability through stochastic choice and its gating by anterior cingulate cortex}},
url = {http://dx.doi.org/10.1016/j.cell.2014.08.037},
volume = {159},
year = {2014}
}
@article{Runyan2017,
abstract = {The cortex represents information across widely varying timescales 1–5 . For instance, sensory cortex encodes stimuli that fluctuate over few tens of milliseconds 6,7 , whereas in association cortex behavioural choices can require the maintenance of information over seconds 8,9 . However, it remains poorly understood whether diverse timescales result mostly from features intrinsic to individual neurons or from neuronal population activity. This question remains unanswered, because the timescales of coding in populations of neurons have not been studied extensively, and population codes have not been compared systematically across cortical regions. Here we show that population codes can be essential to achieve long coding timescales. Furthermore, we find that the properties of population codes differ between sensory and association cortices. We compared coding for sensory stimuli and behavioural choices in auditory cortex and posterior parietal cortex as mice performed a sound localization task. Auditory stimulus information was stronger in auditory cortex than in posterior parietal cortex, and both regions contained choice information. Although auditory cortex and posterior parietal cortex coded information by tiling in time neurons that were transiently informative for approximately 200 milliseconds, the areas had major differences in functional coupling between neurons, measured as activity correlations that could not be explained by task events. Coupling among posterior parietal cortex neurons was strong and extended over long time lags, whereas coupling among auditory cortex neurons was weak and short-lived. Stronger coupling in posterior parietal cortex led to a population code with long timescales and a representation of choice that remained consistent for approximately 1 second. In contrast, auditory cortex had a code with rapid fluctuations in stimulus and choice information over hundreds of milliseconds. Our results reveal that population codes differ across cortex and that coupling is a variable property of cortical populations that affects the timescale of information coding and the accuracy of behaviour. The goal of this work was to compare coding across cortical regions for two key features of behavioural tasks: stimulus and choice. We developed a sound localization task in which mice reported percep-tual decisions by navigating through a visual virtual reality T-maze 10 (Fig. 1a). As mice ran down the T-stem, a sound cue was played from one of eight possible locations in head-centred, real-world coordinates. Mice reported whether the sound originated from their left or right by turning in that direction at the T-intersection (Fig. 1b, c). We focused on auditory cortex (AC), because it is necessary for sound localization tasks 11},
author = {Runyan, Caroline A and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D},
doi = {10.1038/nature23020},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Runyan et al. - 2017 - Distinct timescales of population coding across cortex.pdf:pdf;:Users/Yves/Documents/Papers/coupled{\_}SI.pdf:pdf},
issn = {0028-0836},
journal = {Nature Publishing Group},
number = {7665},
pages = {92--96},
pmid = {28723889},
title = {{Distinct timescales of population coding across cortex}},
url = {https://www.nature.com/nature/journal/v548/n7665/pdf/nature23020.pdf http://dx.doi.org/10.1038/nature23020},
volume = {548},
year = {2017}
}
@article{Rigas,
abstract = {During behavioral quiescence, the neocortex generates spontaneous slow oscillations that consist of Up and Down states. Up states are short epochs of persistent activity that resemble the activated neocortex during arousal and cognition. Although Up states are generated within the cortex, the impact of extrinsic (thalamocortical) and intrinsic (intracortical) inputs on the persistent activity is not known. Using thalamocortical slices, we found that the persistent cortical activity during spontaneous Up states effectively drives thalamocortical relay cells through corticothalamic connections. However, thalamic activity can also precede the onset of cortical Up states, which suggests a role of thalamic activity in triggering cortical Up states through thalamocortical connections. In support of this hypothesis, we found that cutting the connections between thalamus and cortex reduced the incidence of spontaneous Up states in the cortex. Consistent with a facilitating role of thalamic activity on Up states, electrical or chemical stimulation of the thalamus triggered cortical Up states very effectively and enhanced those occurring spontaneously. In contrast, stimulation of the cortex triggered Up states only at very low intensities but otherwise had a suppressive effect on Up states. Moreover, cortical stimulation suppressed the facilitating effect of thalamic stimulation on Up states. In conclusion, thalamocortical inputs facilitate and intracortical inputs suppress cortical Up states. Thus, extrinsic and intrinsic cortical inputs differentially regulate persistent activity, which may serve to adjust the processing state of thalamocortical networks during behavior.},
author = {Rigas, Pavlos and Castro-Alamancos, Manuel A},
doi = {10.1523/JNEUROSCI.0003-07.2007},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Rigas, Castro-Alamancos - 2007 - Thalamocortical Up states differential effects of intrinsic and extrinsic cortical inputs on persistent.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Affect,Affect: physiology,Animals,Arousal,Arousal: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Inbred BALB C,Membrane Potentials,Membrane Potentials: physiology,Mice,Nerve Net,Nerve Net: physiology,Patch-Clamp Techniques,Thalamus,Thalamus: physiology,arousal,cortex,down state,slow oscillation,thalamocortical slice,thalamus},
number = {16},
pages = {4261--72},
pmid = {17442810},
title = {{Thalamocortical Up states: differential effects of intrinsic and extrinsic cortical inputs on persistent activity.}},
url = {http://www.jneurosci.org/content/jneuro/27/16/4261.full.pdf http://www.ncbi.nlm.nih.gov/pubmed/17442810},
volume = {27},
year = {2007}
}
@article{Wilson2016,
author = {Wilson, Daniel E and Whitney, David E and Scholl, Benjamin and Fitzpatrick, David},
doi = {10.1038/nn.4323},
file = {:Users/Yves/Downloads/nn.4323.pdf:pdf},
journal = {Nature Neuroscience},
keywords = {dendrites,dendritic integration,orientation tuning,vision},
mendeley-tags = {dendrites,dendritic integration,orientation tuning,vision},
month = {jun},
number = {8},
pages = {1003--1009},
publisher = {Nature Research},
title = {{Orientation selectivity and the functional clustering of synaptic inputs in primary visual cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.4323},
volume = {19},
year = {2016}
}
@article{Tsitsiklis1997,
abstract = {— We discuss the temporal-difference learning algo-rithm, as applied to approximating the cost-to-go function of an infinite-horizon discounted Markov chain. The algorithm we analyze updates parameters of a linear function approximator on-line during a single endless trajectory of an irreducible aperiodic Markov chain with a finite or infinite state space. We present a proof of convergence (with probability one), a characterization of the limit of convergence, and a bound on the resulting approxi-mation error. Furthermore, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning. In addition to proving new and stronger positive results than those previously available, we identify the significance of on-line updating and potential hazards associated with the use of nonlinear function approximators. First, we prove that diver-gence may occur when updates are not based on trajectories of the Markov chain. This fact reconciles positive and negative results that have been discussed in the literature, regarding the soundness of temporal-difference learning. Second, we present an example illustrating the possibility of divergence when temporal-difference learning is used in the presence of a nonlinear function approximator.},
author = {Tsitsiklis, John N and Roy, Benjamin Van},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Tsitsiklis, Roy - 1997 - An Analysis of Temporal-Difference Learning with Function Approximation.pdf:pdf},
journal = {IEEE TRANSACTIONS ON AUTOMATIC CONTROL},
keywords = {Index Terms— Dynamic programming,Markov chains,function approxima-tion,neuro-dynamic programming,reinforce-ment learning,temporal-difference learning},
number = {5},
title = {{An Analysis of Temporal-Difference Learning with Function Approximation}},
volume = {42},
year = {1997}
}
@article{Slivkins,
abstract = {In the multi-armed bandit (MAB) problem there are k distributions associated with the rewards of playing each of k strategies (slot machine arms). The reward distributions are initially unknown to the player. The player iteratively plays one strat-egy per round, observes the associated reward, and decides on the strategy for the next iteration. The goal is to maximize the reward by balancing ex-ploitation: the use of acquired information, with exploration: learning new information. We introduce and study a dynamic MAB prob-lem in which the reward functions stochastically and gradually change in time. Specifically, the ex-pected reward of each arm follows a Brownian mo-tion, a discrete random walk, or similar processes. In this setting a player has to continuously keep ex-ploring in order to adapt to the changing environ-ment. Our formulation is (roughly) a special case of the notoriously intractable restless MAB prob-lem. Our goal here is to characterize the cost of learn-ing and adapting to the changing environment, in terms of the stochastic rate of the change. We con-sider an infinite time horizon, and strive to min-imize the average cost per step which we define with respect to a hypothetical algorithm that at ev-ery step plays the arm with the maximum expected reward at this step. A related line of work on the adversarial MAB problem used a significantly weaker benchmark, the best time-invariant policy. The dynamic MAB problem models a variety of practical online, game-against-nature type opti-mization settings. While building on prior work, algorithms and steady-state analysis for the dynamic setting require a novel approach based on different stochastic tools.},
author = {Slivkins, Aleksandrs and Upfal, Eli},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Slivkins, Upfal - Unknown - Adapting to a Changing Environment the Brownian Restless Bandits.pdf:pdf},
title = {{Adapting to a Changing Environment: the Brownian Restless Bandits}}
}
@article{Cohen,
abstract = {No matter how hard subjects concentrate on a task, their minds wander {\{}(Raichle{\}} et al., 2001; Buckner et al., 2008; Christoff et al., 2009; Killingsworth and Gilbert, 2010). Internal fluctuations cannot be measured behaviorally or from conventional neurophysiological measures, so their effects on performance have been difficult to study. Previously, we measured fluctuations in visual attention using the responses of populations of simultaneously recorded neurons in macaque visual cortex {\{}(Cohen{\}} and Maunsell, 2010). Here, we use this ability to investigate how attentional fluctuations affect performance. We found that attentional fluctuations have large and complex effects on performance, the sign of which depends on the difficulty of the perceptual judgment. As expected, attention greatly improves the detection of subtle changes in a stimulus. Surprisingly, we found that attending too strongly to a particular stimulus impairs the ability to notice when that stimulus changes dramatically. Our results suggest that all previously reported measures of behavioral performance should be viewed as amalgamations of different attentional states, whether or not those studies specifically addressed attention.},
author = {Cohen, Marlene R and Maunsell, John H R},
doi = {10.1523/JNEUROSCI.3063-11.2011},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cohen, Maunsell - Unknown - When Attention Wanders How Uncontrolled Fluctuations in Attention Affect Performance.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
number = {44},
pages = {15802--15806},
pmid = {22049423},
title = {{When Attention Wanders: How Uncontrolled Fluctuations in Attention Affect Performance}},
url = {http://www.jneurosci.org/content/jneuro/31/44/15802.full.pdf http://dx.doi.org/10.1523/JNEUROSCI.3063-11.2011},
volume = {31},
year = {2011}
}
@article{Skinner1948,
abstract = {To say that a reinforcement is contingent upon a response may mean nothing more than that it follows the response . It may follow because of some mechanical connection or because of the mediation of another organism ; but conditioning takes place presumably because of the temporal relation only , expressed in terms of the order and proximity of response and reinforcement . Whenever we present a state of affairs which is known to be reinforcing at a given drive , we must suppose that conditioning takes place , even though we have paid no attention to the behavior of the organism in making the presentation . A simple experiment demonstrates this to be the case .},
author = {Skinner, B F},
doi = {10.1037/h0055873},
isbn = {0022-1015},
issn = {0022-1015},
journal = {Journal of experimental psychology},
keywords = {PSYCHOLOGY},
number = {2},
pages = {168--172},
pmid = {18913665},
title = {{Superstition in the pigeon.}},
volume = {38},
year = {1948}
}
@article{White2001,
abstract = {Sensory experience begins when neural circuits in the cerebral cortex are still immature; however, the contribution of experience to cortical maturation remains unclear. In the visual cortex, the selectivity of neurons for oriented stimuli at the time of eye opening is poor and increases dramatically after the onset of visual experience. Here we investigate whether visual experience has a significant role in the maturation of orientation selectivity and underlying cortical circuits using two forms of deprivation: dark rearing, which completely eliminates experience, and binocular lid suture, which alters the pattern of sensory driven activity. Orientation maps were present in dark-reared ferrets, but fully mature levels of tuning were never attained. In contrast, only rudimentary levels of orientation selectivity were observed in lid-sutured ferrets. Despite these differences, horizontal connections in both groups were less extensive and less clustered than normal, suggesting that long-range cortical processing is not essential for the expression of orientation selectivity, but may be needed for the full maturation of tuning. Thus, experience is beneficial or highly detrimental to cortical maturation, depending on the pattern of sensory driven activity.},
annote = {NULL},
author = {White, Leonard E. and Coppola, David M. and Fitzpatrick, David},
doi = {10.1038/35082568},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/MCMB5QFD/White et al. - 2001 - The contribution of sensory experience to the matu.pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Q4W87R4N/4111049a0.html:html},
issn = {0028-0836},
journal = {Nature},
keywords = {Cortex,development,ferret,orientation selectivity},
language = {en},
mendeley-tags = {Cortex,development,ferret,orientation selectivity},
month = {jun},
number = {6841},
pages = {1049--1052},
title = {{The contribution of sensory experience to the maturation of orientation selectivity in ferret visual cortex}},
url = {http://www.nature.com/nature/journal/v411/n6841/full/4111049a0.html http://www.nature.com/nature/journal/v411/n6841/pdf/4111049a0.pdf},
volume = {411},
year = {2001}
}
@article{Kulkarni2007,
abstract = {Recent developments in multi-electrode recordings enable the simultaneous measurement of the spiking activity of many neurons. Analysis of such multineuronal data is one of the key challenge in computational neuroscience today. In this work, we develop a multivariate point-process model in which the observed activity of a network of neurons depends on three terms: (1) the experimentally-controlled stimulus; (2) the spiking history of the observed neurons; and (3) a hidden term that corresponds, for example, to common input from an unobserved population of neurons that is presynaptic to two or more cells in the observed population. We consider two models for the network firing-rates, one of which is computationally and analytically tractable but can lead to unrealistically high firing-rates, while the other with reasonable firing-rates imposes a greater computational burden. We develop an expectation-maximization algorithm for fitting the parameters of both the models. For the analytically tractable model the expectation step is based on a continuous-time implementation of the extended Kalman smoother, and the maximization step involves two concave maximization problems which may be solved in parallel. The other model that we consider necessitates the use of Monte Carlo methods for the expectation as well as maximization step. We discuss the trade-off involved in choosing between the two models and the associated methods. The techniques developed allow us to solve a variety of inference problems in a straightforward, computationally efficient fashion; for example, we may use the model to predict network activity given an arbitrary stimulus, infer a neuron's ring rate given the stimulus and the activity of the other observed neurons, and perform optimal stimulus decoding and prediction. We present several detailed simulation studies which explore the strengths and limitations of our approach.},
author = {Kulkarni, Jayant E. and Paninski, Liam},
doi = {10.1080/09548980701625173},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kulkarni, Paninski - 2007 - Common-input models for multiple neural spike-train data.pdf:pdf},
isbn = {0954-898X (Print)},
issn = {0954-898X},
journal = {Network: Computation in Neural Systems},
number = {4},
pages = {375--407},
pmid = {17943613},
title = {{Common-input models for multiple neural spike-train data}},
url = {http://www.tandfonline.com/action/journalInformation?journalCode=inet20 http://www.tandfonline.com/doi/full/10.1080/09548980701625173},
volume = {18},
year = {2007}
}
@article{Lubke,
abstract = {Cortical columns are the functional units of the neocortex that are particularly prominent in the " barrel " field of the somatosensory cortex. Here we describe the morphology of two classes of synaptically coupled excitatory neurons in layer 4 of the barrel cortex, spiny stellate, and star pyramidal cells, respectively. Within a single barrel, their somata tend to be organized in clusters. The dendritic arbors are largely confined to layer 4, except for the distal part of the apical dendrite of star pyramidal neurons that extends into layer 2/3. In contrast, the axon of both types of neurons spans the cortex from layer 1 to layer 6. The most prominent axonal projections are those to layers 4 and 2/3 where they are largely restricted to a single cortical column. In layers 5 and 6, a small fraction of axon collaterals projects also across cortical columns. Consistent with the dense axonal pro-jection to layers 4 and 2/3, the total number and density of boutons per unit axonal length was also highest there. Electron microscopy combined with GABA postimmunogold labeling re-vealed that most (Ͼ90{\{}{\%}{\}}) of the synaptic contacts were estab-lished on dendritic spines and shafts of excitatory neurons in layers 4 and 2/3. The largely columnar organization of dendrites and axons of both cell types, combined with the preferential and dense pro-jections within cortical layers 4 and 2/3, suggests that spiny stellate and star pyramidal neurons of layer 4 serve to amplify thalamic input and relay excitation vertically within a single cor-tical column.},
author = {L{\"{u}}bke, Joachim and Egger, Veronica and Sakmann, Bert and Feldmeyer, Dirk},
keywords = {axonal projection,barrel cortex,cortical column,intracellular labeling,layer 4,paired record-ings,spiny stellate cell,star pyra-midal neuron},
title = {{Columnar Organization of Dendrites and Axons of Single and Synaptically Coupled Excitatory Spiny Neurons in Layer 4 of the Rat Barrel Cortex}}
}
@inproceedings{Coquelin,
abstract = {Our setting is a Partially Observable Markov Decision Process with continuous state, observation and action spaces. Decisions are based on a Particle Filter for estimating the belief state given past observations. We consider a policy gradient approach for parameterized policy optimization. For that purpose, we investigate sensitivity analysis of the performance measure with respect to the parameters of the policy, focusing on Finite Difference (FD) techniques. We show that the naive FD is subject to variance explosion because of the non-smoothness of the resam- pling procedure. We propose a more sophisticated FD method which overcomes this problem and establish its consistency.},
author = {Coquelin, Pierre-Arnaud and Munos, R{\'{e}}mi},
booktitle = {NIPS},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Coquelin, Deguest, Munos - Unknown - Particle Filter-based Policy Gradient in POMDPs.pdf:pdf},
isbn = {9781605609492},
keywords = {Learning/Statistics {\&} Optimisation},
pages = {1--8},
title = {{Particle Filter-based Policy Gradient in POMDPs}},
url = {https://papers.nips.cc/paper/3397-particle-filter-based-policy-gradient-in-pomdps.pdf http://eprints.pascal-network.org/archive/00005143/},
year = {2008}
}
@article{Cohena,
abstract = {Visual attention improves perception for an attended location or feature and also modulates the responses of sensory neurons. In laboratory studies, the sensory stimuli and task instructions are held constant within an attentional condition, but despite experimenters' best efforts, attention likely varies from moment to moment. Because most previous studies have focused on single neurons, it has been impossible to use neuronal responses to identify attentional fluctuations and determine whether these are associated with changes in behavior. We show that an instantaneous measure of attention based on the responses of a modest number of neurons in area V4 of the rhesus monkey (Macaca mulatta) can reliably predict large changes in an animal's ability to perform a difficult psychophysical task. Unexpectedly, this measure shows that the amount of attention allocated at any moment to locations in opposite hemifields is uncorrelated, suggesting that animals allocate attention to each stimulus independently rather than moving their attentional focus from one location to another.},
author = {Cohen, Marlene R and Maunsell, John H R},
doi = {10.1523/JNEUROSCI.2171-10.2010},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cohen, Maunsell - Unknown - BehavioralSystemsCognitive A Neuronal Population Measure of Attention Predicts Behavioral Performance on Ind.pdf:pdf},
isbn = {0270-6474$\backslash$r1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {45},
pages = {15241--15253},
pmid = {21068329},
title = {{A Neuronal Population Measure of Attention Predicts Behavioral Performance on Individual Trials}},
url = {http://www.jneurosci.org/content/jneuro/30/45/15241.full.pdf http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2171-10.2010},
volume = {30},
year = {2010}
}
@article{Znamenskiy2013,
abstract = {The neural pathways by which information about the acoustic world reaches the auditory cortex are well characterized, but how auditory representations are transformed into motor commands is not known. Here we use a perceptual decision-making task in rats to study this transformation. We demonstrate the role of corticostriatal projection neurons in auditory decisions by manipulating the activity of these neurons in rats performing an auditory frequency-discrimination task. Targeted channelrhodopsin-2 (ChR2)-mediated stimulation of corticostriatal neurons during the task biased decisions in the direction predicted by the frequency tuning of the stimulated neurons, whereas archaerhodopsin-3 (Arch)-mediated inactivation biased decisions in the opposite direction. Striatal projections are widespread in cortex and may provide a general mechanism for the control of motor decisions by sensory cortex.},
author = {Znamenskiy, Petr and Zador, Anthony M},
doi = {10.1038/nature12077},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Znamenskiy, Zador - 2013 - Corticostriatal neurons in auditory cortex drive decisions during auditory discrimination.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7450},
pages = {482--485},
pmid = {23636333},
title = {{Corticostriatal neurons in auditory cortex drive decisions during auditory discrimination}},
url = {https://www.nature.com/nature/journal/v497/n7450/pdf/nature12077.pdf http://www.nature.com/doifinder/10.1038/nature12077},
volume = {497},
year = {2013}
}
@article{Busse2011,
abstract = {The mouse is becoming a key species for research on the neural circuits of the early visual system. To relate such circuits to perception, one must measure visually guided behavior and ask how it depends on fundamental stimulus attributes such as visual contrast. Using operant conditioning, we trained mice to detect visual contrast in a two-alternative forced-choice task. After 3–4 weeks of training, mice performed hundreds of trials in each session. Numerous sessions yielded high-quality psychometric curves from which we inferred measures of contrast sensitivity. In multiple sessions, however, choices were influenced not only by contrast, but also by estimates of reward value and by irrelevant factors such as recent failures and rewards. This behavior was captured by a generalized linear model involving not only the visual responses to the current stimulus but also a bias term and history terms depending on the outcome of the previous trial. We compared the behavioral performance of the mice to predictions of a simple decoder applied to neural responses measured in primary visual cortex of awake mice during passive viewing. The decoder performed better than the animal, suggesting that mice might not use optimally the information contained in the activity of visual cortex.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Busse, Laura and Ayaz, Asli and Dhruv, Neel T and Katzner, Steffen and Saleem, Aman B and Scholvinck, M. L. and Zaharia, Andrew D and Carandini, Matteo},
doi = {10.1523/JNEUROSCI.6689-10.2011},
eprint = {arXiv:1011.1669v3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Busse et al. - 2011 - The Detection of Visual Contrast in the Behaving Mouse.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {Journal of Neuroscience},
number = {31},
pages = {11351--11361},
pmid = {21813694},
title = {{The Detection of Visual Contrast in the Behaving Mouse}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.6689-10.2011},
volume = {31},
year = {2011}
}
@article{Kawai2015,
abstract = {Motor cortex is widely believed to underlie the acquisition and execution of motor skills, but its contributions to these processes are not fully understood. One reason is that studies on motor skills often conflate motor cortex's established role in dexterous control with roles in learning and producing task-specific motor sequences. To dissociate these aspects, we developed a motor task for rats that trains spatiotemporally precise movement patterns without requirements for dexterity. Remarkably, motor cortex lesions had no discernible effect on the acquired skills, which were expressed in their distinct pre-lesion forms on the very first day of post-lesion training. Motor cortex lesions prior to training, however, rendered rats unable to acquire the stereotyped motor sequences required for the task. These results suggest a remarkable capacity of subcortical motor circuits to execute learned skills and a previously unappreciated role for motor cortex in "tutoring" these circuits during learning. Motor cortex is widely credited with expanding the behavioral repertoire of mammals by enabling the acquisition and execution of new motor skills, but its specific contributions have been difficult to pin down. Using a novel motor skill learning paradigm, Kawai etal. show that motor cortex contributes to learning skills even when it is not required to execute them. This demonstrates a previously unappreciated role for motor cortex in "tutoring" subcortical circuits during skill learning.},
author = {Kawai, Risa and Markman, Timothy and Poddar, Rajesh and Ko, Raymond and Fantana, Antoniu L and Dhawale, Ashesh K and Kampff, Adam R and {\"{O}}lveczky, Bence P},
doi = {10.1016/j.neuron.2015.03.024},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kawai et al. - 2015 - Motor Cortex Is Required for Learning but Not for Executing a Motor Skill.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
number = {3},
pages = {800--812},
pmid = {25892304},
title = {{Motor Cortex Is Required for Learning but Not for Executing a Motor Skill}},
url = {http://ac.els-cdn.com/S0896627315002202/1-s2.0-S0896627315002202-main.pdf?{\_}tid=69cfc15a-2524-11e7-baca-00000aacb35f{\&}acdnat=1492622578{\_}476c0bfb6ebdbf1019a2aea1dab13c3a},
volume = {86},
year = {2015}
}
@article{Hoyera,
abstract = {The responses of cortical sensory neurons are notoriously variable, with the number of spikes evoked by identical stimuli varying significantly from trial to trial. This variability is most often interpreted as 'noise', purely detrimental to the sensory system. In this paper, we propose an al-ternative view in which the variability is related to the uncertainty, about world parameters, which is inherent in the sensory stimulus. Specifi-cally, the responses of a population of neurons are interpreted as stochas-tic samples from the posterior distribution in a latent variable model. In addition to giving theoretical arguments supporting such a representa-tional scheme, we provide simulations suggesting how some aspects of response variability might be understood in this framework.},
author = {Hoyer, Patrik O and Hyvarinen, Aapo},
doi = {10.1.1.71.1731},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Hoyer, Hyv{\"{a}}rinen - Unknown - Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior(2).pdf:pdf},
isbn = {0262025507},
issn = {1049-5258},
journal = {Advances in neural information processing systems},
number = {1},
pages = {293--300},
title = {{Interpreting neural response variability as Monte Carlo sampling of the posterior}},
url = {http://www.cis.hut.fi/phoyer/ http://books.google.com/books?hl=en{\&}lr={\&}id=AAVSDw4Rw9UC{\&}oi=fnd{\&}pg=PA293{\&}dq=Interpreting+Neural+Response+Variability+as+Monte+Carlo+Sampling+of+the+Posterior{\&}ots=U5tjvCjwAR{\&}sig=8EU3--mLxGZtqKQmDaaQSkNVuMA{\%}5Cnpapers3://publicat},
year = {2003}
}
@misc{Gomez-Marin2016,
abstract = {Over the past decade neuroscience has been attacking the problem of cognition with increasing vigor. Yet, what exactly is cognition, beyond a general signifier of anything seemingly complex the brain does? Here, we briefly review attempts to define, describe, explain, build, enhance and experience cognition. We highlight perspectives including psychology, molecular biology, computation, dynamical systems, machine learning, behavior and phenomenology. This survey of the landscape reveals not a clear target for explanation but a pluralistic and evolving scene with diverse opportunities for grounding future research. We argue that rather than getting to the bottom of it, over the next century, by deconstructing and redefining cognition, neuroscience will and should expand rather than merely reduce our concept of the mind.},
author = {Gomez-Marin, Alex and Mainen, Zachary F},
booktitle = {Current Opinion in Neurobiology},
doi = {10.1016/j.conb.2016.01.011},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Gomez-Marin, Mainen - 2016 - Expanding perspectives on cognition in humans, animals, and machines.pdf:pdf},
isbn = {10.1101/037192},
issn = {18736882},
pages = {85--91},
pmid = {26868042},
title = {{Expanding perspectives on cognition in humans, animals, and machines}},
url = {http://www.sciencedirect.com/science/article/pii/S095943881600012X},
volume = {37},
year = {2016}
}
@article{Pfister,
abstract = {In timing-based neural codes, neurons have to emit action potentials at precise moments in time. We use a supervised learning paradigm to derive a synaptic update rule that optimizes by gradient ascent the likelihood of postsynaptic firing at one or several desired firing times. We find that the optimal strategy of up- and downregulating synaptic efficacies depends on the relative timing between presynaptic spike arrival and desired postsynaptic firing. If the presynaptic spike arrives before the desired postsynaptic spike timing, our optimal learning rule predicts that the synapse should become potentiated. The dependence of the potentiation on spike timing directly reflects the time course of an excitatory postsynaptic potential. However, our approach gives no unique reason for synaptic depression under reversed spike timing. In fact, the presence and amplitude of depression of synaptic efficacies for reversed spike timing depend on how constraints are implemented in the optimization problem. Two different constraints, control of postsynaptic rates and control of temporal locality, are studied. The relation of our results to spike-timing-dependent plasticity and reinforcement learning is discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0502037v1},
author = {Pfister, Jean-Pascal and Toyoizumi, Taro and Barber, David and Gerstner, Wulfram},
doi = {10.1162/neco.2006.18.6.1318},
eprint = {0502037v1},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pfister et al. - Unknown - Optimal Spike-Timing-Dependent Plasticity for Precise Action Potential Firing in Supervised Learning.pdf:pdf},
isbn = {0899-7667 (Print)},
issn = {0899-7667},
journal = {Neural computation},
number = {6},
pages = {1318--1348},
pmid = {16764506},
primaryClass = {arXiv:q-bio},
title = {{Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning.}},
volume = {18},
year = {2006}
}
@article{Hirabayashi2013,
author = {Hirabayashi, T. and Takeuchi, D. and Tamura, K. and Miyashita, Y.},
doi = {10.1126/science.1236927},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(5).pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {jul},
number = {6142},
pages = {191--195},
title = {{Microcircuits for Hierarchical Elaboration of Object Coding Across Primate Temporal Areas}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1236927},
volume = {341},
year = {2013}
}
@article{Polack2013,
abstract = {Visual cortical neurons fire at higher rates to visual stimuli during locomotion than during immobility, while maintaining orientation selectivity. The mechanisms underlying this change in gain are not understood. We performed whole-cell recordings from layer 2/3 and layer 4 visual cortical excitatory neurons and from parvalbumin-positive and somatostatin-positive inhibitory neurons in mice that were free to rest or run on a spherical treadmill. We found that the membrane potential of all cell types became more depolarized and (with the exception of somatostatin-positive interneurons) less variable during locomotion. Cholinergic input was essential for maintaining the unimodal membrane potential distribution during immobility, whereas noradrenergic input was necessary for the tonic depolarization associated with locomotion. Our results provide a mechanism for how neuromodulation controls the gain and signal-to-noise ratio of visual cortical neurons during changes in the state of vigilance.},
annote = {NULL},
author = {Polack, Pierre-Olivier and Friedman, Jonathan and Golshani, Peyman},
doi = {10.1038/nn.3464},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Polack, Friedman, Golshani - 2013 - Cellular mechanisms of brain state–dependent gain modulation in visual cortex.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256, 1546-1726},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cortex,DNA-Binding Proteins,DNA-Binding Proteins: genetics,Female,Gain control,Immobilization,Inbred C57BL,Locomotion,Locomotion: drug effects,Locomotion: physiology,Male,Mice,Models,Neurological,Neurons,Neurons: classification,Neurons: drug effects,Neurons: physiology,Neurotransmitter Agents,Neurotransmitter Agents: pharmacology,Orientation,Orientation: drug effects,Orientation: physiology,Orientation: radiation effects,Parvalbumins,Parvalbumins: genetics,Patch-Clamp Techniques,Photic Stimulation,Signal-To-Noise Ratio,Transcription Factors,Transcription Factors: genetics,Transgenic,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,brain state},
mendeley-tags = {Cortex,Gain control,brain state},
month = {jul},
number = {9},
pages = {1331--1339},
pmid = {23872595},
title = {{Cellular mechanisms of brain state–dependent gain modulation in visual cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.3464 http://www.nature.com/neuro/journal/v16/n9/pdf/nn.3464.pdf},
volume = {16},
year = {2013}
}
@inproceedings{Wingate,
abstract = {We consider the problem of learning to act in partially observable, continuous-state-and-action worlds where we have abstract prior knowledge about the structure of the optimal policy in the form of a distribution over policies. Using ideas from planning-as-inference reductions and Bayesian un- supervised learning, we cast Markov Chain Monte Carlo as a stochastic, hill-climbing policy search algorithm. Importantly, this algorithm's search bias is directly tied to the prior and its MCMC proposal kernels, which means we can draw on the full Bayesian toolbox to express the search bias, including nonparametric priors and structured, recursive processes like grammars over action sequences. Furthermore, we can reason about uncertainty in the search bias itself by constructing a hierarchical prior and reasoning about latent variables that determine the abstract structure of the policy. This yields an adaptive search algorithm—our algorithm learns to learn a structured policy efficiently. We show how inference over the latent variables in these policy priors enables intra- and intertask transfer of abstract knowledge. We demonstrate the flexibility of this approach by learning meta search biases, by constructing a nonparametric finite state controller to model memory, by discovering motor primitives using a simple grammar over primitive actions, and by combining all three.},
author = {Wingate, David and Goodman, Noah D and Roy, Daniel M and Kaelbling, Leslie P and Tenenbaum, Joshua B},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.5591/978-1-57735-516-8/IJCAI11-263},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Wingate et al. - Unknown - Bayesian Policy Search with Policy Priors.pdf:pdf},
isbn = {9781577355120},
issn = {10450823},
pages = {1565--1570},
title = {{Bayesian policy search with policy priors}},
year = {2011}
}
@article{Jia2010,
author = {Jia, Hongbo and Rochefort, Nathalie L. and Chen, Xiaowei and Konnerth, Arthur},
doi = {10.1038/nature08947},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Jia et al. - 2010 - Dendritic organization of sensory input to cortical neurons in vivo.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {apr},
number = {7293},
pages = {1307--1312},
publisher = {Nature Research},
title = {{Dendritic organization of sensory input to cortical neurons in vivo}},
url = {http://www.nature.com/doifinder/10.1038/nature08947},
volume = {464},
year = {2010}
}
@article{Truccolo,
abstract = {Multiple factors simultaneously affect the spiking activity of individual neurons. Determining the effects and relative importance of these factors is a challenging problem in neurophysiology. We propose a statistical framework based on the point process likelihood function to relate a neuron's spiking probability to three typical covariates: the neuron's own spiking history, concurrent ensemble activity, and extrinsic covariates such as stimuli or behavior. The framework uses parametric models of the conditional intensity function to define a neuron's spiking probability in terms of the covariates. The discrete time likelihood function for point processes is used to carry out model fitting and model analysis. We show that, by modeling the logarithm of the conditional intensity function as a linear combination of functions of the covariates, the discrete time point process likelihood function is readily analyzed in the generalized linear model (GLM) framework. We illustrate our approach for both GLM and non-GLM likelihood functions using simulated data and multivariate single-unit activity data simultaneously recorded from the motor cortex of a monkey performing a visuomotor pursuit-tracking task. The point process framework provides a flexible, computationally efficient approach for maximum likelihood estimation, goodness-of-fit assessment, residual analysis, model selection, and neural decoding. The framework thus allows for the formulation and analysis of point process models of neural spiking activity that readily capture the simultaneous effects of multiple covariates and enables the assessment of their relative importance.},
author = {Truccolo, Wilson and Eden, Uri T and Fellows, Matthew R and Donoghue, John P and Brown, Emery N and John, P},
doi = {10.1152/jn.00697.2004},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Truccolo et al. - 2005 - A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble, and Extrins.pdf:pdf},
isbn = {0022-3077 (Print)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Neural Networks (Computer),Neurons,Neurons: physiology,Psychomotor Performance,Psychomotor Performance: physiology},
number = {2},
pages = {1074--1089},
pmid = {15356183},
title = {{A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble, and Extrinsic Covariate Effects}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15356183{\%}5Cnhttp://jn.physiology.org/cgi/doi/10.1152/jn.00697.2004},
volume = {93},
year = {2005}
}
@article{Akam2015,
abstract = {Author Summary Planning is the use of a predictive model of the consequences of actions to guide decision making. Planning plays a critical role in human behaviour, but isolating its contribution is challenging because it is complemented by control systems which learn values of actions directly from the history of reinforcement, resulting in automatized mappings from states to actions often termed habits. Our study examined a recently developed behavioural task which uses choices in a multi-step decision tree to differentiate planning from value-based control. We compared various strategies using simulations, showing a range that produce behaviour that resembles planning but in fact arises as a fixed mapping from particular sorts of states to action. These results show that when a planning problem is faced repeatedly, sophisticated automatization strategies may be developed which identify that there are in fact a limited number of relevant states of the world each with an appropriate fixed or habitual response. Understanding such strategies is important for the design and interpretation of tasks which aim to isolate the contribution of planning to behaviour. Such strategies are also of independent scientific interest as they may contribute to automatization of behaviour in complex environments.},
annote = {NULL},
author = {Akam, Thomas and Costa, Rui and Dayan, Peter},
doi = {10.1371/journal.pcbi.1004648},
editor = {Daunizeau, Jean},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Akam, Costa, Dayan - 2015 - Simple Plans or Sophisticated Habits State, Transition and Learning Interactions in the Two-Step Task.pdf:pdf},
isbn = {10.1371/journal.pcbi.1004648},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {dec},
number = {12},
pages = {e1004648},
pmid = {26657806},
title = {{Simple Plans or Sophisticated Habits? State, Transition and Learning Interactions in the Two-Step Task}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004648},
volume = {11},
year = {2015}
}
@article{Daw2011,
abstract = {The mesostriatal dopamine system is prominently implicated in model-free reinforcement learning, with fMRI BOLD signals in ventral striatum notably covarying with model-free prediction errors. However, latent learning and devaluation studies show that behavior also shows hallmarks of model-based planning, and the interaction between model-based and model-free values, prediction errors, and preferences is underexplored. We designed a multistep decision task in which model-based and model-free influences on human choice behavior could be distinguished. By showing that choices reflected both influences we could then test the purity of the ventral striatal BOLD signal as a model-free report. Contrary to expectations, the signal reflected both model-free and model-based predictions in proportions matching those that best explained choice behavior. These results challenge the notion of a separate model-free learner and suggest a more integrated computational architecture for high-level human decision-making. ?? 2011 Elsevier Inc.},
annote = {NULL},
author = {Daw, Nathaniel D. and Gershman, Samuel J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond J.},
doi = {10.1016/j.neuron.2011.02.027},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
month = {mar},
number = {6},
pages = {1204--1215},
pmid = {21435563},
title = {{Model-based influences on humans' choices and striatal prediction errors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627311001255},
volume = {69},
year = {2011}
}
@article{Park2011,
abstract = {Author Summary$\backslash$nA central problem in systems neuroscience is to understand how sensory neurons convert environmental stimuli into spike trains. The receptive field (RF) provides a simple model for the first stage in this encoding process: it is a linear filter that describes how the neuron integrates the stimulus over time and space. A neuron's RF can be estimated using responses to white noise or naturalistic stimuli, but traditional estimators such as the spike-triggered average tend to be noisy and require large amounts of data to converge. Here, we introduce a novel estimator that can accurately determine RFs with far less data. The key insight is that RFs tend to be localized in spacetime and spatiotemporal frequency. We introduce a family of prior distributions that flexibly incorporate these tendencies, using an approach known as empirical Bayes. These methods will allow experimentalists to characterize RFs more accurately and more rapidly, freeing more time for other experiments. We argue that locality, which is a structured form of sparsity, may play an important role in a wide variety of biological inference problems.},
author = {Park, Mijung and Pillow, Jonathan W},
doi = {10.1371/journal.pcbi.1002219},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Park, Pillow - 2011 - Receptive field inference with localized priors.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {10},
pmid = {22046110},
title = {{Receptive field inference with localized priors}},
volume = {7},
year = {2011}
}
@article{Peters2010,
abstract = {Policy gradient methods are a type of reinforcement learning techniques that rely upon optimizing parametrized policies with respect to the expected return (long-term cumulative reward) by gradient descent. They do not suffer from many of the problems that have been marring traditional reinforcement learning approaches such as the lack of guarantees of a value function, the intractability problem resulting from uncertain state information and the complexity arising from continuous states {\&} actions.},
author = {Peters, Jan},
doi = {10.4249/scholarpedia.3698},
isbn = {142440259X},
issn = {1941-6016},
journal = {Scholarpedia},
number = {11},
pages = {3698},
title = {{Policy gradient methods}},
volume = {5},
year = {2010}
}
@article{Andalman2009,
abstract = {$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n},
author = {Andalman, A. S. and Fee, M. S. and Andalman, AS. and Fee, MS. and Brainard, MS. and Doupe, AJ. and Charlesworth, JD. and Warren, TL. and Brainard, MS. and Hahnloser, RHR. and Kozhevnikov, AA. and Fee, MS. and Hamaguchi, K. and Tschida, KA. and Yoon, I. and Donald, BR. and Mooney, R. and Kozhevnikov, AA. and Fee, MS. and Long, MA. and Jin, DZ. and Fee, MS. and Nottebohm, F. and Stokes, TM. and Leonardo, CM. and Prather, JF. and Peters, S. and Nowicki, S. and Mooney, R. and Roy, A. and Mooney, R. and Tschida, KA. and Mooney, R. and Warren, TL. and Tumer, EC. and Charlesworth, JD. and Brainard, MS.},
doi = {10.1073/pnas.0903214106},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Andalman et al. - 2009 - A basal ganglia-forebrain circuit in the songbird biases motor output to avoid vocal errors.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {auditory feedback,birdsong,sensorimotor,zebra finch},
month = {jul},
number = {30},
pages = {12518--12523},
pmid = {19597157},
publisher = {National Academy of Sciences},
title = {{A basal ganglia-forebrain circuit in the songbird biases motor output to avoid vocal errors}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19597157 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2709669 http://www.pnas.org/cgi/doi/10.1073/pnas.0903214106},
volume = {106},
year = {2009}
}
@article{Gilbert1996,
abstract = {Cells in adult primary visual cortex are capable of integrating information over much larger portions of the visual field than was originally thought. Moreover, their receptive field properties can be altered by the context within which local features are presented and by changes in visual experience. The substrate for both spatial integration and cortical plasticity is likely to be found in a plexus of long-range horizontal connections, formed by cortical pyramidal cells, which link cells within each cortical area over distances of 6-8 mm. The relationship between horizontal connections and cortical functional architecture suggests a role in visual segmentation and spatial integration. The distribution of lateral interactions within striate cortex was visualized with optical recording, and their functional consequences were explored by using comparable stimuli in human psychophysical experiments and in recordings from alert monkeys. They may represent the substrate for perceptual phenomena such as illusory contours, surface fill-in, and contour saliency. The dynamic nature of receptive field properties and cortical architecture has been seen over time scales ranging from seconds to months. One can induce a remapping of the topography of visual cortex by making focal binocular retinal lesions. Shorter-term plasticity of cortical receptive fields was observed following brief periods of visual stimulation. The mechanisms involved entailed, for the short-term changes, altering the effectiveness of existing cortical connections, and for the long-term changes, sprouting of axon collaterals and synaptogenesis. The mutability of cortical function implies a continual process of calibration and normalization of the perception of visual attributes that is dependent on sensory experience throughout adulthood and might further represent the mechanism of perceptual learning.},
author = {Gilbert, C D and Das, a and Ito, M and Kapadia, M and Westheimer, G},
doi = {10.1073/pnas.93.2.615},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {2},
pages = {615--622},
pmid = {8570604},
title = {{Spatial integration and cortical dynamics.}},
volume = {93},
year = {1996}
}
@article{Caviness1980,
abstract = {The intracortical distributions of the thalamic projections to a large number of neocortical fields are studied by the anterograde degeneration methods in the mouse. The basic radial distribution of terminating thalamofugal axons is uniform throughout the mouse cortex and is essentially the same as that encountered in other mammalian species. Terminating axons are concentrated in three tiers: an outer tier in layer I, a middle tier in layers IV and/or III, and an inner tier in layer VI. In most fields, terminating axons also extend, to some extent, into layer V. Variations are encountered from field to field, particularly in the density and degree of divergence of projections and in the radial extent of individual tiers with respect to cytoarchitectonic layers. In accord with other studies, the thalamic projections to each field appear to be composed of two general axon classes. Class I axons terminate densely in the middle tier, seem to be of large caliber, and often have collaterals to the other tiers. Class II axons do not terminate densely in the middle tier and seem to be of small caliber. Terminating class II axons may be distributed to one or more tiers and may be concentrated in the inner and/or outer tiers. The thalamic projection to each field has its origin in multiple nuclei. All thalamic nuclei projecting to the neocortex appear to have class II projections and many also have class I projections. Patterns of degeneration in the cortex associated with lesions in different positions in many nuclei suggest that thalamic relay neurons are organized along "lines of projection"--neurons in the same line projecting to the same tangentially restricted cortical region. The neurons of origin of class I and class II axons are intermixed along the lines of projection.},
author = {Caviness, Verne S. and Frost, Douglas O.},
doi = {10.1002/cne.901940205},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Caviness, Frost - 1980 - Tangential organization of thalamic projections to the neocortex in the mouse.pdf:pdf},
isbn = {0021-9967 (Print)},
issn = {10969861},
journal = {Journal of Comparative Neurology},
number = {2},
pages = {335--367},
pmid = {7440806},
title = {{Tangential organization of thalamic projections to the neocortex in the mouse}},
volume = {194},
year = {1980}
}
@article{Carandini2011a,
author = {Carandini, Matteo and Heeger, David J.},
doi = {10.1038/nrn3136},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(9).pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {nov},
title = {full-text},
url = {http://www.nature.com/doifinder/10.1038/nrn3136},
year = {2011}
}
@article{Arous2009,
abstract = {Most animals display multiple behavioral states and control the time allocation to each of their activity phases depending on their environment. Here we develop a new quantitative method to analyze Caenorhabditis elegans behavioral states. We show that the dwelling and roaming two-state behavior of C. elegans is tightly controlled by the concentration of food in the environment of the animal. Sensory perception through the amphid neurons is necessary to extend roaming phases while internal metabolic perception of food nutritional value is needed to induce dwelling. Our analysis also shows that the proportion of time spent in each state is modulated by past nutritional experiences of the animal. This two-state behavior is regulated through serotonin as well as insulin and TGF-beta signaling pathways. We propose a model where food nutritional value is assessed through internal metabolic signaling. Biogenic amines signaling could allow the worm to adapt to fast changes in the environment when peptide transcriptional pathways may mediate slower adaptive changes.},
author = {{Ben Arous}, Juliette and Laffont, Sophie and Chatenay, Didier},
doi = {10.1371/journal.pone.0007584},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Arous, Laffont, Chatenay - 2009 - Molecular and Sensory Basis of a Food Related Two-State Behavior in C. elegans.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$n1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pmid = {19851507},
title = {{Molecular and sensory basis of a food related two-state behavior in C. elegans}},
volume = {4},
year = {2009}
}
@article{Berman2016,
abstract = {Even the simplest of animals exhibit behavioral sequences with complex temporal dynamics. Prominent amongst the proposed organizing principles for these dynamics has been the idea of a hierarchy, wherein the movements an animal makes can be understood as a set of nested sub-clusters. Although this type of organization holds potential advantages in terms of motion control and neural circuitry, measurements demonstrating this for an animal's entire behavioral repertoire have been limited in scope and temporal complexity. Here, we use a recently developed unsupervised technique to discover and track the occurrence of all stereotyped behaviors performed by fruit flies moving in a shallow arena. Calculating the optimally predictive representation of the fly's future behaviors, we show that fly behavior exhibits multiple time scales and is organized into a hierarchical structure that is indicative of its underlying behavioral programs and its changing internal states.},
archivePrefix = {arXiv},
arxivId = {1605.03626},
author = {Berman, Gordon J and Bialek, William and Shaevitz, Joshua W},
doi = {10.1073/pnas.1607601113},
eprint = {1605.03626},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Berman, Bialek, Shaevitz - 2016 - Predictability and hierarchy in Drosophila behavior.pdf:pdf},
isbn = {1216578109},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {42},
pages = {11943--11948},
pmid = {23112202},
title = {{Predictability and hierarchy in Drosophila behavior}},
url = {http://www.pnas.org/content/113/42/11943.full.pdf http://arxiv.org/abs/1605.03626{\%}0Ahttp://dx.doi.org/10.1073/pnas.1607601113 http://www.pnas.org/lookup/doi/10.1073/pnas.1607601113},
volume = {113},
year = {2016}
}
@article{Schmidt2013,
abstract = {Salient cues can prompt the rapid interruption of planned actions. It has been proposed that fast, reactive behavioral inhibition involves specific basal ganglia pathways, and we tested this by comparing activity in multiple rat basal ganglia structures during performance of a stop-signal task. Subthalamic nucleus (STN) neurons exhibited low-latency responses to 'Stop' cues, irrespective of whether actions were canceled or not. By contrast, neurons downstream in the substantia nigra pars reticulata (SNr) only responded to Stop cues in trials with successful cancellation. Recordings and simulations together indicate that this sensorimotor gating arises from the relative timing of two distinct inputs to neurons in the SNr dorsolateral 'core' subregion: cue-related excitation from STN and movement-related inhibition from striatum. Our results support race models of action cancellation, with stopping requiring Stop-cue information to be transmitted from STN to SNr before increased striatal input creates a point of no return.},
author = {Schmidt, Robert and Leventhal, Daniel K and Mallet, Nicolas and Chen, Fujun and Berke, Joshua D},
doi = {10.1038/nn.3456},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Schmidt et al. - 2013 - Canceling actions involves a race between basal ganglia pathways.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jul},
number = {8},
pages = {1118--1124},
pmid = {23852117},
title = {{Canceling actions involves a race between basal ganglia pathways}},
url = {http://www.nature.com/doifinder/10.1038/nn.3456 http://dx.doi.org/10.1038/nn.3456},
volume = {16},
year = {2013}
}
@misc{Friston2016,
abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
annote = {Up to date reference showing that the state space is specified as a prior in the experiments done by friston and co.},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
booktitle = {Neuroscience and Biobehavioral Reviews},
doi = {10.1016/j.neubiorev.2016.06.022},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Friston et al. - 2016 - Active inference and learning.pdf:pdf},
isbn = {0149-7634},
issn = {18737528},
keywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},
pages = {862--879},
pmid = {27375276},
title = {{Active inference and learning}},
url = {http://creativecommons.org/licenses/by/4.0/},
volume = {68},
year = {2016}
}
@book{Bellman1957,
abstract = {Dynamic Programming is a recursive method for solving sequential decision problems (hereafter abbre- viated as SDP). Also known as backward induction, it is used to find optimal decision rules in games against nature and subgame perfect equilibria of dynamic multi-agent games, and competitive equilib- ria in dynamic economic models. Dynamic programming has enabled economists to formulate and solve a huge variety of problems involving sequential decision making under uncertainty, and as a result it is now widely regarded as the single most important tool in economics. Section 2 provides a brief history of dynamic programming. Section 3 discusses some of the main theoretical results underlying dynamic programming, and its relation to game theory and optimal control theory. Section 4 provides a brief survey on numerical dynamic programming. Section 5 surveys the experimental and econometric literature that uses dynamic programming to construct empirical models economic behavior.},
annote = {NULL},
author = {Bellman, R},
booktitle = {Princeton University Press Princeton New Jersey},
doi = {10.1108/eb059970},
issn = {00029092},
pages = {342},
title = {{Dynamic Programming}},
url = {http://ajae.oxfordjournals.org/cgi/doi/10.2307/1241949},
volume = {70},
year = {1957}
}
@article{ClayReid1995,
author = {{Clay Reid}, R. and Alonso, Jose-Manuel},
doi = {10.1038/378281a0},
issn = {0028-0836},
journal = {Nature},
month = {nov},
number = {6554},
pages = {281--284},
publisher = {Nature Publishing Group},
title = {{Specificity of monosynaptic connections from thalamus to visual cortex}},
url = {http://www.nature.com/doifinder/10.1038/378281a0},
volume = {378},
year = {1995}
}
@article{Guo,
abstract = {Topographically organized maps of the sensory receptor epithelia are regarded as cornerstones of cortical organization as well as valuable readouts of diverse biological processes ranging from evolution to neural plasticity. However, maps are most often derived from multi-unit activity recorded in the thalamic input layers of anesthetized animals using near-threshold stimuli. Less distinct topography has been described by studies that deviated from the formula above, which brings into question the generality of the principle. Here, we explicitly compared the strength of tonotopic organization at various depths within core and belt regions of the auditory cortex using electrophysiological measurements ranging from single units to delta-band local field potentials (LFP) in the awake and anesthetized mouse. Unit recordings in the middle cortical layers revealed a precise tonotopic organization in core, but not belt, regions of auditory cortex that was similarly robust in awake and anesthetized conditions. In core fields, tonotopy was degraded outside the middle layers or when LFP signals were substituted for unit activity, due to an increasing proportion of recording sites with irregular tuning for pure tones. However, restricting our analysis to clearly defined receptive fields revealed an equivalent tonotopic organization in all layers of the cortical column and for LFP activity ranging from gamma to theta bands. Thus, core fields represent a transition between topographically organized simple receptive field arrangements that extend throughout all layers of the cortical column and the emergence of nontono-topic representations outside the input layers that are further elaborated in the belt fields.},
author = {Guo, Wei and Chambers, Anna R and Darrow, Keith N and Hancock, Kenneth E and Shinn-Cunningham, Barbara G and Polley, Daniel B},
doi = {10.1523/JNEUROSCI.0065-12.2012},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - Unknown - BehavioralSystemsCognitive Robustness of Cortical Topography across Fields, Laminae, Anesthetic States, and Ne(2).pdf:pdf},
keywords = {anaesthesia,auditory,cortex,topography},
mendeley-tags = {anaesthesia,auditory,cortex,topography},
title = {{Behavioral/Systems/Cognitive Robustness of Cortical Topography across Fields, Laminae, Anesthetic States, and Neurophysiological Signal Types}}
}
@article{Pineau2015,
author = {Pineau, J and Tamar, A and Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
doi = {10.1561/2200000049},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pineau et al. - 2015 - Bayesian Reinforcement Learning A Survey.pdf:pdf},
journal = {Foundations and Trends R in Machine Learning},
number = {5},
pages = {6--359},
title = {{Bayesian Reinforcement Learning: A Survey}},
volume = {8},
year = {2015}
}
@article{Park2013,
abstract = {We describe a set of fast, tractable methods for characterizing neural responses to high-dimensional sensory stimuli using a model we refer to as the generalized quadratic model (GQM). The GQM consists of a low-rank quadratic function fol- lowed by a point nonlinearity and exponential-family noise. The quadratic func- tion characterizes the neuron's stimulus selectivity in terms of a set linear receptive fields followed by a quadratic combination rule, and the invertible nonlinearity maps this output to the desired response range. Special cases of the GQM include the 2nd-order Volterra model [1, 2] and the elliptical Linear-Nonlinear-Poisson model [3]. Here we show that for “canonical form” GQMs, spectral decomposi- tion of the first two response-weighted moments yields approximate maximum- likelihood estimators via a quantity called the expected log-likelihood. The result- ing theory generalizes moment-based estimators such as the spike-triggered co- variance, and, in the Gaussian noise case, provides closed-form estimators under a large class of non-Gaussian stimulus distributions. We show that these estimators are fast and provide highly accurate estimates with far lower computational cost than full maximum likelihood. Moreover, theGQMprovides a natural framework for combining multi-dimensional stimulus sensitivity and spike-history dependen- cies within a single model. We show applications to both analog and spiking data using intracellular recordings of V1 membrane potential and extracellular record- ings of retinal spike trains.},
author = {Park, Il Memming and Archer, Evan W. and Priebe, Nicholas and Pillow, Jonathan W},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Park et al. - 2013 - Spectral methods for neural characterization using generalized quadratic models.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {2454--2462},
pmid = {1000106266},
title = {{Spectral methods for neural characterization using generalized quadratic models}},
url = {http://papers.nips.cc/paper/4993-spectral-methods-for-neural-characterization-using-generalized-quadratic-models},
volume = {26},
year = {2013}
}
@article{Smith2013,
author = {Smith, Spencer L. and Smith, Ikuko T. and Branco, Tiago and H{\"{a}}usser, Michael},
doi = {10.1038/nature12600},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Smith et al. - 2013 - Dendritic spikes enhance stimulus selectivity in cortical neurons in vivo.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {oct},
number = {7474},
pages = {115--120},
publisher = {Nature Research},
title = {{Dendritic spikes enhance stimulus selectivity in cortical neurons in vivo}},
url = {http://www.nature.com/doifinder/10.1038/nature12600},
volume = {503},
year = {2013}
}
@article{Girolami2011,
abstract = {The paper proposes Metropolis adjusted Langevin and Hamiltonian Monte Carlo sampling methods defined on the Riemann manifold to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The methods provide fully automated adaptation mechanisms that circumvent the costly pilot runs that are required to tune proposal densities for Metropolis-Hastings or indeed Hamiltonian Monte Carlo and Metropolis adjusted Langevin algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The methodology proposed exploits the Riemann geometry of the parameter space of statistical models and thus automatically adapts to the local structure when simulating paths across this manifold, providing highly efficient convergence and exploration of the target density. The performance of these Riemann manifold Monte Carlo methods is rigorously assessed by performing inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models and Bayesian estimation of dynamic systems described by non-linear differential equations. Substantial improvements in the time-normalized effective sample size are reported when compared with alternative sampling approaches. MATLAB code that is available from http://www.ucl.ac.uk/statistics/research/rmhmc allows replication of all the results reported.},
archivePrefix = {arXiv},
arxivId = {0907.1100},
author = {Girolami, Mark and Calderhead, Ben},
doi = {10.1111/j.1467-9868.2010.00765.x},
eprint = {0907.1100},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Girolami, Calderhead - 2011 - Riemann manifold Langevin and Hamiltonian Monte Carlo methods.pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Bayesian inference,Geometry in statistics,Hamiltonian Monte Carlo methods,Langevin diffusion,Markov chain Monte Carlo methods,Riemann manifolds},
month = {mar},
number = {2},
pages = {123--214},
publisher = {Blackwell Publishing Ltd},
title = {{Riemann manifold Langevin and Hamiltonian Monte Carlo methods}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2010.00765.x},
volume = {73},
year = {2011}
}
@article{Li2013,
abstract = {Animals learn both whether and when a reward will occur. Neural models of timing posit that animals learn the mean time until reward perturbed by a fixed relative uncertainty. Nonetheless, animals can learn to perform actions for reward even in highly variable natural environments. Optimal inference in the presence of variable information requires probabilistic models, yet it is unclear whether animals can infer such models for reward timing. Here, we develop a behavioral paradigm in which optimal performance required knowledge of the distribution from which reward delays were chosen. We found that mice were able to accurately adjust their behavior to the SD of the reward delay distribution. Importantly, mice were able to flexibly adjust the amount of prior information used for inference according to the moment-by-moment demands of the task. The ability to infer probabilistic models for timing may allow mice to adapt to complex and dynamic natural environments.},
author = {Li, Yi and Dudman, Joshua Tate},
doi = {10.1073/pnas.1310666110},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Li, Dudman - 2013 - Mice infer probabilistic models for timing.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Adaptation,Animal,Animal: physiology,Animals,Behavior,Biological,Learning,Learning: physiology,Mice,Models,Physiological},
month = {oct},
number = {42},
pages = {17154--17159},
pmid = {24082097},
title = {{Mice infer probabilistic models for timing}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3801012{\&}tool=pmcentrez{\&}rendertype=abstract{\%}5Cnhttp://www.pnas.org/cgi/doi/10.1073/pnas.1310666110 http://www.pnas.org/cgi/doi/10.1073/pnas.1310666110},
volume = {110},
year = {2013}
}
@article{Liu2011,
abstract = {We consider the restless multi-armed bandit (RMAB) problem with unknown dynamics in which a player chooses M out of N arms to play at each time. The reward state of each arm transits according to an unknown Markovian rule when it is played and evolves according to an arbitrary unknown random process when it is passive. The performance of an arm selection policy is measured by regret, defined as the reward loss with respect to the case where the player knows which M arms are the most rewarding and always plays the M best arms. We construct a policy with an interleaving exploration and exploitation epoch structure that achieves a regret with logarithmic order when arbitrary (but nontrivial) bounds on certain system parameters are known. When no knowledge about the system is available, we show that the proposed policy achieves a regret arbitrarily close to the logarithmic order. We further extend the problem to a decentralized setting where multiple distributed players share the arms without information exchange. Under both an exogenous restless model and an endogenous restless model, we show that a decentralized extension of the proposed policy preserves the logarithmic regret order as in the centralized setting. The results apply to adaptive learning in various dynamic systems and communication networks, as well as financial investment.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.4969v2},
author = {Liu, Haoyang and Liu, Keqin and Zhao, Qing},
eprint = {arXiv:1011.4969v2},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Liu, Zhao - 2011 - Learning in A Changing World Restless Multi-Armed Bandit with Unknown Dynamics.pdf:pdf},
keywords = {()},
title = {{Learning in A Changing World: Restless Multi-Armed Bandit with Unknown Dynamics}},
year = {2011}
}
@article{Charlesworth2011,
abstract = {Reinforcement signals indicating success or failure are known to alter the probability of selecting between distinct actions. However, successful performance of many motor skills, such as speech articulation, also requires learning behavioral trajectories that vary continuously over time. Here, we investigated how temporally discrete reinforcement signals shape a continuous behavioral trajectory, the fundamental frequency of adult Bengalese finch song. We provided reinforcement contingent on fundamental frequency performance only at one point in the song. Learned changes to fundamental frequency were maximal at this point, but also extended both earlier and later in the fundamental frequency trajectory. A simple principle predicted the detailed structure of learning: birds learned to produce the average of the behavioral trajectories associated with successful outcomes. This learning rule accurately predicted the structure of learning at a millisecond timescale, demonstrating that the nervous system records fine-grained details of successful behavior and uses this information to guide learning.},
author = {Charlesworth, Jonathan D and Tumer, Evren C and Warren, Timothy L and Brainard, Michael S},
doi = {10.1038/nn.2748},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Charlesworth et al. - 2011 - Learning the microstructure of successful behavior.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {3},
pages = {373--380},
pmid = {21278732},
title = {{Learning the microstructure of successful behavior.}},
url = {http://www.nature.com/neuro/journal/v14/n3/pdf/nn.2748.pdf http://dx.doi.org/10.1038/nn.2748},
volume = {14},
year = {2011}
}
@article{Richardson2009,
author = {Richardson, Robert J. and Blundon, Jay A. and Bayazitov, Ildar T. and Zakharenko, Stanislav S.},
journal = {Journal of Neuroscience},
keywords = {auditory,dendrites,integration},
mendeley-tags = {auditory,dendrites,integration},
number = {20},
title = {{Connectivity Patterns Revealed by Mapping of Active Inputs on Dendrites of Thalamorecipient Neurons in the Auditory Cortex}},
volume = {29},
year = {2009}
}
@article{Cunningham2014,
abstract = {Most sensory, cognitive and motor functions depend on the interactions of many neurons. In recent years, there has been rapid development and increasing use of technologies for recording from large numbers of neurons, either sequentially or simultaneously. A key question is what scientific insight can be gained by studying a population of recorded neurons beyond studying each neuron individually. Here, we examine three important motivations for population studies: single-trial hypotheses requiring statistical power, hypotheses of population response structure and exploratory analyses of large data sets. Many recent studies have adopted dimensionality reduction to analyze these populations and to find features that are not apparent at the level of individual neurons. We describe the dimensionality reduction methods commonly applied to population activity and offer practical advice about selecting methods and interpreting their outputs. This review is intended for experimental and computational researchers who seek to understand the role dimensionality reduction has had and can have in systems neuroscience, and who seek to apply these methods to their own data. A},
author = {Cunningham, John P and Yu, Byron M},
doi = {10.1038/nn.3776},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cunningham, Yu - 2014 - Dimensionality reduction for large-scale neural recordings.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {aug},
number = {11},
pages = {1500--1509},
pmid = {25151264},
title = {{Dimensionality reduction for large-scale neural recordings}},
url = {http://www.nature.com/doifinder/10.1038/nn.3776},
volume = {17},
year = {2014}
}
@article{Schmitt2017,
abstract = {Although interactions between the thalamus and cortex are critical for cognitive function, the exact contribution of the thalamus to these interactions remains unclear. Recent studies have shown diverse connectivity patterns across the thalamus, but whether this diversity translates to thalamic functions beyond relaying information to or between cortical regions is unknown. Here we show, by investigating the representation of two rules used to guide attention in the mouse prefrontal cortex (PFC), that the mediodorsal thalamus sustains these representations without relaying categorical information. Specifically, mediodorsal input amplifies local PFC connectivity, enabling rule-specific neural sequences to emerge and thereby maintain rule representations. Consistent with this notion, broadly enhancing PFC excitability diminishes rule specificity and behavioural performance, whereas enhancing mediodorsal excitability improves both. Overall, our results define a previously unknown principle in neuroscience; thalamic control of functional cortical connectivity. This function, which is dissociable from categorical information relay, indicates that the thalamus has a much broader role in cognition than previously thought.},
author = {Schmitt, L Ian and Wimmer, Ralf D and Nakajima, Miho and Happ, Michael and Mofakham, Sima and Halassa, Michael M},
doi = {10.1038/nature22073},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Schmitt et al. - 2017 - Thalamic amplification of cortical connectivity sustains attentional control.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7653},
pages = {219--223},
pmid = {28467827},
title = {{Thalamic amplification of cortical connectivity sustains attentional control}},
url = {https://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22073.pdf http://www.nature.com/doifinder/10.1038/nature22073},
volume = {545},
year = {2017}
}
@article{Roweis1999,
abstract = {Factor analysis, principal component analysis, mixtures of gaussian clusters, vector quantization, Kalman filter models, and hidden Markov models can all be unified as variations of unsupervised learning under a single basic generative model. This is achieved by collecting together disparate observations and derivations made by many previous authors and introducing a new way of linking discrete and continuous state models using a simple nonlinearity. Through the use of other nonlinearities, we show how independent component analysis is also a variation of the same basic generative model. We show that factor analysis and mixtures of gaussians can be implemented in autoencoder neural networks and learned using squared error plus the same regularization term. We introduce a new model for static data, known as sensible principal component analysis, as well as a novel concept of spatially adaptive observation noise. We also review some of the literature involving global and local mixtures of the basic models and provide pseudocode for inference and learning for all the basic models.},
author = {Roweis, S and Ghahramani, Z},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Roweis, Ghahramani - 1999 - A unifying review of linear gaussian models.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
month = {feb},
number = {2},
pages = {305--45},
pmid = {9950734},
title = {{A unifying review of linear gaussian models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9950734},
volume = {11},
year = {1999}
}
@book{Chen2015,
abstract = {This authoritative work provides an in-depth treatment of state space methods, with a range of applications in neural and clinical data. Advanced and state-of-the-art research topics are detailed, including topics in state space analyses, maximum likelihood methods, variational Bayes, sequential Monte Carlo, Markov chain Monte Carlo, nonparametric Bayesian, and deep learning methods. Details are provided on practical applications in neural and clinical data, whether this is characterising time series data from neural spike trains recorded from the rat hippocampus, the primate motor cortex, or the human EEG, MEG or fMRI, or physiological measurements of heartbeats or blood pressures. With real-world case studies of neuroscience experiments and clinical data sets, and written by expert authors from across the field, this is an ideal resource for anyone working in neuroscience and physiological data analysis. {\textcopyright} Cambridge University Press 2015},
author = {Chen, Z},
booktitle = {Advanced State Space Methods for Neural and Clinical Data},
doi = {10.1017/CBO9781139941433},
isbn = {9781139941433},
pages = {1--374},
title = {{Advanced State Space Methods for Neural and Clinical Data}},
url = {http://ebooks.cambridge.org/ref/id/CBO9781139941433},
year = {2015}
}
@article{Rochefort2011,
abstract = {Previous studies of the ferret visual cortex indicate that the development of direction selectivity requires visual experience. Here, we used two-photon calcium imaging to study the development of direction selectivity in layer 2/3 neurons of the mouse visual cortex in vivo. Surprisingly, just after eye opening nearly all orientation-selective neurons were also direction selective. During later development, the number of neurons responding to drifting gratings increased in parallel with the fraction of neurons that were orientation, but not direction, selective. Our experiments demonstrate that direction selectivity develops normally in dark-reared mice, indicating that the early development of direction selectivity is independent of visual experience. Furthermore, remarkable functional similarities exist between the development of direction selectivity in cortical neurons and the previously reported development of direction selectivity in the mouse retina. Together, these findings provide strong evidence that the development of orientation and direction selectivity in the mouse brain is distinctly different from that in ferrets. ?? 2011 Elsevier Inc.},
annote = {NULL},
author = {Rochefort, Nathalie L. and Narushima, Madoka and Grienberger, Christine and Marandi, Nima and Hill, Daniel N. and Konnerth, Arthur},
doi = {10.1016/j.neuron.2011.06.013},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/3AWMGXCZ/S0896-6273(11)00518-6.pdf:pdf},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {Cortex,development,direction selectivity,mouse},
language = {en},
mendeley-tags = {Cortex,development,direction selectivity,mouse},
month = {aug},
number = {3},
pages = {425--432},
pmid = {21835340},
title = {{Development of Direction Selectivity in Mouse Cortical Neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627311005186 http://www.cell.com/neuron/pdf/S0896-6273(11)00518-6.pdf},
volume = {71},
year = {2011}
}
@article{Schweber1993,
author = {Schweber, Silvan S.},
doi = {10.1063/1.881368},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(12).pdf:pdf},
issn = {0031-9228},
journal = {Physics Today},
month = {nov},
number = {11},
pages = {34--40},
title = {{Physics, Community and the Crisis in Physical Theory}},
url = {http://physicstoday.scitation.org/doi/10.1063/1.881368},
volume = {46},
year = {1993}
}
@article{Pillow2005,
abstract = {Sensory encoding in spiking neurons depends on both the integration of sensory inputs and the intrinsic dynamics and variability of spike generation. We show that the stimulus selectivity, reliability, and timing precision of primate retinal ganglion cell (RGC) light responses can be reproduced accurately with a simple model consisting of a leaky integrate-and-fire spike generator driven by a linearly filtered stimulus, a postspike current, and a Gaussian noise current. We fit model parameters for individual RGCs by maximizing the likelihood of observed spike responses to a stochastic visual stimulus. Although compact, the fitted model predicts the detailed time structure of responses to novel stimuli, accurately capturing the interaction between the spiking history and sensory stimulus selectivity. The model also accounts for the variability in responses to repeated stimuli, even when fit to data from a single (nonrepeating) stimulus sequence. Finally, the model can be used to derive an explicit, maximum-likelihood decoding rule for neural spike trains, thus providing a tool for assessing the limitations that spiking variability imposes on sensory performance.},
author = {Pillow, Jonathan W},
doi = {10.1523/JNEUROSCI.3305-05.2005},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pillow et al. - Unknown - BehavioralSystemsCognitive Prediction and Decoding of Retinal Ganglion Cell Responses with a Probabilistic (2).pdf:pdf},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {computational model,decoding,integrate and fire,neural coding,precision,retinal ganglion cell,spike timing,spike trains,variability},
number = {47},
pages = {11003--11013},
pmid = {16306413},
title = {{Prediction and Decoding of Retinal Ganglion Cell Responses with a Probabilistic Spiking Model}},
url = {http://pillowlab.princeton.edu/pubs/Pillow{\_}etal{\_}JN05.pdf http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3305-05.2005},
volume = {25},
year = {2005}
}
@article{Cohen2008,
abstract = {Animals can flexibly change their behavior in response to a particular sensory stimulus; the mapping between sensory and motor representations in the brain must therefore be flexible as well. Changes in the correlated firing of pairs of neurons may provide a metric of changes in functional circuitry during behavior. We studied dynamic changes in functional circuitry by analyzing the noise correlations of simultaneously recorded MT neurons in two behavioral contexts: one that promotes cooperative interactions between the two neurons and another that promotes competitive interactions. We found that identical visual stimuli give rise to differences in noise correlation in the two contexts, suggesting that MT neurons receive inputs of central origin whose strength changes with the task structure. The data are consistent with a mixed feature-based attentional strategy model in which the animal sometimes alternates attention between opposite directions of motion and sometimes attends to the two directions simultaneously. ?? 2008 Elsevier Inc. All rights reserved.},
author = {Cohen, Marlene R. and Newsome, William T.},
doi = {10.1016/j.neuron.2008.08.007},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Cohen, Newsome - 2008 - Context-Dependent Changes in Functional Circuitry in Visual Area MT.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$n1097-4199 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
number = {1},
pages = {162--173},
pmid = {18940596},
title = {{Context-Dependent Changes in Functional Circuitry in Visual Area MT}},
volume = {60},
year = {2008}
}
@article{Poort2015,
abstract = {We determined how learning modifies neural representations in primary visual cortex (V1) during acquisition of a visually guided behavioral task. We imaged the activity of the same layer 2/3 neuronal populations as mice learned to discriminate two visual patterns while running through a virtual corridor, where one pattern was rewarded. Improvements in behavioral performance were closely associated with increasingly distinguishable population-level representations of task-relevant stimuli, as a result of stabilization of existing and recruitment of new neurons selective for these stimuli. These effects correlated with the appearance of multiple task-dependent signals during learning: those that increased neuronal selectivity across the population when expert animals engaged in the task, and those reflecting anticipation or behavioral choices specifically in neuronal subsets preferring the rewarded stimulus. Therefore, learning engages diverse mechanisms that modify sensory and non-sensory representations in V1 to adjust its processing to task requirements and the behavioral relevance of visual stimuli. By tracking the same visual cortex neurons across days, Poort et al. demonstrate how learning a visual task leads to increasingly distinguishable representations of relevant stimuli. These changes parallel the emergence of diverse non-sensory signals in specific neuronal subsets.},
author = {Poort, Jasper and Khan, Adil G and Pachitariu, Marius and Nemri, Abdellatif and Orsolic, Ivana and Krupic, Julija and Bauza, Marius and Sahani, Maneesh and Keller, Georg B and Mrsic-Flogel, Thomas D and Hofer, Sonja B},
doi = {10.1016/j.neuron.2015.05.037},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Poort et al. - 2015 - Learning Enhances Sensory and Multiple Non- sensory Representations in Primary Visual Cortex Learning Enhances Sen.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {6},
pages = {1478--1490},
pmid = {26051421},
title = {{Learning Enhances Sensory and Multiple Non-sensory Representations in Primary Visual Cortex}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.05.037},
volume = {86},
year = {2015}
}
@misc{Press1992,
author = {Press, William H},
booktitle = {Numerical Recipes},
title = {{Errors in Both Coordinates}},
year = {1992}
}
@article{Fonseca2015,
abstract = {Background The central neuromodulator serotonin (5-HT) has been implicated in a wide range of behaviors and affective disorders, but the principles underlying its function remain elusive. One influential line of research has implicated 5-HT in response inhibition and impulse control. Another has suggested a role in affective processing. However, whether and how these effects relate to each other is still unclear. Results Here, we report that optogenetic activation of 5-HT neurons in the dorsal raphe nucleus (DRN) produces a dose-dependent increase in mice's ability to withhold premature responding in a task that requires them to wait several seconds for a randomly delayed tone. The 5-HT effect had a rapid onset and was maintained throughout the stimulation period. In addition, movement speed was slowed, but photostimulation did not affect reaction time or time spent at the reward port. Using similar photostimulation protocols in place preference and value-based choice tests, we found no evidence of either appetitive or aversive effects of DRN 5-HT neuron activation. Conclusions These results provide strong evidence that the efficacy of DRN 5-HT neurons in promoting waiting for delayed reward is independent of appetitive or aversive effects and support the importance of 5-HT in behavioral persistence and impulse control.},
annote = {NULL},
author = {Fonseca, Madalena S. and Murakami, Masayoshi and Mainen, Zachary F.},
doi = {10.1016/j.cub.2014.12.002},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/AE4S9RKB/S0960-9822(14)01561-9.pdf:pdf},
isbn = {1879-0445 (Electronic)$\backslash$r0960-9822 (Linking)},
issn = {09609822},
journal = {Current Biology},
keywords = {behaviour,raphe,reward,serotonin},
language = {en},
mendeley-tags = {behaviour,raphe,reward,serotonin},
month = {feb},
number = {3},
pages = {306--315},
pmid = {25601545},
title = {{Activation of Dorsal Raphe Serotonergic Neurons Promotes Waiting but Is Not Reinforcing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982214015619 http://www.cell.com/current-biology/pdfExtended/S0960-9822(14)01561-9},
volume = {25},
year = {2015}
}
@article{BencePOlveczky2011,
abstract = {The acquisition of complex motor sequences often proceeds through trial-and-error learning, requiring the deliberate exploration of motor actions and the concomitant evaluation of the resulting performance. Songbirds learn their song in this manner, producing highly variable vocalizations as juveniles. As the song improves, vocal variability is gradually reduced until it is all but eliminated in adult birds. Here we examine how the motor program underlying such a complex motor behavior evolves during learning by recording from RA, a motor cortex analogue brain region. In young birds, neurons in RA exhibited highly variable firing patterns that throughout development became more precise, sparse, and bursty. We further explored how the developing motor program in RA is shaped by its two main inputs: LMAN, the output nucleus of a basal ganglia-forebrain circuit, and HVC a premotor nucleus. Pharmacological inactivation of LMAN during singing made the song-aligned firing patterns of RA neurons adult-like in their stereotypy without dramatically affecting the spike statistics or the overall firing patterns. Removing the input from HVC, on the other hand, resulted in a complete loss of stereotypy of both the song and the underlying motor program. Thus our results show that a basal ganglia-forebrain circuit drives motor exploration required for trial-and-error learning by adding variability to the developing motor program. As learning proceeds and the motor circuits mature, the relative contribution of the basal ganglia circuit is reduced, allowing the premotor input from HVC to drive an increasingly stereotyped song.},
author = {Olveczky, Bence Patrik and Otchy, Timothy Matthew and Goldberg, Jesse Heymann and Aronov, Dmitriy and Fee, Michale S},
doi = {10.1152/jn.00018.2011},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Olveczky et al. - 2011 - Changes in the neural control of a complex motor sequence during learning.pdf:pdf},
isbn = {1522-1598 (Electronic) 0022-3077 (Linking)},
issn = {1522-1598},
journal = {Journal of neurophysiology},
number = {1},
pages = {386--97},
pmid = {21543758},
title = {{Changes in the neural control of a complex motor sequence during learning.}},
url = {http://jn.physiology.org/content/jn/106/1/386.full.pdf http://www.researchgate.net/publication/51099465{\_}Changes{\_}in{\_}the{\_}neural{\_}control{\_}of{\_}a{\_}complex{\_}motor{\_}sequence{\_}during{\_}learning?ev=prf{\_}pub http://jn.physiology.org/cgi/content/abstract/106/1/386{\%}5Cnhttp://},
volume = {106},
year = {2011}
}
@article{Todorov2002,
abstract = {A central problem in motor control is understanding how the many biomechanical degrees of freedom are coordinated to achieve a common goal. An especially puzzling aspect of coordination is that behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Existing theoretical frameworks emphasize either goal achievement or the richness of motor variability, but fail to reconcile the two. Here we propose an alternative theory based on stochastic optimal feedback control. We show that the optimal strategy in the face of uncertainty is to allow variability in redundant (task-irrelevant) dimensions. This strategy does not enforce a desired trajectory, but uses feedback more intelligently, correcting only those deviations that interfere with task goals. From this framework, task-constrained variability, goal-directed corrections, motor synergies, controlled parameters, simplifying rules and discrete coordination modes emerge naturally. We present experimental results from a range of motor tasks to support this theory.},
author = {Todorov, Emanuel and Jordan, Michael I},
doi = {10.1038/nn963},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Todorov, Jordan - 2002 - Optimal feedback control as a theory of motor coordination.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {11},
pages = {1226--1235},
pmid = {12404008},
title = {{Optimal feedback control as a theory of motor coordination.}},
url = {http://www.nature.com/neuro/journal/v5/n11/pdf/nn963.pdf},
volume = {5},
year = {2002}
}
@article{Munos,
abstract = {Policy gradient is an efficient technique for improving a policy in a reinforcement learning setting. However, vanilla online variants are on-policy only and not able to take advantage of off-policy data. In this paper we describe a new technique that combines policy gradient with off-policy Q-learning, drawing experience from a replay buffer. This is motivated by making a connection between the fixed points of the regularized policy gradient algorithm and the Q-values. This connection allows us to estimate the Q-values from the action preferences of the policy, to which we apply Q-learning updates. We refer to the new technique as 'PGQ', for policy gradient and Q-learning. We also establish an equivalency between action-value fitting techniques and actor-critic algorithms, showing that regularized policy gradient techniques can be interpreted as advantage function learning algorithms. We conclude with some numerical examples that demonstrate improved data efficiency and stability of PGQ. In particular, we tested PGQ on the full suite of Atari games and achieved performance exceeding that of both asynchronous advantage actor-critic (A3C) and Q-learning.},
archivePrefix = {arXiv},
arxivId = {1611.01626},
author = {O'Donoghue, Brendan and Munos, Remi and Kavukcuoglu, Koray and Mnih, Volodymyr},
eprint = {1611.01626},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Munos, Kavukcuoglu, Mnih Deepmind - Unknown - PGQ COMBINING POLICY GRADIENT AND Q-LEARNING.pdf:pdf},
month = {nov},
pages = {1--15},
title = {{PGQ: Combining policy gradient and Q-learning}},
url = {http://arxiv.org/abs/1611.01626},
year = {2016}
}
@article{Pillow,
abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20{\%} more information about the visual scene than decoding under the assumption of independence, and preserves 40{\%} more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M and Chichilnisky, E J and Simoncelli, Eero P},
doi = {10.1038/nature07140},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Pillow et al. - Unknown - Spatio-temporal correlations and visual signalling in a complete neuronal population.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7207},
pages = {995--999},
pmid = {18650810},
title = {{Spatio-temporal correlations and visual signalling in a complete neuronal population}},
url = {http://www.nature.com/doifinder/10.1038/nature07140},
volume = {454},
year = {2008}
}
@misc{Paninski2010,
abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates.},
author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and {Rahnama Rad}, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
booktitle = {Journal of Computational Neuroscience},
doi = {10.1007/s10827-009-0179-x},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Paninski et al. - 2010 - A new look at state-space models for neural data.pdf:pdf},
isbn = {0929-5313},
issn = {09295313},
keywords = {Hidden Markov model,Neural coding,State-space models,Tridiagonal matrix},
number = {1-2},
pages = {107--126},
pmid = {19649698},
title = {{A new look at state-space models for neural data}},
url = {http://www.stat.columbia.edu/∼liam},
volume = {29},
year = {2010}
}
@article{MemmingPark2014,
abstract = {It has been suggested that the lateral intraparietal area (LIP) of macaques plays a fundamental role in sensorimotor decision-making. We examined the neural code in LIP at the level of individual spike trains using a statistical approach based on generalized linear models. We found that LIP responses reflected a combination of temporally overlapping task- and decision-related signals. Our model accounts for the detailed statistics of LIP spike trains and accurately predicts spike trains from task events on single trials. Moreover, we derived an optimal decoder for heterogeneous, multiplexed LIP responses that could be implemented in biologically plausible circuits. In contrast with interpretations of LIP as providing an instantaneous code for decision variables, we found that optimal decoding requires integrating LIP spikes over two distinct timescales. These analyses provide a detailed understanding of neural representations in LIP and a framework for studying the coding of multiplexed signals in higher brain areas.},
annote = {NULL},
author = {Park, Il Memming and Meister, Miriam L R and Huk, Alexander C and Pillow, Jonathan W},
doi = {10.1038/nn.3800},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Memming Park et al. - 2014 - Encoding and decoding in parietal cortex during sensorimotor decision-making.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1546-1726},
journal = {Nat Neurosci},
keywords = {Algorithms,Animals,Decision Making,Macaca mulatta,Male,Models,Motion Perception,Neurological,Neurons,Parietal Lobe,Photic Stimulation,physiology},
number = {August},
pages = {1395--1403},
pmid = {25174005},
title = {{Encoding and decoding in parietal cortex during sensorimotor decision-making.}},
url = {http://www.nature.com/neuro/journal/v17/n10/pdf/nn.3800.pdf http://dx.doi.org/10.1038/nn.3800{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/25174005},
volume = {17},
year = {2014}
}
@article{Delevich,
abstract = {Although the medial prefrontal cortex (mPFC) is classically defined by its reciprocal connections with the mediodorsal thalamic nucleus (MD), the nature of information transfer between MD and mPFC is poorly understood. In sensory thalamocortical pathways, thalamic recruitment of feedforward inhibition mediated by fast-spiking, putative parvalbumin-expressing (PV) interneurons is a key feature that enables cortical neurons to represent sensory stimuli with high temporal fidelity. Whether a similar circuit mechanism is in place for the projection from the MD (a higher-order thalamic nucleus that does not receive direct input from the periphery) to the mPFC is unknown. Here we show in mice that inputs from the MD drive disynaptic feedforward inhibition in the dorsal anterior cingulate cortex (dACC) subregion of the mPFC. In particular, we demonstrate that axons arising from MD neurons directly synapse onto and excite PV interneurons that in turn mediate feedforward inhibition of pyramidal neurons in layer 3 of the dACC. This feedforward inhibition in the dACC limits the time window during which pyramidal neurons integrate excitatory synaptic inputs and fire action potentials, but in a manner that allows for greater flexibility than in sensory cortex. These findings provide a foundation for understanding the role of MD-PFC circuit function in cognition.},
author = {Delevich, Kristen and Tucciarone, Jason and Huang, Z Josh and Li, B.},
doi = {10.1523/JNEUROSCI.4565-14.2015},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Delevich et al. - Unknown - The Mediodorsal Thalamus Drives Feedforward Inhibition in the Anterior Cingulate Cortex via Parvalbumin Inte.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {anterior cingulate cortex,feedforward inhibition,medial prefrontal cortex,mediodorsal thalamus,parvalbumin interneuron},
number = {14},
pages = {5743--5753},
pmid = {25855185},
title = {{The Mediodorsal Thalamus Drives Feedforward Inhibition in the Anterior Cingulate Cortex via Parvalbumin Interneurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25855185},
volume = {35},
year = {2015}
}
@incollection{Daw2009,
abstract = {This latest volume in the critically acclaimed and highly influential Attention and Performance series focuses on two of the fastest moving research areas in cognitive and affective neuroscience - decision making and emotional processing. Decision Making, Affect, and Learning investigates the psychological and neural systems underlying decision making, and the relationship with reward, affect, and learning. In addition, it considers neurodevelopmental and clinical aspects of these issues - for example the role of decision making and reward in drug addiction. It also looks at the applied aspects of this knowledge to other disciplines, including the growing field of Neuroeconomics. After an introductory chapter from the Volume editors, the book is then arranged according to the following themes: Psychological Processes underlying decision-making. Neural systems of decision-making Neural systems of emotion, reward and learning Neurodevelopmental and clinical aspects Superbly written and edited, the book highlights the complex interplay between emotional and decision-making processes and their relationship with learning.},
author = {Daw, Nathaniel D},
booktitle = {Decision Making, Affect, and Learning: Attention and Performance XXIII},
doi = {10.1093/acprof:oso/9780199600434.003.0001},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Daw - 2009 - Trial-by-trial data analysis using computational models.pdf:pdf},
isbn = {9780191725623},
issn = {0199600430},
keywords = {Computational models,Data analysis,Decision making,Neural data,Reward learning,Statistical methods},
title = {{Trial-by-trial data analysis using computational models}},
url = {http://www.princeton.edu/{~}ndaw/d10.pdf},
year = {2011}
}
@article{Daw,
abstract = {Although theorists have interpreted classical conditioning as a laboratory model of Bayesian belief updating, a recent reanalysis showed that the key features that theoretical models capture about learning are artifacts of averaging over subjects. Rather than learning smoothly to asymptote (reflecting, according to Bayesian models, the gradual tradeoff from prior to posterior as data accumulate), subjects learn suddenly, and their predictions fluctuate perpetually. We suggest that abrupt and unstable learning can be modeled by assuming subjects are conducting in- ference using sequential Monte Carlo sampling with a small number of samples —one, in our simulations. Ensemble behavior resembles exact Bayesian models since, as in particle filters, it averages over many samples. Further, the model is capable of exhibiting sophisticated behaviors like retrospective revaluation at the ensemble level, even given minimally sophisticated individuals that do not track uncertainty in their beliefs over trials},
author = {Daw, Nathaniel D and Courville, Aaron C},
doi = {10.1.1.73.3246},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Daw, Courville - 2008 - The pigeon as particle filter.pdf:pdf},
isbn = {160560352X},
journal = {Advances in neural information processing systems},
pages = {369--376},
title = {{The pigeon as particle filter}},
url = {http://www.princeton.edu/{~}ndaw/dc07.pdf},
year = {2008}
}
@inproceedings{Deisenroth2009,
annote = {NULL},
author = {Deisenroth, Marc Peter and Huber, Marco F. and Hanebeck, Uwe D.},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/DMX4QW94/icml2009{\_}finalCorrected.pdf:pdf},
keywords = {Filtering,Gaussian Process,State Space Models},
mendeley-tags = {Filtering,Gaussian Process,State Space Models},
pages = {225--232},
publisher = {ACM},
title = {{Analytic moment-based Gaussian process filtering}},
url = {http://dl.acm.org/citation.cfm?id=1553403 https://spiral.imperial.ac.uk/bitstream/10044/1/11621/8/icml2009{\_}finalCorrected.pdf},
year = {2009}
}
@article{Graves,
abstract = {This paper shows how Long Short-term Memory recurrent neural net-works can be used to generate complex sequences with long-range struc-ture, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwrit-ing (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
author = {Graves, Alex},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Graves - Unknown - Generating Sequences With Recurrent Neural Networks.pdf:pdf},
title = {{Generating Sequences With Recurrent Neural Networks}}
}
@article{Zohary1994,
abstract = {Single neurons can signal subtle changes in the sensory environment with surprising fidelity, often matching the perceptual sensitivity of trained psychophysical observers. This similarity poses an intriguing puzzle: why is psychophysical sensitivity not greater than that of single neurons? Pooling responses across neurons should average out noise in the activity of single cells, leading to substantially improved psychophysical performance. If, however, noise is correlated among these neurons, the beneficial effects of pooling would be diminished. To assess correlation within a pool, the responses of pairs of neurons were recorded simultaneously during repeated stimulus presentations. We report here that the observed covariation in spike count was relatively weak, the correlation coefficient averaging 0.12. A theoretical analysis revealed, however, that weak correlation can limit substantially the signalling capacity of the pool. In addition, theory suggests a relationship between neuronal responses and psychophysical decisions which may prove useful for identifying cell populations underlying specific perceptual capacities.},
author = {Zohary, Ehud and Shadlen, Michael N. and Newsome, William T.},
doi = {10.1038/370140a0},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Zohary, Shadlen, Newsome - 1994 - Correlated neuronal discharge rate and its implications for psychophysical performance.pdf:pdf},
isbn = {0028-0836 (Print)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {6485},
pages = {140--143},
pmid = {8022482},
title = {{Correlated neuronal discharge rate and its implications for psychophysical performance}},
url = {http://www.nature.com/doifinder/10.1038/370140a0},
volume = {370},
year = {1994}
}
@article{Denil2016,
abstract = {When encountering novel objects, humans are able to infer a wide range of physical properties such as mass, friction and deformability by interacting with them in a goal driven way. This process of active interaction is in the same spirit as a scientist performing experiments to discover hidden facts. Recent advances in artificial intelligence have yielded machines that can achieve superhuman performance in Go, Atari, natural language processing, and complex control problems; however, it is not clear that these systems can rival the scientific intuition of even a young child. In this work we introduce a basic set of tasks that require agents to estimate properties such as mass and cohesion of objects in an interactive simulated environment where they can manipulate the objects and observe the consequences. We found that state of art deep reinforcement learning methods can learn to perform the experiments necessary to discover such hidden properties. By systematically manipulating the problem difficulty and the cost incurred by the agent for performing experiments, we found that agents learn different strategies that balance the cost of gathering information against the cost of making mistakes in different situations.},
archivePrefix = {arXiv},
arxivId = {1611.01843},
author = {Denil, Misha and Agrawal, Pulkit and Kulkarni, Tejas D and Erez, Tom and Battaglia, Peter and de Freitas, Nando},
eprint = {1611.01843},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Denil et al. - Unknown - LEARNING TO PERFORM PHYSICS EXPERIMENTS VIA DEEP REINFORCEMENT LEARNING.pdf:pdf},
journal = {arXiv stat.ML},
pages = {01843},
title = {{Learning to Perform Physics Experiments via Deep Reinforcement Learning}},
url = {https://arxiv.org/pdf/1611.01843.pdf http://arxiv.org/abs/1611.01843},
volume = {11},
year = {2016}
}
@article{Schonfelder2013,
abstract = {The classical psychophysical paradigm of narrow-band tone-in-noise (TiN) detection has been under investigation for more than 70 years, yet no conclusive answer has been given as to which auditory stimulus features listeners rely on. Here, individual observer models were fit to a large trial-by-trial behavioral data set using a modern statistical analysis procedure. Relative perceptual weights were estimated for a set of auditory features including sound energy, representations of the spectra as well as summary statistics of both fine structure and envelope. The fitted models captured the behavior of all listeners on a single-trial level. The estimated perceptual weights were stable across signal levels. They suggest that responses of observers depended on stimulus energy, though that cue was not always dominant, as well as on band-pass detectors applied to the fine structure spectrum. A subset of the observers exhibited an additional dependence on sound envelope which was best captured by two envelope descriptors: average slope and extrema count. For some listeners, a concurrent analysis of sequential dependencies showed interactions between the current and several preceding decisions. There was no unique answer regarding the strategy individual listeners employ during TiN detection, and implications thereof are discussed.},
author = {Sch{\"{o}}nfelder, Vinzenz H and Wichmann, Felix A},
doi = {10.1121/1.4807561},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Sch{\"{o}}nfelder, Wichmann - 2013 - Identification of stimulus cues in narrow-band tone-in-noise detection using sparse observer models.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adult,Cues,Decision Making,Female,Humans,Logistic Models,Loudness Perception,Male,Perceptual Masking,Pitch Discrimination,Psychoacoustics,Sound Spectrography},
month = {jul},
number = {1},
pages = {447--463},
pmid = {23862820},
title = {{Identification of stimulus cues in narrow-band tone-in-noise detection using sparse observer models}},
url = {http://dx.doi.org/10.1121/1.4807561 http://asa.scitation.org/toc/jas/134/1 http://www.ncbi.nlm.nih.gov/pubmed/23862820 http://asa.scitation.org/doi/10.1121/1.4807561},
volume = {134},
year = {2013}
}
@article{Wiltschko2015,
abstract = {Complex animal behaviors are likely built from simpler modules, but their systematic identification in mammals remains a significant challenge. Here we use depth imaging to show that 3D mouse pose dynamics are structured at the sub-second timescale. Computational modeling of these fast dynamics effectively describes mouse behavior as a series of reused and stereotyped modules with defined transition probabilities. We demonstrate this combined 3D imaging and machine learning method can be used to unmask potential strategies employed by the brain to adapt to the environment, to capture both predicted and previously hidden phenotypes caused by genetic or neural manipulations, and to systematically expose the global structure of behavior within an experiment. This work reveals that mouse body language is built from identifiable components and is organized in a predictable fashion; deciphering this language establishes an objective framework for characterizing the influence of environmental cues, genes and neural activity on behavior.},
author = {Wiltschko, Alexander B. and Johnson, Matthew J. and Iurilli, Giuliano and Peterson, Ralph E. and Katon, Jesse M. and Pashkovski, Stan L. and Abraira, Victoria E. and Adams, Ryan P. and Datta, Sandeep Robert},
doi = {10.1016/j.neuron.2015.11.031},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Wiltschko et al. - 2015 - Mapping Sub-Second Structure in Mouse Behavior.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {6},
pages = {1121--1135},
pmid = {26687221},
title = {{Mapping Sub-Second Structure in Mouse Behavior}},
volume = {88},
year = {2015}
}
@article{Peters2008,
abstract = {Autonomous learning is one of the hallmarks of human and animal behavior, and understanding the principles of learning will be crucial in order to achieve true autonomy in advanced machines like humanoid robots. In this paper, we examine learning of complex motor skills with human-like limbs. While supervised learning can offer useful tools for bootstrapping behavior, e.g., by learning from demonstration, it is only reinforcement learning that offers a general approach to the final trial-and-error improvement that is needed by each individual acquiring a skill. Neither neurobiological nor machine learning studies have, so far, offered compelling results on how reinforcement learning can be scaled to the high-dimensional continuous state and action spaces of humans or humanoids. Here, we combine two recent research developments on learning motor control in order to achieve this scaling. First, we interpret the idea of modular motor control by means of motor primitives as a suitable way to generate parameterized control policies for reinforcement learning. Second, we combine motor primitives with the theory of stochastic policy gradient learning, which currently seems to be the only feasible framework for reinforcement learning for humanoids. We evaluate different policy gradient methods with a focus on their applicability to parameterized motor primitives. We compare these algorithms in the context of motor primitive learning, and show that our most modern algorithm, the Episodic Natural Actor-Critic outperforms previous algorithms by at least an order of magnitude. We demonstrate the efficiency of this reinforcement learning method in the application of learning to hit a baseball with an anthropomorphic robot arm. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Peters, Jan and Schaal, Stefan},
doi = {10.1016/j.neunet.2008.02.003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Peters, Schaal - 2008 - Reinforcement learning of motor skills with policy gradients.pdf:pdf},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {Motor primitives,Motor skills,Natural Actor-Critic,Natural gradients,Policy gradient methods,Reinforcement learning},
number = {4},
pages = {682--697},
pmid = {18482830},
title = {{Reinforcement learning of motor skills with policy gradients}},
volume = {21},
year = {2008}
}
@article{Woolley2014a,
abstract = {Context dependence is a key feature of cortical-basal ganglia circuit activity, and in songbirds the cortical outflow of a basal ganglia circuit specialized for song, LMAN, shows striking increases in trial-by-trial variability and bursting when birds sing alone rather than to females. To reveal where this variability and its social regulation emerge, we recorded stepwise from corticostriatal (HVC) neurons and their target spiny and pallidal neurons in Area X. We find that corticostriatal and spiny neurons both show precise singing-related firing across both social settings. Pallidal neurons, in contrast, exhibit markedly increased trial-by-trial variation when birds sing alone, created by highly variable pauses in firing. This variability persists even when recurrent inputs from LMAN are ablated. These data indicate that variability and its context sensitivity emerge within the basal ganglia network, suggest a network mechanism for this emergence, and highlight variability generation and regulation as basal ganglia functions. ?? 2014 Elsevier Inc.},
author = {Woolley, Sarah C and Rajan, Raghav and Joshua, Mati and Doupe, Allison J},
doi = {10.1016/j.neuron.2014.01.039},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of context-dependent variability across a basal ganglia network(4).pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {1},
pages = {208--223},
pmid = {24698276},
title = {{Emergence of context-dependent variability across a basal ganglia network}},
url = {http://dx.doi.org/10.1016/j.neuron.2014.01.039},
volume = {82},
year = {2014}
}
@article{Bathellier,
abstract = {Both in humans and in animals, different individuals may learn the same task with strikingly different speeds; however, the sources of this variability remain elusive. In standard learning models, interindividual variability is often explained by variations of the learning rate, a parameter indicating how much synapses are updated on each learning event. Here, we theoretically show that the initial connectivity between the neurons involved in learning a task is also a strong determinant of how quickly the task is learned, provided that connections are updated in a multiplicative manner. To experimentally test this idea, we trained mice to perform an auditory Go/NoGo discrimination task followed by a reversal to compare learning speed when starting from naive or already trained synaptic connections. All mice learned the initial task, but often displayed sigmoid-like learning curves, with a variable delay period followed by a steep increase in performance, as often observed in operant conditioning. For all mice, learning was much faster in the subsequent reversal training. An accurate fit of all learning curves could be obtained with a reinforcement learning model endowed with a multiplicative learning rule, but not with an additive rule. Surprisingly, the multiplicative model could explain a large fraction of the interindividual variability by variations in the initial synaptic weights. Altogether, these results demonstrate the power of multiplicative learning rules to account for the full dynamics of biological learning and suggest an important role of initial wiring in the brain for predispositions to different tasks.},
author = {Bathellier, Brice and Poh, Sui and Hrovat, Christina and Rumpel, Simon and Tee, Sui Poh and Hrovat, Christina and Rumpel, Simon},
doi = {10.1073/pnas.1312125110/-/DCSupplemental.www.pnas.org/cgi/doi/10.1073/pnas.1312125110},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bathellier et al. - Unknown - A multiplicative reinforcement learning model capturing learning dynamics and interindividual variability.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Inbred C57BL,Individuality,Learning,Learning: physiology,Male,Mice,Models,Psychological,Reinforcement (Psychology),Time Factors},
number = {49},
pages = {19950--5},
pmid = {24255115},
title = {{A multiplicative reinforcement learning model capturing learning dynamics and interindividual variability in mice}},
url = {http://www.pnas.org/content/110/49/19950.long},
volume = {110},
year = {2013}
}
@article{Carandini2011,
abstract = {There is increasing evidence that the brain relies on a set of canonical neural computations, repeating them across brain regions and modalities to apply similar operations to different problems. A promising candidate for such a computation is normalization, in which the responses of neurons are divided by a common factor that typically includes the summed activity of a pool of neurons. Normalization was developed to explain responses in the primary visual cortex and is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions. Normalization may underlie operations such as the representation of odours, the modulatory effects of visual attention, the encoding of value and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that it serves as a canonical neural computation.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Carandini, Matteo and Heeger, Dj},
doi = {10.1038/nrn3136},
eprint = {NIHMS150003},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(8).pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Adaptation,Afferent Pathways,Anim,Physiological},
month = {nov},
number = {November},
pages = {1--12},
pmid = {22108672},
title = {{Normalization as a canonical neural computation.}},
url = {http://www.nature.com/doifinder/10.1038/nrn3136 http://www.nature.com/nrn/journal/v13/n1/abs/nrn3136.html{\%}5Cnhttp://discovery.ucl.ac.uk/1332718/},
year = {2012}
}
@article{Gao,
abstract = {A body of recent work in modeling neural activity focuses on recovering low-dimensional latent features that capture the statistical structure of large-scale neural populations. Most such approaches have focused on linear generative models, where inference is computationally tractable. Here, we propose fLDS, a general class of nonlinear generative models that permits the firing rate of each neuron to vary as an arbitrary smooth function of a latent, linear dynamical state. This extra flexibility allows the model to capture a richer set of neural variability than a purely linear model, but retains an easily visualizable low-dimensional latent space. To fit this class of non-conjugate models we propose a variational inference scheme, along with a novel approximate posterior capable of capturing rich temporal correlations across time. We show that our techniques permit inference in a wide class of generative models.We also show in application to two neural datasets that, compared to state-of-the-art neural population models, fLDS captures a much larger proportion of neural variability with a small number of latent dimensions, providing superior predictive performance and interpretability.},
archivePrefix = {arXiv},
arxivId = {1605.08454},
author = {Gao, Yuanjun and Archer, Evan and Paninski, Liam and Cunningham, John P},
eprint = {1605.08454},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - Unknown - Linear dynamical neural population models through nonlinear embeddings.pdf:pdf},
month = {may},
number = {Nips},
pages = {1--9},
title = {{Linear dynamical neural population models through nonlinear embeddings}},
url = {http://arxiv.org/abs/1605.08454},
year = {2016}
}
@article{Siniscalchi2016a,
abstract = {The ability to shift between repetitive and goal-directed actions is a hallmark of cognitive control. Previous studies have reported that adaptive shifts in behavior are accompanied by changes of neural activity in frontal cortex. However, neural and behavioral adaptations can occur at multiple time scales, and their relationship remains poorly defined. Here we developed an adaptive sensorimotor decision-making task for head-fixed mice, requiring them to shift flexibly between multiple auditory–motor mappings. Two-photon calcium imaging of secondary motor cortex (M2) revealed different ensemble activity states for each mapping. When adapting to a conditional mapping, transitions in ensemble activity were abrupt and occurred before the recovery of behavioral performance. By contrast, gradual and delayed transitions accompanied shifts toward repetitive responding. These results demonstrate distinct ensemble signatures associated with the start versus end of sensory-guided behavior and suggest that M2 leads in engaging goal-directed response strategies that require sensorimotor associations.},
author = {Siniscalchi, Michael J and Phoumthipphavong, Victoria and Ali, Farhan and Lozano, Marc and Kwan, Alex C},
doi = {10.1038/nn.4342},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Siniscalchi et al. - 2016 - Fast and slow transitions in frontal ensemble activity during flexible sensorimotor behavior.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jul},
number = {July},
pages = {1--11},
pmid = {27399844},
title = {{Fast and slow transitions in frontal ensemble activity during flexible sensorimotor behavior}},
url = {http://www.nature.com/doifinder/10.1038/nn.4342},
volume = {19},
year = {2016}
}
@article{Ahmadian2010a,
abstract = {Stimulus reconstruction or decoding methods provide an important tool for understanding how sensory and motor information is represented in neural activity. We discuss Bayesian decoding methods based on an encoding generalized linear model (GLM) that accurately describes how stimuli are transformed into the spike trains of a group of neurons. The form of the GLM likelihood ensures that the posterior distribution over the stimuli that caused an observed set of spike trains is log concave so long as the prior is. This allows the maximum a posteriori (MAP) stimulus estimate to be obtained using efficient optimization algorithms. Unfortunately, the MAP estimate can have a relatively large average error when the posterior is highly nongaussian. Here we compare several Markov chain Monte Carlo (MCMC) algorithms that allow for the calculation of general Bayesian estimators involving posterior expectations (conditional on model parameters). An efficient version of the hybrid Monte Carlo (HMC) algorithm was signif...},
author = {Ahmadian, Yashar and Pillow, Jonathan W and Paninski, Liam},
doi = {10.1162/NECO_a_00059},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ahmadian, Pillow, Paninski - 2010 - Efficient Markov Chain Monte Carlo Methods for Decoding Neural Spike Trains(2).pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {jan},
number = {1},
pages = {46--96},
pmid = {20964539},
title = {{Efficient Markov Chain Monte Carlo Methods for Decoding Neural Spike Trains}},
url = {http://www.stat.columbia.edu/{~}liam/research/pubs/yashar-nc08.pdf papers2://publication/uuid/905F3B39-D2E6-4608-9B4C-DF251FD3A8F6{\%}5Cnhttp://pillowlab.cps.utexas.edu/pubs/Ahmadian{\_}etal{\_}NC2011.pdf{\%}5Cnpapers2://publication/uuid/DCEE55BA-40E6-4A43-BC55-ED2FFA7},
volume = {23},
year = {2011}
}
@article{Kobak2016,
abstract = {Neurons in higher cortical areas, such as the prefrontal cortex, are often tuned to a variety of sensory and motor variables, and are therefore said to display mixed selectivity. This complexity of single neuron responses can obscure what information these areas represent and how it is represented. Here we demonstrate the advantages of a new dimensionality reduction technique, demixed principal component analysis (dPCA), that decomposes population activity into a few components. In addition to systematically capturing the majority of the variance of the data, dPCA also exposes the dependence of the neural representation on task parameters such as stimuli, decisions, or rewards. To illustrate our method we reanalyze population data from four datasets comprising different species, different cortical areas and different experimental tasks. In each case, dPCA provides a concise way of visualizing the data that summarizes the task-dependent features of the population response in a single figure.},
archivePrefix = {arXiv},
arxivId = {1410.6031},
author = {Kobak, Dmitry and Brendel, Wieland and Constantinidis, Christos and Feierstein, Claudia E and Kepecs, Adam and Mainen, Zachary F and Qi, Xue Lian and Romo, Ranulfo and Uchida, Naoshige and Machens, Christian K},
doi = {10.7554/eLife.10989},
eprint = {1410.6031},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kobak et al. - 2016 - Demixed principal component analysis of neural population data(2).pdf:pdf},
issn = {2050084X},
journal = {eLife},
keywords = {dimensionality reduction,neuroscience,population activity,prefrontal cortex,principal component analysis,rat,rhesus macaque},
month = {apr},
number = {APRIL2016},
pages = {e10989},
pmid = {27067378},
publisher = {eLife Sciences Publications Limited},
title = {{Demixed principal component analysis of neural population data}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27067378 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4887222},
volume = {5},
year = {2016}
}
@article{Lin2011,
abstract = {Channelrhodopsins (ChRs) are light-activated channels from algae that provide these organisms with fast sensors to visible light for phototaxis. Since its discovery, channelrhodopsin-2 (ChR2) has been used as a research tool to depolarize membranes of excitable cells with light. Subsequent chimeragenesis, mutagenesis and bioinformatic approaches have introduced additional ChR variants, such as channelrhodopsin-2 with H134R mutation (ChR2/H134R), channelrhodopsin-2 with E123T mutation (ChETA), Volvox carteri channelrhodopsin-1 (VChR1), Volvox carteri channelrhodopsin-2 (VChR2), channelrhodopsin-2 with C128 or D156A mutations (ChR2/C128X/D156A), chimera D (ChD), chimera EF (ChEF) and chimera EF with I170V mutation (I170V). Each of these ChR variuants has unique features and limitations, but there are few resources summarizing and comparing these ChRs in a systematic manner. In this review, the seven following key properties of ChRs that have significant influences on their effectiveness as research tools are examined: conductance, selectivity, kinetics, desensitization, light sensitivity, spectral response and membrane trafficking. Using this information, valuable qualities and deficits of each ChR variant are summarized. Optimal uses and potential future improvements of ChRs as optogenetic tools are also discussed.},
author = {Lin, John Y.},
doi = {10.1113/expphysiol.2009.051961},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Lin - 2011 - A user's guide to channelrhodopsin variants features, limitations and future developments.pdf:pdf},
isbn = {1469-445X (Electronic)$\backslash$r0958-0670 (Linking)},
issn = {1469-445X},
journal = {Experimental physiology},
keywords = {Animals,Ligand-Gated Ion Channels,Ligand-Gated Ion Channels: physiology,Light,Membrane Potentials,Membrane Potentials: physiology,Membranes,Membranes: physiology,Mutation,Rhodopsin,Rhodopsin: physiology},
month = {jan},
number = {1},
pages = {19--25},
pmid = {20621963},
publisher = {Blackwell Publishing Ltd},
title = {{A user's guide to channelrhodopsin variants: features, limitations and future developments.}},
url = {http://doi.wiley.com/10.1113/expphysiol.2009.051961 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2995811{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {96},
year = {2011}
}
@article{Siniscalchi2016,
author = {Siniscalchi, Michael J and Phoumthipphavong, Victoria and Ali, Farhan and Lozano, Marc and Kwan, Alex C},
doi = {10.1038/nn.4342},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Siniscalchi et al. - 2016 - Fast and slow transitions in frontal ensemble activity during flexible sensorimotor behavior.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jul},
number = {9},
pages = {1234--1242},
publisher = {Nature Research},
title = {{Fast and slow transitions in frontal ensemble activity during flexible sensorimotor behavior}},
url = {http://www.nature.com/doifinder/10.1038/nn.4342},
volume = {19},
year = {2016}
}
@article{Courville,
abstract = {The Temporal Coding Hypothesis of Miller and colleagues [7] sug-gests that animals integrate related temporal patterns of stimuli into single memory representations. We formalize this concept using quasi-Bayes estimation to update the parameters of a con-strained hidden Markov model. This approach allows us to account for some surprising temporal effects in the second order condition-ing experiments of Miller et al. [1 , 2, 3], which other models are unable to explain.},
author = {Courville, Aaron C and Touretzky, David S},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Courville, Touretzky - Unknown - Modeling Temporal Structure in Classical Conditioning.pdf:pdf},
title = {{Modeling Temporal Structure in Classical Conditioning}}
}
@inproceedings{Bak,
abstract = {Neuroscience experiments often require training animals to perform tasks designed to elicit various sensory, cognitive, and motor behaviors. Training typically involves a series of gradual adjustments of stimulus conditions and rewards in order to bring about learning. However, training protocols are usually hand-designed, relying on a combination of intuition, guesswork, and trial-and-error, and often require weeks or months to achieve a desired level of task performance. Here we combine ideas from reinforcement learning and adaptive optimal experimental design to formulate methods for adaptive optimal training of animal behavior. Our work addresses two intriguing problems at once: first, it seeks to infer the learning rules underlying an animal's behavioral changes during training; second, it seeks to exploit these rules to select stimuli that will maximize the rate of learning toward a desired objective. We develop and test these methods using data collected from rats during training on a two-interval sensory discrimination task. We show that we can accurately infer the parameters of a policy-gradient-based learning algorithm that describes how the animal's internal model of the task evolves over the course of training. We then formulate a theory for optimal training, which involves selecting sequences of stimuli that will drive the animal's internal policy toward a desired location in the parameter space. Simulations show that our method can in theory provide a substantial speedup over standard training methods. We feel these results will hold considerable theoretical and practical implications both for researchers in reinforcement learning and for experimentalists seeking to train animals.},
author = {Bak, Ji Hyun and Choi, Jung and Witten, Ilana and Akrami, Athena and Pillow, Jonathan W},
booktitle = {NIPS},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bak et al. - Unknown - Adaptive optimal training of animal behavior.pdf:pdf},
pages = {1939--1947},
title = {{Adaptive optimal training of animal behavior}},
year = {2016}
}
@article{Elstrott2009,
annote = {NULL},
author = {Elstrott, Justin and Feller, Marla B},
doi = {10.1016/j.conb.2009.03.004},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/82PFMAJK/2009 Elstrott Feller CurrOpNeurobiol.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
keywords = {development,direction selectivity,ferret},
language = {en},
mendeley-tags = {development,direction selectivity,ferret},
month = {jun},
number = {3},
pages = {293--297},
shorttitle = {Vision and the establishment of direction-selectiv},
title = {{Vision and the establishment of direction-selectivity: a tale of two circuits}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438809000142 http://homes.mpimf-heidelberg.mpg.de/{~}mhelmsta/pdf/2009 Elstrott Feller CurrOpNeurobiol.pdf},
volume = {19},
year = {2009}
}
@article{Krakauer2017,
abstract = {There are ever more compelling tools available for neuroscience research, ranging from selective genetic tar-geting to optogenetic circuit control to mapping whole connectomes. These approaches are coupled with a deep-seated, often tacit, belief in the reductionist program for understanding the link between the brain and behavior. The aim of this program is causal explanation through neural manipulations that allow testing of necessity and sufficiency claims. We argue, however, that another equally important approach seeks an alternative form of understanding through careful theoretical and experimental decomposition of behavior. Specifically, the detailed analysis of tasks and of the behavior they elicit is best suited for discovering compo-nent processes and their underlying algorithms. In most cases, we argue that study of the neural implemen-tation of behavior is best investigated after such behavioral work. Thus, we advocate a more pluralistic notion of neuroscience when it comes to the brain-behavior relationship: behavioral work provides understanding, whereas neural interventions test causality.},
author = {Krakauer, John W and Ghazanfar, Asif A and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
doi = {10.1016/j.neuron.2016.12.041},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Krakauer et al. - 2017 - Neuroscience Needs Behavior Correcting a Reductionist Bias(2).pdf:pdf},
isbn = {doi:10.1016/j.neuron.2016.12.041},
issn = {08966273},
journal = {Neuron},
month = {feb},
number = {3},
pages = {480--490},
pmid = {28182904},
title = {{Neuroscience Needs Behavior: Correcting a Reductionist Bias}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.041 http://linkinghub.elsevier.com/retrieve/pii/S0896627316310406},
volume = {93},
year = {2017}
}
@article{Ji,
abstract = {Despite many previous studies, the functional innervation pattern of thalamic axons and their target specificity remains to be investigated thoroughly. Here, in primary auditory cortical slices, we examined thalamic innervation patterns for excitatory and different types of inhibitory neurons across laminae, by optogenetically stimulating axons from the medial geniculate body. We found that excitatory cells and parvalbumin (PV)-expressing inhibitory neurons across layer 2/3 (L2/3) to L6 are directly innervated by thalamic projections, with the strongest innervation occurring in L4. The innervation of PV neurons is stronger than that of excitatory neurons in the same layer, with a relatively constant ratio between their innervation strengths across layers. For somatostatin and vasoactive intestinal peptide inhibitory neurons, essentially only L4 neurons were innervated by thalamic axons and the innervation was much weaker compared with excitatory and PV cells. In addition, more than half of inhibitory neurons in L1 were innervated, relatively strongly, by thalamic axons. Similar innervation patterns were also observed in the primary visual cortex. Thus, thalamic information can be processed independently and differentially by different cortical layers, in addition to the generally thought hierarchical processing starting from L4. This parallel processing is likely shaped by feedforward inhibition from PV neurons in each individual lamina, and may extend the computation power of sensory cortices.},
author = {Ji, Xu-Ying and Zingg, Brian and Mesik, Lukas and Xiao, Zhongju and Zhang, Li I and Tao, Huizhong W},
doi = {10.1093/cercor/bhv099},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Ji et al. - Unknown - Thalamocortical Innervation Pattern in Mouse Auditory and Visual Cortex Laminar and Cell-Type Specificity.pdf:pdf},
keywords = {interneurons,thalamocortical connections},
mendeley-tags = {interneurons,thalamocortical connections},
title = {{Thalamocortical Innervation Pattern in Mouse Auditory and Visual Cortex: Laminar and Cell-Type Specificity}}
}
@article{Burgess2017,
abstract = {Research in neuroscience increasingly relies on the mouse, a mammalian species that affords unparalleled genetic tractability and brain atlases. Here, we introduce high-yield methods for probing mouse visual decisions. Mice are head-fixed, facilitating repeatable visual stimulation, eye tracking, and brain access. They turn a steering wheel to make two alternative choices, forced or unforced. Learning is rapid thanks to intuitive coupling of stimuli to wheel position. The mouse decisions deliver high-quality psychometric curves for detection and discrimination and conform to the predictions of a simple probabilistic observer model. The task is readily paired with two-photon imaging of cortical activity. Optogenetic inactivation reveals that the task requires mice to use their visual cortex. Mice are motivated to perform the task by fluid reward or optogenetic stimulation of dopamine neurons. This stimulation elicits a larger number of trials and faster learning. These methods provide a platform to accurately probe mouse vision and its neural basis.},
author = {Burgess, Christopher P. and Lak, Armin and Steinmetz, Nicholas A. and Zatka-Haas, Peter and {Bai Reddy}, Charu and Jacobs, Elina A.K. and Linden, Jennifer F. and Paton, Joseph J. and Ranson, Adam and Schr{\"{o}}der, Sylvia and Soares, Sofia and Wells, Miles J. and Wool, Lauren E. and Harris, Kenneth D. and Carandini, Matteo},
doi = {10.1016/j.celrep.2017.08.047},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/-h et al. - Unknown - High-yield methods for accurate two-alternative visual psychophysics in head-fixed mice.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
number = {10},
pages = {2513--2524},
pmid = {28877482},
title = {{High-Yield Methods for Accurate Two-Alternative Visual Psychophysics in Head-Fixed Mice}},
volume = {20},
year = {2017}
}
@article{Latimer2016,
abstract = {Latimeret al (Reports, 10 July 2015, p. 184) claim that during perceptual decision formation, parietal neurons undergo one-time, discrete steps in firing rate instead of gradual changes that represent the accumulation of evidence. However, that conclusion rests on unsubstantiated assumptions about the time window of evidence accumulation, and their stepping model cannot explain existing data as effectively as evidence-accumulation models.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.7245v1},
author = {Latimer, Kenneth W and Yates, Jacob L and Meister, Miriam L R and Huk, Alexander C and Pillow, Jonathan W},
doi = {10.1126/science.aaa4056},
eprint = {arXiv:1402.7245v1},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Latimer et al. - Unknown - Single-trial spike trains in parietal cortex reveal discrete steps during decision-making.pdf:pdf},
isbn = {10.1126/science.aaa4056},
issn = {0036-8075},
journal = {Science},
keywords = {bayesian,markov-chain-monte-carlo,parietal,stepping},
mendeley-tags = {bayesian,markov-chain-monte-carlo,parietal,stepping},
month = {jul},
number = {6244},
pages = {184--187},
pmid = {27013723},
title = {{Single-trial spike trains in parietal cortex reveal discrete steps during decision-making}},
url = {http://science.sciencemag.org/content/sci/349/6244/184.full.pdf http://www.sciencemag.org/cgi/doi/10.1126/science.aad3596 http://www.sciencemag.org/cgi/doi/10.1126/science.aaa4056},
volume = {349},
year = {2015}
}
@article{Vinyals,
abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6{\{}{\%}{\}} to 93.2{\{}{\%}{\}} and from 88.0{\{}{\%}{\}} to 93.8{\{}{\%}{\}} on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Woolley et al. - 2014 - Emergence of Context-Dependent Variability across a Basal Ganglia Network(3).pdf:pdf;:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Vinyals, Blundell, Lillicrap - 2016 - Matching networks for one shot learning.pdf:pdf},
journal = {Advances In Neural},
title = {{Matching networks for one shot learning}},
url = {http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning},
year = {2016}
}
@article{Anderson1972,
abstract = {Fundamental conceptual problems that arise from the macroscopic and microscopic aspects of the second law of thermodynamics are considered. It is shown that nonequilibrium may become a source of order and that irreversible processes may lead to a new type of dynamic states of matter called "dissipative structures." The thermodynamic theory of such structures is outlined. A microscopic definition of irreversible processes is given, and a transformation theory is developed that allows one to introduce nonunitary equations of motion that explicitly display irreversibility and approach to thermodynamic equilibrium. The work of the group at the University of Brussels in these fields is briefly reviewed. In this new development of theoretical chemistry and physics, it is likely that thermodynamic concepts will play an ever increasing role},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Anderson, P W},
doi = {10.1126/science.177.4047.393},
eprint = {arXiv:1011.1669v3},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Anderson - 1972 - More is different.pdf:pdf},
isbn = {8028675581},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
keywords = {b},
mendeley-tags = {b},
number = {4047},
pages = {393--396},
pmid = {17796623},
title = {{More is different.}},
url = {http://links.jstor.org/sici?sici=0036-8075{\%}2819720804{\%}293{\%}3A177{\%}3A4047{\%}3C393{\%}3AMID{\%}3E2.0.CO{\%}3B2-N},
volume = {177},
year = {1972}
}
@article{Cook2002,
abstract = {We examined how the relationship between neuronal activity and behavior evolved over time during a motion-detection task. Recording from two regions of visual cortex that process motion, the middle temporal (MT) and ventral intraparietal (VIP) areas, we used the time it took subjects to detect a motion stimulus to evaluate the dynamics of the underlying neuronal signals. Single-neuron activity was correlated with stimulus detection and reaction time (RT) in both areas. The rising edge of the population response from both areas was highly predictive of RT using a simple threshold-detection model. The time course of the population responses, however, differed between MT and VIP. For MT, the onset of the neuronal response was relatively constant, whereas for VIP the onset of the neuronal responses increased with RT. In contrast to previous studies, we found that single neurons were not reliable detectors of the motion signal when constrained by realistic detection times.},
author = {Cook, Erik P. and Maunsell, John H. R.},
doi = {10.1038/nn924},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - How does the relationship between activity in visual cortex and.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {985--994},
pmid = {12244324},
title = {{Dynamics of neuronal responses in macaque MT and VIP during motion detection}},
url = {https://www.nature.com/neuro/journal/v5/n10/pdf/nn924.pdf http://www.nature.com/doifinder/10.1038/nn924},
volume = {5},
year = {2002}
}
@article{Deisenroth2011a,
abstract = {Policy search is a subfield in reinforcement learning which focuses on finding good parameters for a given policy parametrization. It is well suited for robotics as it can cope with high-dimensional state and action spaces, one of the main challenges in robot learning. We review recent successes of both model-free and model-based policy search in robot learning. Model-free policy search is a general approach to learn policies based on sampled trajectories. We classify model-free methods based on their policy evaluation strategy, policy update strategy, and exploration strategy and present a unified view on existing algorithms. Learning a policy is often easier than learning an accurate forward model, and, hence, model-free methods are more frequently used in practice. However, for each sampled trajectory, it is necessary to interact with the robot, which can be time consuming and challenging in practice. Model-based policy search addresses this problem by first learning a simulator of the robot's dynamics from data. Subsequently, the simulator generates trajectories that are used for policy learning. For both model-free and model-based policy search methods, we review their respective properties and their applicability to robotic systems.},
author = {Deisenroth, Marc Peter},
doi = {10.1561/2300000021},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Deisenroth, Neumann, Peters - 2011 - A Survey on Policy Search for Robotics(3).pdf:pdf},
isbn = {9781601987037},
issn = {1935-8253},
journal = {Foundations and Trends in Robotics},
keywords = {Artificial Intelligence in Robotics,Markov Decision Processes,Planning and Control,Policy Search},
number = {1},
pages = {1--142},
title = {{A Survey on Policy Search for Robotics}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-robotics/ROB-021},
volume = {2},
year = {2011}
}
@article{Godsill2004,
abstract = {We develop methods for performing smoothing computations in general state-space models. The methods rely on a particle representation of the filtering distributions, and their evolution through time using sequential importance sampling and resampling ideas. In particular, novel techniques are presented for generation of sample realizations of historical state sequences. This is carried out in a forward-filtering backward-smoothing procedure that can be viewed as the nonlinear, non-Gaussian counterpart of standard Kalman filter-based simulation smoothers in the linear Gaussian case. Convergence in the mean squared error sense of the smoothed trajectories is proved, showing the validity of our proposed method. The methods are tested in a substantial application for the processing of speech signals represented by a time-varying autoregression and parameterized in terms of time-varying partial correlation coefficients, comparing the results of our algorithm with those from a simple smoother based on the filtered trajectories.},
annote = {NULL},
author = {Godsill, Simon J and Doucet, Arnaud and West, Mike},
doi = {10.1198/016214504000000151},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Godsill, Doucet, West - 2004 - Monte Carlo Smoothing for Nonlinear Time Series.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {bayesian inference,non gaussian time series,nonlinear time series,particle filter,sequential monte carlo,state},
number = {465},
pages = {156--168},
title = {{Monte Carlo Smoothing for Nonlinear Time Series}},
url = {http://jimbeck.caltech.edu/summerlectures/references/Particle smoother.pdf http://pubs.amstat.org/doi/abs/10.1198/016214504000000151{\%}5Cnhttp://www.tandfonline.com/doi/abs/10.1198/016214504000000151},
volume = {99},
year = {2004}
}
@article{Kormushev2012,
abstract = {We reveal a link between particle filtering methods and direct policy search reinforcement learning, and propose a novel reinforcement learning algorithm, based heavily on ideas borrowed from particle filters. A major advantage of the proposed algorithm is its ability to perform global search in policy space and thus find the globally optimal policy. We validate the approach on one-and two-dimensional problems with multiple optima, and compare its performance to a global random sampling method, and a state-of-the-art Expectation-Maximization based reinforcement learning algorithm.},
author = {Kormushev, Petar and Caldwell, Darwin G},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kormushev, Caldwell - 2012 - Direct Policy Search Reinforcement Learning based on Particle Filtering.pdf:pdf},
journal = {European Workshop on Reinforcement Learning},
keywords = {global search,parameterized policy,particle filter,reinforcement learning},
pages = {1--13},
title = {{Direct Policy Search Reinforcement Learning based on Particle Filtering}},
url = {https://spiral.imperial.ac.uk/bitstream/10044/1/26091/2/Kormushev{\_}EWRL-2012.pdf},
year = {2012}
}
@article{Gomez-Marin2014,
abstract = {Behavior is a unifying organismal process where genes, neural function, anatomy and environment converge and interrelate. Here we review the current state and discuss the future effect of accelerating advances in technology for behavioral studies, focusing on rodents as an example. We frame our perspective in three dimensions: the degree of experimental constraint, dimensionality of data and level of description. We argue that 'big behavioral data' presents challenges proportionate to its promise and describe how these challenges might be met through opportunities afforded by the two rival conceptual legacies of twentieth century behavioral science, ethology and psychology. We conclude that, although 'more is not necessarily better', copious, quantitative and open behavioral data has the potential to transform and unify these two disciplines and to solidify the foundations of others, including neuroscience, but only if the development of new theoretical frameworks and improved experimental designs matches the technological progress.},
author = {Gomez-Marin, Alex and Paton, Joseph J and Kampff, Adam R and Costa, Rui M and Mainen, Zachary F},
doi = {10.1038/nn.3812},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(3).pdf:pdf},
isbn = {1097-6256},
issn = {1546-1726},
journal = {Nature neuroscience},
month = {oct},
number = {11},
pages = {1455--1462},
pmid = {25349912},
title = {{Big behavioral data: psychology, ethology and the foundations of neuroscience.}},
url = {http://www.nature.com/doifinder/10.1038/nn.3812},
volume = {17},
year = {2014}
}
@article{Fyodorov2007,
abstract = {We start with a rather detailed, general discussion of recent results of the replica approach to statistical mechanics of a single classical particle placed in a random {\$}N (\backslashgg 1){\$}-dimensional Gaussian landscape and confined by a spherically symmetric potential suitably growing at infinity. Then we employ random matrix methods to calculate the density of stationary points, as well as minima, of the associated energy surface. This is used to show that for a generic smooth, concave confining potentials the condition of the zero-temperature replica symmetry breaking coincides with one signalling that {\{}$\backslash$it both{\}} mean total number of stationary points in the energy landscape, {\{}$\backslash$it and{\}} the mean number of minima are exponential in {\$}N{\$}. For such systems the (annealed) complexity of minima vanishes cubically when approaching the critical confinement, whereas the cumulative annealed complexity vanishes quadratically. Different behaviour reported in our earlier short communication [Y.V. Fyodorov et al., {\{}$\backslash$it JETP Lett.{\}} {\{}$\backslash$bf 85{\}}, 261, (2007)] was due to non-analyticity of the hard-wall confinement potential. Finally, for the simplest case of parabolic confinement we investigate how the complexity depends on the index of stationary points. In particular, we show that in the vicinity of critical confinement the saddle-points with a positive annealed complexity must be close to minima, as they must have a vanishing {\{}$\backslash$it fraction{\}} of negative eigenvalues in the Hessian.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0702601},
author = {Fyodorov, Yan V and Williams, Ian},
doi = {10.1007/s10955-007-9386-x},
eprint = {0702601},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Fyodorov, Williams - 2007 - Replica symmetry breaking condition exposed by random matrix calculation of landscape complexity.pdf:pdf},
issn = {00224715},
journal = {Journal of Statistical Physics},
number = {5-6},
pages = {1081--1116},
primaryClass = {cond-mat},
title = {{Replica symmetry breaking condition exposed by random matrix calculation of landscape complexity}},
volume = {129},
year = {2007}
}
@article{Koralek2012,
abstract = {The ability to learn new skills and perfect them with practice applies not only to physical skills but also to abstract skills, like motor planning or neuroprosthetic actions. Although plasticity in corticostriatal circuits has been implicated in learning physical skills, it remains unclear if similar circuits or processes are required for abstract skill learning. Here we use a novel behavioural task in rodents to investigate the role of corticostriatal plasticity in abstract skill learning. Rodents learned to control the pitch of an auditory cursor to reach one of two targets by modulating activity in primary motor cortex irrespective of physical movement. Degradation of the relation between action and outcome, as well as sensory-specific devaluation and omission tests, demonstrate that these learned neuroprosthetic actions are intentional and goal-directed, rather than habitual. Striatal neurons change their activity with learning, with more neurons modulating their activity in relation to target-reaching as learning progresses. Concomitantly, strong relations between the activity of neurons in motor cortex and the striatum emerge. Specific deletion of striatal NMDA receptors impairs the development of this corticostriatal plasticity, and disrupts the ability to learn neuroprosthetic skills. These results suggest that corticostriatal plasticity is necessary for abstract skill learning, and that neuroprosthetic movements capitalize on the neural circuitry involved in natural motor learning.},
author = {Koralek, Aaron C and Jin, Xin and {Long II}, John D. and Costa, Rui M and Carmena, Jose M},
doi = {10.1038/nature10845},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Koralek et al. - 2012 - Corticostriatal plasticity is necessary for learning intentional neuroprosthetic skills.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {7389},
pages = {331--335},
pmid = {22388818},
title = {{Corticostriatal plasticity is necessary for learning intentional neuroprosthetic skills}},
url = {https://www.nature.com/nature/journal/v483/n7389/pdf/nature10845.pdf http://www.nature.com/doifinder/10.1038/nature10845},
volume = {483},
year = {2012}
}
@article{Yu2009,
abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality- reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality- reduction operations in a common probabilistic framework. We ap- plied these methods to the activity of 61 neurons recorded simulta- neously in macaque premotor and motor cortices during reach plan- ning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor plan- ning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single- trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method. INTRODUCTION},
author = {Yu, Bm and Cunningham, Jp and Santhanam, Gopal and Ryu, Si and Shenoy, Kv and Sahani, Maneesh},
doi = {10.1152/jn.90941.2008.},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Yu et al. - 2009 - Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity (vol 102, pg.pdf:pdf},
isbn = {0022-3077},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {April 2009},
pages = {614--635},
pmid = {19357332},
title = {{Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity (vol 102, pg 614, 2009)}},
url = {http://discovery.ucl.ac.uk/120939/},
volume = {102},
year = {2009}
}
@article{Bruno,
abstract = {Sensory stimuli reach the brain via the thalamocortical projection, a group of axons thought to be among the most powerful in the neocortex. Surprisingly, these axons account for only {\`{E}}15{\%} of synapses onto cortical neurons. The thalamocortical pathway might thus achieve its effectiveness via high-efficacy thalamocortical synapses or via amplification within cortical layer 4. In rat somatosensory cortex, we measured in vivo the excitatory postsynaptic potential evoked by a single synaptic connection and found that thalamocortical synapses have low efficacy. Convergent inputs, however, are both numerous and synchronous, and intracortical amplification is not required. Our results suggest a mechanism of cortical activation by which thalamic input alone can drive cortex.},
author = {Bruno, Randy M and Sakmann, Bert},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bruno, Sakmann - 2006 - Cortex Is Driven by Weak but Synchronously Active Thalamocortical Synapses.pdf:pdf},
title = {{Cortex Is Driven by Weak but Synchronously Active Thalamocortical Synapses}}
}
@misc{Krakauer2017a,
abstract = {There are ever more compelling tools available for neuroscience research, ranging from selective genetic targeting to optogenetic circuit control to mapping whole connectomes. These approaches are coupled with a deep-seated, often tacit, belief in the reductionist program for understanding the link between the brain and behavior. The aim of this program is causal explanation through neural manipulations that allow testing of necessity and sufficiency claims. We argue, however, that another equally important approach seeks an alternative form of understanding through careful theoretical and experimental decomposition of behavior. Specifically, the detailed analysis of tasks and of the behavior they elicit is best suited for discovering component processes and their underlying algorithms. In most cases, we argue that study of the neural implementation of behavior is best investigated after such behavioral work. Thus, we advocate a more pluralistic notion of neuroscience when it comes to the brain-behavior relationship: behavioral work provides understanding, whereas neural interventions test causality.},
author = {Krakauer, John W and Ghazanfar, Asif A and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
booktitle = {Neuron},
doi = {10.1016/j.neuron.2016.12.041},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Krakauer et al. - 2017 - Neuroscience Needs Behavior Correcting a Reductionist Bias(2).pdf:pdf},
isbn = {doi:10.1016/j.neuron.2016.12.041},
issn = {10974199},
number = {3},
pages = {480--490},
pmid = {28182904},
title = {{Neuroscience Needs Behavior: Correcting a Reductionist Bias}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.041},
volume = {93},
year = {2017}
}
@article{Bogunovic,
abstract = {We consider the sequential Bayesian optimization problem with bandit feedback, adopting a formulation that allows for the reward function to vary with time. We model the reward function using a Gaussian process whose evolution obeys a simple Markov model. We introduce two natural extensions of the classical Gaussian process upper confidence bound (GP-UCB) algorithm. The first, R-GP-UCB, resets GP-UCB at regular intervals. The second, TV-GP-UCB, instead forgets about old data in a smooth fashion. Our main contribution comprises of novel regret bounds for these algorithms, providing an explicit characterization of the trade-off between the time horizon and the rate at which the function varies. We illustrate the performance of the algorithms on both synthetic and real data, and we find the gradual forgetting of TV-GP-UCB to perform favorably compared to the sharp resetting of R-GP-UCB. Moreover, both algorithms significantly outperform classical GP-UCB, since it treats stale and fresh data equally.},
archivePrefix = {arXiv},
arxivId = {1601.06650},
author = {Bogunovic, Ilija and Scarlett, Jonathan and Cevher, Volkan},
eprint = {1601.06650},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bogunovic, Scarlett, Cevher - Unknown - Time-Varying Gaussian Process Bandit Optimization.pdf:pdf},
pages = {1--9},
title = {{Time-Varying Gaussian Process Bandit Optimization}},
url = {http://arxiv.org/abs/1601.06650},
volume = {51},
year = {2016}
}
@article{Zhang2014,
abstract = {Zhang, Kechen, Iris Ginzburg, Bruce L. McNaughton, and Ter-decoding problems have been studied previously (Abbott rence J. Sejnowski. Interpreting neuronal population activity by re-1994; Bialek et al. 1991; Optican and Richmond 1987; Sali-construction: unified framework with application to hippocampal nas and Abbott 1994; Seung and Sompolinsky 1993; Snippe place cells.},
author = {Zhang, Kechen and Ginzburg, Iris and Mcnaughton, Bruce L and Sejnowski, Terrence J and Hartley, Tom and Lever, Colin and Burgess, Neil and Keefe, John O and B, Phil Trans R Soc and Kloosterman, Fabian and Layton, Stuart P and Chen, Zhe and Wilson, Matthew a and Bendor, Daniel and Mckenzie, Sam and Robinson, Nick T M and Herrera, Lauren and Churchill, Jordana C and Naughton, Bruce L M C},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2014 - Interpreting Neuronal Population Activity by Reconstruction Unified Framework With Application to Hippocampal Pla.pdf:pdf},
isbn = {1024310256},
journal = {The American Physiological society},
pages = {1017--1044},
title = {{Interpreting Neuronal Population Activity by Reconstruction : Unified Framework With Application to Hippocampal Place Cells Interpreting Neuronal Population Activity by Reconstruction : Unified Framework With Application to Hippocampal Place Cells}},
url = {http://jn.physiology.org/content/jn/79/2/1017.full.pdf},
volume = {79},
year = {2014}
}
@article{Bruno2006,
author = {Bruno, Randy M. and Sakmann, Bert},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Bruno, Sakmann - 2006 - Cortex Is Driven by Weak but Synchronously Active Thalamocortical Synapses.pdf:pdf},
journal = {Science},
keywords = {thalamocortical},
mendeley-tags = {thalamocortical},
number = {5780},
title = {{Cortex Is Driven by Weak but Synchronously Active Thalamocortical Synapses}},
volume = {312},
year = {2006}
}
@article{Kojima,
abstract = {Basal ganglia-thalamocortical circuits are critical for motor control and motor learning. Classically, basal ganglia nuclei are thought to regulate motor behavior by increasing or decreasing cortical firing rates, and basal ganglia diseases are assumed to reflect abnormal overall activity levels. More recent studies suggest instead that motor disorders derive from abnormal firing patterns, and have led to the hypothesis that surgical treatments, such as pallidotomy, act primarily by eliminating pathological firing patterns. Surprisingly little is known, however, about how the basal ganglia normally influence task-related cortical activity to regulate motor behavior, and how lesions of the basal ganglia influence cortical firing properties. Here, we investigated these questions in a songbird circuit that has striking homologies to mammalian basal ganglia-thalamocortical circuits but is specialized for singing. The "cortical" outflow nucleus of this circuit is required for song plasticity and normally exhibits increased firing during singing and song-locked burst firing. We found that lesions of the striato-pallidal nucleus in this circuit prevented hearing-dependent song changes. These basal ganglia lesions also stripped the cortical outflow neurons of their patterned burst firing during singing, without changing their spontaneous or singing-related firing rates. Taken together, these results suggest that the basal ganglia are essential not for normal cortical firing rates but for driving task-specific cortical firing patterns, including bursts. Moreover, such patterned bursting appears critical for motor plasticity. Our findings thus provide support for therapies that aim to treat basal ganglia movement disorders by normalizing firing patterns.},
archivePrefix = {arXiv},
arxivId = {1408.1149},
author = {Kojima, Satoshi and Kao, Mimi H and Doupe, Allison J},
doi = {10.1073/pnas.1216308110},
eprint = {1408.1149},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Kojima, Kao, Doupe - Unknown - Task-related {\&}quot cortical {\&}quot bursting depends critically on basal ganglia input and is linked to voc.pdf:pdf},
isbn = {0086278787102},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animal,Animal: physiology,Animals,Basal Ganglia,Basal Ganglia: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Finches,Finches: physiology,Male,Vocalization},
number = {12},
pages = {4756--61},
pmid = {23449880},
title = {{Task-related "cortical" bursting depends critically on basal ganglia input and is linked to vocal plasticity.}},
url = {http://www.pnas.org/content/110/12/4756.full.pdf http://www.pnas.org/content/110/12/4756.long},
volume = {110},
year = {2013}
}
@article{Einstein1934,
abstract = {IF YOU wish to learn from the theoretical physi- cist anything about the methods which he uses, I would give you the following piece of advice: Don't listen to his words, examine his achieve- ments. For to the discoverer in that field, the constructions of his imagination appear so necessary and so natural that he is apt to treat them not as the creations of his thoughts but as given realities.},
author = {Einstein, Albert},
doi = {10.1086/286316},
file = {:Users/Yves/Library/Application Support/Mendeley Desktop/Downloaded/Einstein - 1934 - On the Method of Theoretical Physics.pdf:pdf},
isbn = {00318248},
issn = {0031-8248},
journal = {Philosophy of Science},
number = {2},
pages = {163},
pmid = {14497307},
title = {{On the Method of Theoretical Physics}},
url = {http://www.journals.uchicago.edu/doi/abs/10.1086/286316},
volume = {1},
year = {1934}
}
@book{Rasmussen2006,
abstract = {GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified},
author = {Rasmussen, Edward and Williams, K I},
booktitle = {MIT Press},
isbn = {0-262-18253-X},
keywords = {Computers},
pages = {248},
title = {{Gaussian processes for machine learning‎}},
year = {2006}
}
